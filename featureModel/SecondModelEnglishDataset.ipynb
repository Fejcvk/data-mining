{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondModelEnglishDataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3HJfGRjHi_Yq",
        "colab_type": "text"
      },
      "source": [
        "# Model based on sentence features\n",
        "***\n",
        "Libraries:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wQH-5eAsLAiz",
        "colab_type": "code",
        "outputId": "49246352-c478-46e1-d7f2-7b257d8bafb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 446
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install -q pyyaml h5py\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WQzx8FvjYPs",
        "colab_type": "text"
      },
      "source": [
        "## Data preprocessing \n",
        "- reading data \n",
        "- change columns names \n",
        "- drop NaN rows \n",
        "- fill others NaN values by special sign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pC-SuQGTLnrB",
        "colab_type": "code",
        "outputId": "7cb5a0c4-cae1-4f95-f35f-acf0b0877f3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "df = pd.read_excel('dataset3.xlsx')\n",
        "df.reset_index()\n",
        "df = df.iloc[:,[2,3,5,8,9,11,12,13]]\n",
        "df.columns = [\"verb_veridial_positive\",\n",
        "              \"verb_veridical_negative\",\n",
        "              \"semantic_characteristic\",\n",
        "              \"standford_signature_for_that\",\n",
        "              \"standford_signature_for_to\",\n",
        "              \"complementizer\",\n",
        "              \"verb_tense\",\n",
        "              \"semantic_relation\"]\n",
        "df.dropna(inplace=True, axis = 0, how = 'all')\n",
        "df.fillna(axis = 0, inplace =True, value=\"none\")\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verb_veridial_positive</th>\n",
              "      <th>verb_veridical_negative</th>\n",
              "      <th>semantic_characteristic</th>\n",
              "      <th>standford_signature_for_that</th>\n",
              "      <th>standford_signature_for_to</th>\n",
              "      <th>complementizer</th>\n",
              "      <th>verb_tense</th>\n",
              "      <th>semantic_relation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>o/o</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>emotywny</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>m√≥wienia</td>\n",
              "      <td>nie ma</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>o/o</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>nie ma</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>past</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  verb_veridial_positive verb_veridical_negative  ... verb_tense semantic_relation\n",
              "0                      o                       o  ...    present                 N\n",
              "1                      o                       o  ...    present                 N\n",
              "2                      o                       o  ...    present                 N\n",
              "3                      o                       o  ...    present                 N\n",
              "4                      o                       o  ...       past                 E\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "94rQMkhukBCp",
        "colab_type": "text"
      },
      "source": [
        "### cleaning data by deleting uncertainty - simplification \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OnfM4fytjyde",
        "colab_type": "code",
        "outputId": "c3bec9aa-737d-4938-e7a7-f0025810bd96",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 214
        }
      },
      "source": [
        "#verb veridical positive cleaning\n",
        "df.verb_veridial_positive = df.verb_veridial_positive.apply(lambda x: '+' if '+' in x else x)\n",
        "df.verb_veridial_positive = df.verb_veridial_positive.apply(lambda x: '-' if '-' in x else x)\n",
        "df.verb_veridial_positive = df.verb_veridial_positive.apply(lambda x: 'o' if 'o' in x else x)\n",
        "df.verb_veridial_positive = df.verb_veridial_positive.apply(lambda x: '?' if '?' in x else x)\n",
        "\n",
        "#verb veridical negative cleaning\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '+' if '+' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: 'o' if 'o' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '-' if '-' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '1' if '1' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '?' if '?' in x else x)\n",
        "\n",
        "#df.semantic_characteristic.unique() cleaning not needed\n",
        "#df.standford_signature_for_that.unique() cleaning not needed\n",
        "#df.standford_signature_for_to.unique() cleaning not needed\n",
        "#df.complementizer.unique() cleaning not needed\n",
        "\n",
        "#df.verb_tense cleaning\n",
        "df.verb_tense = df.verb_tense.apply(lambda x: 'present' if 'present' in x else x)\n",
        "df.verb_tense = df.verb_tense.apply(lambda x: 'past' if 'past' in x else x)\n",
        "df.verb_tense = df.verb_tense.apply(lambda x: 'future' if 'future' in x else x)\n",
        "df.verb_tense = df.verb_tense.apply(lambda x: 'none' if 'none' in x else x)\n",
        "df.verb_tense = df.verb_tense.apply(lambda x: '?' if '?' in x else x)\n",
        "\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verb_veridial_positive</th>\n",
              "      <th>verb_veridical_negative</th>\n",
              "      <th>semantic_characteristic</th>\n",
              "      <th>standford_signature_for_that</th>\n",
              "      <th>standford_signature_for_to</th>\n",
              "      <th>complementizer</th>\n",
              "      <th>verb_tense</th>\n",
              "      <th>semantic_relation</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>o/o</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>emotywny</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>m√≥wienia</td>\n",
              "      <td>nie ma</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>o/o</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>present</td>\n",
              "      <td>N</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>nie ma</td>\n",
              "      <td>none</td>\n",
              "      <td>that</td>\n",
              "      <td>past</td>\n",
              "      <td>E</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  verb_veridial_positive verb_veridical_negative  ... verb_tense semantic_relation\n",
              "0                      o                       o  ...    present                 N\n",
              "1                      o                       o  ...    present                 N\n",
              "2                      o                       o  ...    present                 N\n",
              "3                      o                       o  ...    present                 N\n",
              "4                      o                       o  ...       past                 E\n",
              "\n",
              "[5 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "09oFxOcRnZEc",
        "colab_type": "code",
        "outputId": "74756b81-a44f-49c1-b674-c57375da6e03",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "print(df.verb_veridial_positive.unique())\n",
        "print(df.verb_veridical_negative.unique())\n",
        "print(df.semantic_characteristic.unique())\n",
        "print(df.standford_signature_for_that.unique())\n",
        "print(df.standford_signature_for_to.unique())\n",
        "print(df.complementizer.unique())\n",
        "print(df.verb_tense.unique())\n",
        "print(df.semantic_relation.unique())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['o' '+' '-' '?']\n",
            "['o' '+' '-' '?' '1']\n",
            "['epistemiczny' 'emotywny' 'm√≥wienia' 'ontyczny' 'wynikania'\n",
            " 'okre≈õlajƒÖce dostƒôp do wiedzy' 'percepcyjny' 'pamiƒôciowy' 'odkrycia'\n",
            " 'czynno≈õciowy' 'epistemiczno-percepcyjny' 'pokazywania' 'dowodzenia'\n",
            " 'm√≥wieniowo-pamiƒôciowy' 'liczenia' 'wnioskowania'\n",
            " 'percepcyjno-m√≥wieniowy' 'zdarzeniowy']\n",
            "['o/o' 'none' 'nie ma' '\"+/o\"' '\"+/+\"' 'o/+']\n",
            "['none' 'o/o']\n",
            "['that' 'to']\n",
            "['present' 'past' 'none' 'future' '?']\n",
            "['N' 'E' '?' 'C']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNUe-X4_gqmL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.to_csv(\"engData.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIX0AGcQkGG5",
        "colab_type": "text"
      },
      "source": [
        "### vectorize data and split to features and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7NRdcwkIX5",
        "colab_type": "code",
        "outputId": "a98eace7-8bc2-49b3-e244-4dc08d6fa27c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        }
      },
      "source": [
        "df = pd.get_dummies(df)\n",
        "\n",
        "X_train = df.iloc[:,1:-4]\n",
        "y_train = df.iloc[:,-4:]\n",
        "\n",
        "X_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>verb_veridial_positive_-</th>\n",
              "      <th>verb_veridial_positive_?</th>\n",
              "      <th>verb_veridial_positive_o</th>\n",
              "      <th>verb_veridical_negative_+</th>\n",
              "      <th>verb_veridical_negative_-</th>\n",
              "      <th>verb_veridical_negative_1</th>\n",
              "      <th>verb_veridical_negative_?</th>\n",
              "      <th>verb_veridical_negative_o</th>\n",
              "      <th>semantic_characteristic_czynno≈õciowy</th>\n",
              "      <th>semantic_characteristic_dowodzenia</th>\n",
              "      <th>semantic_characteristic_emotywny</th>\n",
              "      <th>semantic_characteristic_epistemiczno-percepcyjny</th>\n",
              "      <th>semantic_characteristic_epistemiczny</th>\n",
              "      <th>semantic_characteristic_liczenia</th>\n",
              "      <th>semantic_characteristic_m√≥wienia</th>\n",
              "      <th>semantic_characteristic_m√≥wieniowo-pamiƒôciowy</th>\n",
              "      <th>semantic_characteristic_odkrycia</th>\n",
              "      <th>semantic_characteristic_okre≈õlajƒÖce dostƒôp do wiedzy</th>\n",
              "      <th>semantic_characteristic_ontyczny</th>\n",
              "      <th>semantic_characteristic_pamiƒôciowy</th>\n",
              "      <th>semantic_characteristic_percepcyjno-m√≥wieniowy</th>\n",
              "      <th>semantic_characteristic_percepcyjny</th>\n",
              "      <th>semantic_characteristic_pokazywania</th>\n",
              "      <th>semantic_characteristic_wnioskowania</th>\n",
              "      <th>semantic_characteristic_wynikania</th>\n",
              "      <th>semantic_characteristic_zdarzeniowy</th>\n",
              "      <th>standford_signature_for_that_\"+/+\"</th>\n",
              "      <th>standford_signature_for_that_\"+/o\"</th>\n",
              "      <th>standford_signature_for_that_nie ma</th>\n",
              "      <th>standford_signature_for_that_none</th>\n",
              "      <th>standford_signature_for_that_o/+</th>\n",
              "      <th>standford_signature_for_that_o/o</th>\n",
              "      <th>standford_signature_for_to_none</th>\n",
              "      <th>standford_signature_for_to_o/o</th>\n",
              "      <th>complementizer_that</th>\n",
              "      <th>complementizer_to</th>\n",
              "      <th>verb_tense_?</th>\n",
              "      <th>verb_tense_future</th>\n",
              "      <th>verb_tense_none</th>\n",
              "      <th>verb_tense_past</th>\n",
              "      <th>verb_tense_present</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   verb_veridial_positive_-  ...  verb_tense_present\n",
              "0                         0  ...                   1\n",
              "1                         0  ...                   1\n",
              "2                         0  ...                   1\n",
              "3                         0  ...                   1\n",
              "4                         0  ...                   0\n",
              "\n",
              "[5 rows x 41 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLqFLidq0YLV",
        "colab_type": "code",
        "outputId": "b03855b0-243d-4719-dc8e-83947e0b8001",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        }
      },
      "source": [
        "X_train.columns"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['verb_veridial_positive_-', 'verb_veridial_positive_?',\n",
              "       'verb_veridial_positive_o', 'verb_veridical_negative_+',\n",
              "       'verb_veridical_negative_-', 'verb_veridical_negative_1',\n",
              "       'verb_veridical_negative_?', 'verb_veridical_negative_o',\n",
              "       'semantic_characteristic_czynno≈õciowy',\n",
              "       'semantic_characteristic_dowodzenia',\n",
              "       'semantic_characteristic_emotywny',\n",
              "       'semantic_characteristic_epistemiczno-percepcyjny',\n",
              "       'semantic_characteristic_epistemiczny',\n",
              "       'semantic_characteristic_liczenia', 'semantic_characteristic_m√≥wienia',\n",
              "       'semantic_characteristic_m√≥wieniowo-pamiƒôciowy',\n",
              "       'semantic_characteristic_odkrycia',\n",
              "       'semantic_characteristic_okre≈õlajƒÖce dostƒôp do wiedzy',\n",
              "       'semantic_characteristic_ontyczny',\n",
              "       'semantic_characteristic_pamiƒôciowy',\n",
              "       'semantic_characteristic_percepcyjno-m√≥wieniowy',\n",
              "       'semantic_characteristic_percepcyjny',\n",
              "       'semantic_characteristic_pokazywania',\n",
              "       'semantic_characteristic_wnioskowania',\n",
              "       'semantic_characteristic_wynikania',\n",
              "       'semantic_characteristic_zdarzeniowy',\n",
              "       'standford_signature_for_that_\"+/+\"',\n",
              "       'standford_signature_for_that_\"+/o\"',\n",
              "       'standford_signature_for_that_nie ma',\n",
              "       'standford_signature_for_that_none', 'standford_signature_for_that_o/+',\n",
              "       'standford_signature_for_that_o/o', 'standford_signature_for_to_none',\n",
              "       'standford_signature_for_to_o/o', 'complementizer_that',\n",
              "       'complementizer_to', 'verb_tense_?', 'verb_tense_future',\n",
              "       'verb_tense_none', 'verb_tense_past', 'verb_tense_present'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxEJ6K-fxkTU",
        "colab_type": "code",
        "outputId": "157ac9e1-9504-48cd-8323-c57e92e6f8e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "y_train.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>semantic_relation_?</th>\n",
              "      <th>semantic_relation_C</th>\n",
              "      <th>semantic_relation_E</th>\n",
              "      <th>semantic_relation_N</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   semantic_relation_?  ...  semantic_relation_N\n",
              "0                    0  ...                    1\n",
              "1                    0  ...                    1\n",
              "2                    0  ...                    1\n",
              "3                    0  ...                    1\n",
              "4                    0  ...                    0\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xi8QfyAkbiN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Keras model building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amhvtjnZQwhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YQA-dmJ5RL9y",
        "colab_type": "code",
        "outputId": "76585c3f-937d-40b5-a31f-43ff8750c809",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        }
      },
      "source": [
        "model = tf.keras.Sequential()\n",
        "\n",
        "#get number of columns in training data\n",
        "n_cols = X_train.shape[1]\n",
        "print(n_cols)\n",
        "#add model layers\n",
        "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3), input_shape=(n_cols,)))\n",
        "model.add(Dense(250, activation='relu'))\n",
        "model.add(Dense(500, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(250, activation='selu'))\n",
        "model.add(Dense(100, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(50, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
        "model.add(Dense(4, activation='softmax'))\n",
        "\n",
        "model.compile(optimizer = 'adam', loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "41\n",
            "Model: \"sequential_5\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense_35 (Dense)             (None, 100)               4200      \n",
            "_________________________________________________________________\n",
            "dense_36 (Dense)             (None, 250)               25250     \n",
            "_________________________________________________________________\n",
            "dense_37 (Dense)             (None, 500)               125500    \n",
            "_________________________________________________________________\n",
            "dense_38 (Dense)             (None, 250)               125250    \n",
            "_________________________________________________________________\n",
            "dense_39 (Dense)             (None, 100)               25100     \n",
            "_________________________________________________________________\n",
            "dense_40 (Dense)             (None, 50)                5050      \n",
            "_________________________________________________________________\n",
            "dense_41 (Dense)             (None, 4)                 204       \n",
            "=================================================================\n",
            "Total params: 310,554\n",
            "Trainable params: 310,554\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xq3yIS2Kkh2r",
        "colab_type": "text"
      },
      "source": [
        "## Training model on prepared data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1gnjHDM5dJb_",
        "colab_type": "code",
        "outputId": "da69c34c-358d-4ee3-ad07-114097dbb05e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#train model\n",
        "history = model.fit(X_train, y_train, validation_split=0.4, epochs=30)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "42/42 [==============================] - 0s 10ms/step - loss: 0.5196 - accuracy: 0.8474 - val_loss: 0.4843 - val_accuracy: 0.8565\n",
            "Epoch 2/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3902 - accuracy: 0.8808 - val_loss: 0.4513 - val_accuracy: 0.8679\n",
            "Epoch 3/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3734 - accuracy: 0.8914 - val_loss: 0.4616 - val_accuracy: 0.8679\n",
            "Epoch 4/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3631 - accuracy: 0.8945 - val_loss: 0.4668 - val_accuracy: 0.8690\n",
            "Epoch 5/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3569 - accuracy: 0.8907 - val_loss: 0.4602 - val_accuracy: 0.8610\n",
            "Epoch 6/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3413 - accuracy: 0.8960 - val_loss: 0.4561 - val_accuracy: 0.8679\n",
            "Epoch 7/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3285 - accuracy: 0.8967 - val_loss: 0.4583 - val_accuracy: 0.8724\n",
            "Epoch 8/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3223 - accuracy: 0.8952 - val_loss: 0.5002 - val_accuracy: 0.8690\n",
            "Epoch 9/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3149 - accuracy: 0.9036 - val_loss: 0.4844 - val_accuracy: 0.8690\n",
            "Epoch 10/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3440 - accuracy: 0.8998 - val_loss: 0.4969 - val_accuracy: 0.8679\n",
            "Epoch 11/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3206 - accuracy: 0.9005 - val_loss: 0.4862 - val_accuracy: 0.8599\n",
            "Epoch 12/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3105 - accuracy: 0.8960 - val_loss: 0.5134 - val_accuracy: 0.8759\n",
            "Epoch 13/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3094 - accuracy: 0.9021 - val_loss: 0.5288 - val_accuracy: 0.8690\n",
            "Epoch 14/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3048 - accuracy: 0.9021 - val_loss: 0.5135 - val_accuracy: 0.8679\n",
            "Epoch 15/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3137 - accuracy: 0.9013 - val_loss: 0.5156 - val_accuracy: 0.8690\n",
            "Epoch 16/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.3065 - accuracy: 0.9036 - val_loss: 0.5254 - val_accuracy: 0.8656\n",
            "Epoch 17/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3070 - accuracy: 0.9043 - val_loss: 0.5094 - val_accuracy: 0.8724\n",
            "Epoch 18/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2877 - accuracy: 0.9074 - val_loss: 0.5287 - val_accuracy: 0.8633\n",
            "Epoch 19/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.3054 - accuracy: 0.9028 - val_loss: 0.5484 - val_accuracy: 0.8656\n",
            "Epoch 20/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2998 - accuracy: 0.9089 - val_loss: 0.5269 - val_accuracy: 0.8736\n",
            "Epoch 21/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2915 - accuracy: 0.9119 - val_loss: 0.5858 - val_accuracy: 0.8679\n",
            "Epoch 22/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2933 - accuracy: 0.9089 - val_loss: 0.5866 - val_accuracy: 0.8690\n",
            "Epoch 23/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2935 - accuracy: 0.8990 - val_loss: 0.5479 - val_accuracy: 0.8565\n",
            "Epoch 24/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2990 - accuracy: 0.9028 - val_loss: 0.5482 - val_accuracy: 0.8679\n",
            "Epoch 25/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2967 - accuracy: 0.9096 - val_loss: 0.5667 - val_accuracy: 0.8656\n",
            "Epoch 26/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2863 - accuracy: 0.9043 - val_loss: 0.5604 - val_accuracy: 0.8702\n",
            "Epoch 27/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2770 - accuracy: 0.9081 - val_loss: 0.6043 - val_accuracy: 0.8667\n",
            "Epoch 28/30\n",
            "42/42 [==============================] - 0s 8ms/step - loss: 0.2898 - accuracy: 0.9058 - val_loss: 0.5804 - val_accuracy: 0.8702\n",
            "Epoch 29/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2880 - accuracy: 0.9074 - val_loss: 0.6383 - val_accuracy: 0.8702\n",
            "Epoch 30/30\n",
            "42/42 [==============================] - 0s 7ms/step - loss: 0.2896 - accuracy: 0.9096 - val_loss: 0.5925 - val_accuracy: 0.8702\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQDKmJQ_kmdh",
        "colab_type": "text"
      },
      "source": [
        "## plot with train and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi0f_JObgC4C",
        "colab_type": "code",
        "outputId": "ecda56e7-e75f-455c-d78e-9d544c772f6c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim(0,1)\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwVgSUc6uC6Y",
        "colab_type": "text"
      },
      "source": [
        "### Save model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2XZ1N0JuIop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('featureModelEng.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eumOj-NEwNsa",
        "colab_type": "text"
      },
      "source": [
        "## Load model example"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_iSl1JGpu9-E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model2 = tf.keras.models.load_model('my_model.h5',custom_objects={'LeakyReLU': keras.layers.LeakyReLU })\n",
        "model2.summary()\n",
        "print(model2.evaluate(X_train, y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}