{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TestingSecondModels.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kri6U3txHmaY",
        "colab_type": "text"
      },
      "source": [
        "# You can test model here "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SUdthTl_cq1a",
        "colab_type": "text"
      },
      "source": [
        "Steps to use model! \n",
        "\n",
        "\n",
        "1.   Run \"Read libraries\" cell\n",
        "2.   Check you have models to read in your directory. (You should have featureModelEng.h5 and featureModelPl.h5 here) \n",
        "3.   Run \"Read models\" \n",
        "4.   Input data into an \"Input data\" cell and run it \n",
        "5.   Check you have engData.csv and plData.csv in your directory \n",
        "6.   Run \"Input data preprocess\" cell \n",
        "7.   Run \"Model test\" cell \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nw2SUkIvIBP3",
        "colab_type": "text"
      },
      "source": [
        "## Read libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QwHBIwzBIAoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "import pandas as pd \n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjCWJkdjHrda",
        "colab_type": "text"
      },
      "source": [
        "## Read models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0rZLc6TQHtgd",
        "colab_type": "code",
        "outputId": "02752622-1707-4e38-e49c-87df86511642",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "try: \n",
        "  feature_model_eng = tf.keras.models.load_model('featureModelEng.h5',custom_objects={'LeakyReLU': keras.layers.LeakyReLU })\n",
        "  print(\"Model featureModelEng.h5 read successfully!\")\n",
        "except: \n",
        "  print(\"Error occured during reading file!\")\n",
        "  print(\"Probably you don't have featureModelEng.h5 in your working directory!\\n\")\n",
        "try:\n",
        "  feature_model_pl = tf.keras.models.load_model('featureModelPl.h5', custom_objects={\"LeakyReLU\": keras.layers.LeakyReLU})\n",
        "  print(\"Model featureModelPl.h5 read successfully!\")\n",
        "except: \n",
        "  print(\"Error occured during reading file!\")\n",
        "  print(\"Probably you don't have featureModelPl.h5 in your working directory!\\n\")\n",
        "try:\n",
        "  feature_model_pl_presup = tf.keras.models.load_model('featureModelPlPresup.h5', custom_objects={\"LeakyReLU\": keras.layers.LeakyReLU})\n",
        "  print(\"Model featureModelPl.h5 read successfully!\")\n",
        "except: \n",
        "  print(\"Error occured during reading file!\")\n",
        "  print(\"Probably you don't have featureModelPlPresup.h5 in your working directory!\\n\")  "
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model featureModelEng.h5 read successfully!\n",
            "Model featureModelPl.h5 read successfully!\n",
            "Model featureModelPl.h5 read successfully!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "85hbAzmeFjjg",
        "colab_type": "text"
      },
      "source": [
        "## Read data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J--II8tbFnCG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "46784505-8df0-4116-9e62-6b8e8c7a94da"
      },
      "source": [
        "try:\n",
        "  training_eng_data = pd.read_csv(\"engData.csv\", index_col=None)\n",
        "  print(\"English data read successfuly!\")\n",
        "except:\n",
        "  print(\"Error occured during reading file!\")\n",
        "  print(\"Probably you don't have engData.csv in your working directory! \\n\")\n",
        "\n",
        "\n",
        "try:\n",
        "  training_pl_data = pd.read_csv(\"plData.csv\", index_col=None)\n",
        "  print(\"Polish data read successfuly!\")\n",
        "except:\n",
        "  print(\"Error occured during reading file!\")\n",
        "  print(\"Probably you don't have plData.csv in your working directory! \\n\")\n",
        "\n",
        "\n",
        "try:\n",
        "  training_pl_presup_data = pd.read_csv(\"plDataPresup.csv\", index_col=None)\n",
        "  print(\"POlish pressuposition data read successfuly!\")\n",
        "except:\n",
        "  print(\"Error occured during reading file!\")\n",
        "  print(\"Probably you don't have plDataPresup.csv in your working directory! \\n\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "English data read successfuly!\n",
            "Polish data read successfuly!\n",
            "POlish pressuposition data read successfuly!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MKXEa4gKLNdM",
        "colab_type": "text"
      },
      "source": [
        "## Input data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CNoa00FsLQdb",
        "colab_type": "text"
      },
      "source": [
        "### Model ENG "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BmoQ4__DLUZm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "eng_verb_veridical_positive       = \"\" # possible values 'o', '+', '-', '?'\n",
        "eng_verb_veridical_negative       = \"\" # possible values 'o', '+', '-', '?', '1'\n",
        "eng_semantic_characteristic       = \"\" # possible values 'epistemiczny', 'emotywny', 'mówienia', 'ontyczny', 'wynikania',\n",
        "                                       #                 'określające dostęp do wiedzy', 'percepcyjny', 'pamięciowy',\n",
        "                                       #                 'odkrycia', 'czynnościowy', 'epistemiczno-percepcyjny',\n",
        "                                       #                 'pokazywania', 'dowodzenia', 'mówieniowo-pamięciowy', 'liczenia',\n",
        "                                       #                 'wnioskowania', 'percepcyjno-mówieniowy', 'zdarzeniowy'\n",
        "eng_standford_signature_for_that  = \"\" # possible values 'o/o', 'none', 'nie ma', '\"+/o\"', '\"+/+\"', 'o/+'\n",
        "eng_standford_signature_for_to    = \"\" # possible values 'none', 'o/o'\n",
        "eng_complementizer                = \"\" # possible values 'that', 'to'\n",
        "eng_verb_tense                    = \"\" # possible values 'present', 'past', 'none', 'future', '?'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "soyw5MgRLSHd",
        "colab_type": "text"
      },
      "source": [
        "### Model PL"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qf-wBSniM-5_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pl_verb_main_semantic_class   = \"\" # possible values 'mówienia', 'epistemiczny', '?'\n",
        "pl_verb_veridical_positive    = \"\" # possible values 'o' '?' '+' '-'\n",
        "pl_verb_veridical_negative    = \"\" # possible values '?' '+' 'o' '-'\n",
        "pl_verb_tense                 = \"\" # possible values 'brak' 'past' 'present' 'future'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "XSxoRA8i9Qsn"
      },
      "source": [
        "### Model PL Presupposition"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "tJfe8YXK9Qs6",
        "colab": {}
      },
      "source": [
        "pl_presup_verb_main_semantic_class        = \"\" # possible values 'mówienia', 'epistemiczny', '?'\n",
        "pl_presup_verb_veridical_positive    = \"\" # possible values 'o' '?' '+' '-'\n",
        "pl_presup_verb_veridical_negative    = \"\" # possible values '?' '+' 'o' '-'\n",
        "pl_presup_verb_tense                 = \"\" # possible values 'brak' 'past' 'present' 'future'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a3uUV9zaVr0I",
        "colab_type": "text"
      },
      "source": [
        "## Preprocess input data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s-EsnuR7bPDt",
        "colab_type": "code",
        "outputId": "b0b67e41-501b-4083-dd1b-9c9c52b543dc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "#Check values \n",
        "# eng \n",
        "if eng_verb_veridical_positive not in training_eng_data.verb_veridial_positive.unique():\n",
        "  eng_verb_veridical_positive = \"?\"\n",
        "if eng_verb_veridical_negative not in training_eng_data.verb_veridical_negative.unique():\n",
        "  eng_verb_veridical_negative = \"?\"\n",
        "if eng_semantic_characteristic not in training_eng_data.semantic_characteristic.unique():\n",
        "  eng_semantic_characteristic = \"epistemiczny\"\n",
        "if eng_standford_signature_for_that not in training_eng_data.standford_signature_for_that.unique():\n",
        "  eng_standford_signature_for_that = \"none\"\n",
        "if eng_standford_signature_for_to  not in training_eng_data.standford_signature_for_to.unique():\n",
        "  eng_standford_signature_for_to = \"none\"\n",
        "if eng_complementizer  not in training_eng_data.complementizer.unique():\n",
        "  eng_complementizer = \"that\"\n",
        "if eng_verb_tense not in training_eng_data.verb_tense.unique():\n",
        "  eng_verb_tense = \"none\"\n",
        "\n",
        "# pl \n",
        "if pl_verb_main_semantic_class not in training_pl_data.verb_main_semantic_class.unique():\n",
        "  pl_verb_main_semantic_class = \"?\"\n",
        "if pl_verb_veridical_positive not in training_pl_data.verb_veridical_positive.unique():\n",
        "  pl_verb_veridical_positive = \"?\"\n",
        "if pl_verb_veridical_negative not in training_pl_data.verb_veridical_negative.unique():\n",
        "  pl_verb_veridical_negative = \"?\"\n",
        "if pl_verb_tense not in training_pl_data.verb_tense.unique():\n",
        "  pl_verb_tense = \"brak\"\n",
        "\n",
        "# pl presup\n",
        "if pl_presup_verb_main_semantic_class not in training_pl_presup_data.verb_main_semantic_class.unique():\n",
        "  pl_presup_verb_main_semantic_class = \"?\" \n",
        "if pl_presup_verb_veridical_positive not in training_pl_presup_data.verb_veridical_positive.unique():\n",
        "  pl_presup_verb_veridical_positive = \"?\"\n",
        "if pl_presup_verb_veridical_negative not in training_pl_presup_data.verb_veridical_negative.unique():\n",
        "  pl_presup_verb_veridical_negative = \"?\"\n",
        "if pl_presup_verb_tense not in training_pl_presup_data.verb_tense.unique():\n",
        "  pl_presup_verb_tense = \"brak\"\n",
        "\n",
        "# append to datasets\n",
        "# eng\n",
        "training_eng_data = training_eng_data.append({\n",
        " 'verb_veridial_positive': eng_verb_veridical_positive,\n",
        " 'verb_veridical_negative': eng_verb_veridical_negative,\n",
        " 'semantic_characteristic': eng_semantic_characteristic,\n",
        " 'standford_signature_for_that': eng_standford_signature_for_that,\n",
        " 'standford_signature_for_to': eng_standford_signature_for_to,\n",
        " 'complementizer': eng_complementizer,\n",
        " 'verb_tense': eng_verb_tense,\n",
        " 'semantic_relation': \"?\"                                            \n",
        "},\n",
        "ignore_index=True)\n",
        "\n",
        "# pl\n",
        "training_pl_data = training_pl_data.append({\n",
        " 'verb_main_semantic_class' : pl_verb_main_semantic_class,\n",
        " 'verb_veridical_positive': pl_verb_veridical_positive,\n",
        " 'verb_veridical_negative': pl_verb_veridical_negative,\n",
        " 'verb_tense': pl_verb_tense,\n",
        " 'semantic_relation': \"?\"                                      \n",
        "},\n",
        "ignore_index=True)\n",
        "\n",
        "#pl presup\n",
        "training_pl_presup_data = training_pl_presup_data.append({\n",
        " 'verb_main_semantic_class' : pl_presup_verb_main_semantic_class,\n",
        " 'verb_veridical_positive': pl_presup_verb_veridical_positive,\n",
        " 'verb_veridical_negative': pl_presup_verb_veridical_negative,\n",
        " 'verb_tense': pl_presup_verb_tense,\n",
        " 'presupposition': \"no\"                                      \n",
        "},\n",
        "ignore_index=True)\n",
        "\n",
        "# vectorize\n",
        "eng_vectorized = pd.get_dummies(training_eng_data)\n",
        "pl_vectorized = pd.get_dummies(training_pl_data)\n",
        "pl_presup_vectorized = pd.get_dummies(training_pl_presup_data)\n",
        "\n",
        "# get only last row\n",
        "eng_entry_model = eng_vectorized.tail(1)\n",
        "pl_entry_model = pl_vectorized.tail(1)\n",
        "pl_presup_entry_model = pl_presup_vectorized.tail(1)\n",
        "\n",
        "# get features\n",
        "eng_input_model = eng_entry_model.iloc[:,0:-4] \n",
        "pl_input_model = pl_entry_model.iloc[:,0:-4]\n",
        "pl_presup_input_model = pl_presup_entry_model.iloc[:,0:-2]\n",
        "print(\"Data prepared to use in model. Run cell \\\"Model test\\\"\")"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data prepared to use in model. Run cell \"Model test\"\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "szps8k5yvP2F",
        "colab_type": "text"
      },
      "source": [
        "## Model test "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zey8w5GbvRQd",
        "colab_type": "code",
        "outputId": "71200a20-808e-417d-8a92-65f0db4def23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "eng_prediction = feature_model_eng.predict_classes(eng_input_model)\n",
        "pl_prediction = feature_model_pl.predict_classes(pl_input_model)\n",
        "pl_presup_prediction = feature_model_pl_presup.predict_classes(pl_presup_input_model)\n",
        "\n",
        "# eng prediction\n",
        "if 0 in eng_prediction:\n",
        "  eng_prediction_class = \"?\"\n",
        "elif 1 in eng_prediction:\n",
        "  eng_prediction_class = \"C\"\n",
        "elif 2 in eng_prediction:\n",
        "  eng_prediction_class = \"E\"\n",
        "else:\n",
        "  eng_prediction_class = \"N\"\n",
        "\n",
        "# pl prediction\n",
        "if 0 in pl_prediction:\n",
        "  pl_prediction_class = \"?\"\n",
        "elif 1 in pl_prediction:\n",
        "  pl_prediction_class = \"C\"\n",
        "elif 2 in pl_prediction:\n",
        "  pl_prediction_class = \"E\"\n",
        "else:\n",
        "  pl_prediction_class = \"N\"\n",
        "\n",
        "# pl presup prediction \n",
        "if 0 in pl_presup_prediction:\n",
        "  pl_presup_prediction_class = \"\\\"no\\\"\"\n",
        "else:\n",
        "  pl_presup_prediction_class = \"\\\"yes\\\"\"\n",
        "\n",
        "\n",
        "print(\"Your predicted semantic relation class in english model is: {}\".format(eng_prediction_class))\n",
        "print(\"Your predicted semantic relation class in polish model is {}\".format(pl_prediction_class))\n",
        "print(\"Your predicted presupposition in polish model is {}\".format(pl_presup_prediction_class))"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Your predicted semantic relation class in english model is: E\n",
            "Your predicted semantic relation class in polish model is N\n",
            "Your predicted presupposition in polish model is \"no\"\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}