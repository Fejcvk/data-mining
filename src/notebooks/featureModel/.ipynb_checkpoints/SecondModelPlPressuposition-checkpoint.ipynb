{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i61b34AJ1zPY"
   },
   "source": [
    "# Second model presupposition - Polish Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 665
    },
    "colab_type": "code",
    "id": "QLg6EMKN2D0x",
    "outputId": "4b58d7ae-bd32-4ffb-a97d-c9b4d7c93f76"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a3/78/92cedda05552398352ed9784908b834ee32a0bd071a9b32de287327370b7/transformers-2.8.0-py3-none-any.whl (563kB)\n",
      "\u001b[K     |████████████████████████████████| 573kB 3.3MB/s \n",
      "\u001b[?25hCollecting sentencepiece\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/74/f4/2d5214cbf13d06e7cb2c20d84115ca25b53ea76fa1f0ade0e3c9749de214/sentencepiece-0.1.85-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
      "\u001b[K     |████████████████████████████████| 1.0MB 14.9MB/s \n",
      "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Collecting tokenizers==0.5.2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d1/3f/73c881ea4723e43c1e9acf317cf407fab3a278daab3a69c98dcac511c04f/tokenizers-0.5.2-cp36-cp36m-manylinux1_x86_64.whl (3.7MB)\n",
      "\u001b[K     |████████████████████████████████| 3.7MB 21.4MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/50/93509f906a40bffd7d175f97fd75ea328ad9bd91f48f59c4bd084c94a25e/sacremoses-0.0.41.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 48.7MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
      "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.40)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.40 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.40)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (0.15.2)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.40->boto3->transformers) (2.8.1)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.41-cp36-none-any.whl size=893334 sha256=92475016d1c85aa3e13560ab84502f54b3435880424e3e1092521e5428d3bfb0\n",
      "  Stored in directory: /root/.cache/pip/wheels/22/5a/d4/b020a81249de7dc63758a34222feaa668dbe8ebfe9170cc9b1\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: sentencepiece, tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.41 sentencepiece-0.1.85 tokenizers-0.5.2 transformers-2.8.0\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install -q pyyaml h5py\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Qr2zJmEf2Eh3"
   },
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vLXojV3K5Y1U"
   },
   "source": [
    "*   Reading data\n",
    "*   Change columns names\n",
    "*   Drop NaN rows\n",
    "*   Fill others NaN values by special sign"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "j--zuCZf2HvJ",
    "outputId": "3fbd6e00-ca80-40b9-f708-c5fee3e3db49"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_of_sentence</th>\n",
       "      <th>verb_main_semantic_class</th>\n",
       "      <th>verb_second_semantic_class</th>\n",
       "      <th>verb_third_semantic_class</th>\n",
       "      <th>verb_veridical_positive</th>\n",
       "      <th>verb_veridical_negative</th>\n",
       "      <th>verb_tense</th>\n",
       "      <th>t_negation</th>\n",
       "      <th>presupposition</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eliptyczne</td>\n",
       "      <td>mówienia</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>o?</td>\n",
       "      <td>?</td>\n",
       "      <td>brak</td>\n",
       "      <td>0</td>\n",
       "      <td>nie dotyczy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>eliptyczne</td>\n",
       "      <td>epistemiczny</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>past</td>\n",
       "      <td>0</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eliptyczne</td>\n",
       "      <td>mówienia</td>\n",
       "      <td>none</td>\n",
       "      <td>none</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>past</td>\n",
       "      <td>0</td>\n",
       "      <td>nie dotyczy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>epistemiczny</td>\n",
       "      <td>percepcyjny</td>\n",
       "      <td>none</td>\n",
       "      <td>\"+\"</td>\n",
       "      <td>\"+\"</td>\n",
       "      <td>past</td>\n",
       "      <td>0</td>\n",
       "      <td>nie dotyczy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>epistemiczny</td>\n",
       "      <td>percepcyjny</td>\n",
       "      <td>none</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>present</td>\n",
       "      <td>0</td>\n",
       "      <td>nie dotyczy</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  type_of_sentence verb_main_semantic_class  ... t_negation presupposition\n",
       "0       eliptyczne                 mówienia  ...          0    nie dotyczy\n",
       "1       eliptyczne             epistemiczny  ...          0             no\n",
       "2       eliptyczne                 mówienia  ...          0    nie dotyczy\n",
       "3                1             epistemiczny  ...          0    nie dotyczy\n",
       "4                1             epistemiczny  ...          0    nie dotyczy\n",
       "\n",
       "[5 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_excel('polishOriginalDataset.xlsx')\n",
    "df.reset_index()\n",
    "df = df.iloc[:,[6,8,9,10,15,16,19,21,23]]\n",
    "df.columns = [\n",
    "              \"type_of_sentence\",\n",
    "              \"verb_main_semantic_class\",\n",
    "              \"verb_second_semantic_class\",\n",
    "              \"verb_third_semantic_class\",\n",
    "              \"verb_veridical_positive\",\n",
    "              \"verb_veridical_negative\",\n",
    "              \"verb_tense\",\n",
    "              \"t_negation\",\n",
    "              \"presupposition\"\n",
    "              ]\n",
    "df.dropna(inplace=True, axis = 0, how = 'all')\n",
    "df.fillna(axis = 0, inplace =True, value=\"none\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fTXvttwo5v0D"
   },
   "source": [
    "### Cleaning data by deleting uncertainty - simplification "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ewr4Z-ZH8e6Q",
    "outputId": "8c94c188-d499-429e-ceae-b719e740ae85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df.type_of_sentence.unique() cleaning not needed \n",
    "# df.verb_main_semantic_class.unique() cleaning not needed\n",
    "# df.verb_second_semantic_class.unique() cleaning not needed \n",
    "# df.verb_third_semantic_class.unique() cleaning not needed\n",
    "\n",
    "# verb veridical positive cleaning\n",
    "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '+' if '+' in x else x)\n",
    "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '-' if '-' in x else x)\n",
    "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: 'o' if 'o' in x else x)\n",
    "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '?' if '?' in x else x)\n",
    "\n",
    "# verb veridical negative cleaning\n",
    "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '+' if '+' in x else x)\n",
    "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: 'o' if 'o' in x else x)\n",
    "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '-' if '-' in x else x)\n",
    "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '?' if '?' in x else x)\n",
    "\n",
    "# df.verb_tense.unique() cleaning not needed\n",
    "# df.t_negation.unique() cleaning not needed\n",
    "# df.semantic_relation.unique() cleaning not needed \n",
    "\n",
    "df = df[df[\"presupposition\"] != \"nie dotyczy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d0yf4jWrgB4D"
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"plDataPresup.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Eq5Zke-TO3zd"
   },
   "source": [
    "#### Possible feature values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 238
    },
    "colab_type": "code",
    "id": "FVbjgIUMOXXi",
    "outputId": "c538a64e-0fa7-4446-efee-e4cdd1368764"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['eliptyczne' 1 'modalne' 'powinnościowe' 'none' '?' 'warunkowe; pytajne'\n",
      " 'performatyw' 'imperatyw' 'pytajne' 'wolitywne' 'warunkowe; modalne'\n",
      " 'generalne' 'modalne; pytajne' 'imperatyw ' 'warunkowe']\n",
      "['epistemiczny' 'percepcyjny' 'emotywny' '?' 'zdarzeniowy' 'mówienia'\n",
      " 'czynnościowy' 'przyczynowy' 'dowodzenia' 'odkrycia' 'pamięciowy'\n",
      " 'wnioskowania']\n",
      "['none' 'percepcyjny' 'epistemiczny' 'emotywny' 'wolicjonalny'\n",
      " 'wnioskowania' 'pamięciowy' 'zdarzeniowy' 'mówienia']\n",
      "['none' 'mówienia' 'epistemiczny' 'percepcyjny']\n",
      "['?' 'o' '+' '-']\n",
      "['?' 'o' '+' '-']\n",
      "['past' 'brak' 'present' 'future']\n",
      "[0 1]\n"
     ]
    }
   ],
   "source": [
    "print(df.type_of_sentence.unique())\n",
    "print(df.verb_main_semantic_class.unique())\n",
    "print(df.verb_second_semantic_class.unique())\n",
    "print(df.verb_third_semantic_class.unique())\n",
    "print(df.verb_veridical_positive.unique())\n",
    "print(df.verb_veridical_negative.unique())\n",
    "print(df.verb_tense.unique())\n",
    "print(df.t_negation.unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MIX0AGcQkGG5"
   },
   "source": [
    "### vectorize data and split to features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 234
    },
    "colab_type": "code",
    "id": "5r7NRdcwkIX5",
    "outputId": "42670109-db50-41d7-b587-6ec519e36bda"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type_of_sentence_1</th>\n",
       "      <th>type_of_sentence_?</th>\n",
       "      <th>type_of_sentence_eliptyczne</th>\n",
       "      <th>type_of_sentence_generalne</th>\n",
       "      <th>type_of_sentence_imperatyw</th>\n",
       "      <th>type_of_sentence_imperatyw</th>\n",
       "      <th>type_of_sentence_modalne</th>\n",
       "      <th>type_of_sentence_modalne; pytajne</th>\n",
       "      <th>type_of_sentence_none</th>\n",
       "      <th>type_of_sentence_performatyw</th>\n",
       "      <th>type_of_sentence_powinnościowe</th>\n",
       "      <th>type_of_sentence_pytajne</th>\n",
       "      <th>type_of_sentence_warunkowe</th>\n",
       "      <th>type_of_sentence_warunkowe; modalne</th>\n",
       "      <th>type_of_sentence_warunkowe; pytajne</th>\n",
       "      <th>type_of_sentence_wolitywne</th>\n",
       "      <th>verb_main_semantic_class_?</th>\n",
       "      <th>verb_main_semantic_class_czynnościowy</th>\n",
       "      <th>verb_main_semantic_class_dowodzenia</th>\n",
       "      <th>verb_main_semantic_class_emotywny</th>\n",
       "      <th>verb_main_semantic_class_epistemiczny</th>\n",
       "      <th>verb_main_semantic_class_mówienia</th>\n",
       "      <th>verb_main_semantic_class_odkrycia</th>\n",
       "      <th>verb_main_semantic_class_pamięciowy</th>\n",
       "      <th>verb_main_semantic_class_percepcyjny</th>\n",
       "      <th>verb_main_semantic_class_przyczynowy</th>\n",
       "      <th>verb_main_semantic_class_wnioskowania</th>\n",
       "      <th>verb_main_semantic_class_zdarzeniowy</th>\n",
       "      <th>verb_second_semantic_class_emotywny</th>\n",
       "      <th>verb_second_semantic_class_epistemiczny</th>\n",
       "      <th>verb_second_semantic_class_mówienia</th>\n",
       "      <th>verb_second_semantic_class_none</th>\n",
       "      <th>verb_second_semantic_class_pamięciowy</th>\n",
       "      <th>verb_second_semantic_class_percepcyjny</th>\n",
       "      <th>verb_second_semantic_class_wnioskowania</th>\n",
       "      <th>verb_second_semantic_class_wolicjonalny</th>\n",
       "      <th>verb_second_semantic_class_zdarzeniowy</th>\n",
       "      <th>verb_third_semantic_class_epistemiczny</th>\n",
       "      <th>verb_third_semantic_class_mówienia</th>\n",
       "      <th>verb_third_semantic_class_none</th>\n",
       "      <th>verb_third_semantic_class_percepcyjny</th>\n",
       "      <th>verb_veridical_positive_+</th>\n",
       "      <th>verb_veridical_positive_-</th>\n",
       "      <th>verb_veridical_positive_?</th>\n",
       "      <th>verb_veridical_positive_o</th>\n",
       "      <th>verb_veridical_negative_+</th>\n",
       "      <th>verb_veridical_negative_-</th>\n",
       "      <th>verb_veridical_negative_?</th>\n",
       "      <th>verb_veridical_negative_o</th>\n",
       "      <th>verb_tense_brak</th>\n",
       "      <th>verb_tense_future</th>\n",
       "      <th>verb_tense_past</th>\n",
       "      <th>verb_tense_present</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    type_of_sentence_1  type_of_sentence_?  ...  verb_tense_past  verb_tense_present\n",
       "1                    0                   0  ...                1                   0\n",
       "6                    1                   0  ...                1                   0\n",
       "19                   1                   0  ...                1                   0\n",
       "20                   1                   0  ...                1                   0\n",
       "35                   1                   0  ...                0                   0\n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.get_dummies(df)\n",
    "\n",
    "X_train = df.iloc[:,1:-2]\n",
    "y_train = df.iloc[:,-2:]\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 197
    },
    "colab_type": "code",
    "id": "ZCoFLf-U9HHm",
    "outputId": "cba11965-2112-40c8-d985-b8dae10d54ff"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>presupposition_no</th>\n",
       "      <th>presupposition_yes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    presupposition_no  presupposition_yes\n",
       "1                   1                   0\n",
       "6                   0                   1\n",
       "19                  0                   1\n",
       "20                  0                   1\n",
       "35                  0                   1"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "9Xi8QfyAkbiN"
   },
   "source": [
    "***\n",
    "# Keras model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "amhvtjnZQwhz"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "colab_type": "code",
    "id": "YQA-dmJ5RL9y",
    "outputId": "6334c104-153c-47d8-a73c-bf8245ba40bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model input size 53\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 250)               13500     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               125500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1000)              501000    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 500)               500500    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 275)               137775    \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 150)               41400     \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 25)                3775      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 52        \n",
      "=================================================================\n",
      "Total params: 1,323,502\n",
      "Trainable params: 1,323,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "\n",
    "#get number of columns in training data\n",
    "n_cols = X_train.shape[1]\n",
    "print(\"Model input size {}\".format(n_cols))\n",
    "#add model layers\n",
    "model.add(Dense(250, activation=keras.layers.LeakyReLU(alpha=0.9), input_shape=(n_cols,)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(1000, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
    "model.add(Dense(500, activation='relu'))\n",
    "model.add(Dense(275, activation='selu'))\n",
    "model.add(Dense(150, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
    "model.add(Dense(25, activation=keras.layers.LeakyReLU(alpha=0.3)))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.0001)\n",
    "model.compile(optimizer = 'adam', loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xq3yIS2Kkh2r"
   },
   "source": [
    "## Training model on prepared data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "1gnjHDM5dJb_",
    "outputId": "6ce2eb37-ab37-4a37-8ba7-15103f168bef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "15/15 [==============================] - 1s 39ms/step - loss: 0.4853 - accuracy: 0.7538 - val_loss: 0.3389 - val_accuracy: 0.8497\n",
      "Epoch 2/30\n",
      "15/15 [==============================] - 0s 23ms/step - loss: 0.3175 - accuracy: 0.8627 - val_loss: 0.3521 - val_accuracy: 0.8725\n",
      "Epoch 3/30\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.3562 - accuracy: 0.8540 - val_loss: 0.3627 - val_accuracy: 0.8497\n",
      "Epoch 4/30\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.3131 - accuracy: 0.8693 - val_loss: 0.3915 - val_accuracy: 0.8758\n",
      "Epoch 5/30\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2702 - accuracy: 0.8911 - val_loss: 0.4222 - val_accuracy: 0.8431\n",
      "Epoch 6/30\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2454 - accuracy: 0.8932 - val_loss: 0.5913 - val_accuracy: 0.8366\n",
      "Epoch 7/30\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.2229 - accuracy: 0.8824 - val_loss: 0.5218 - val_accuracy: 0.8301\n",
      "Epoch 8/30\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.2212 - accuracy: 0.9085 - val_loss: 0.5955 - val_accuracy: 0.8301\n",
      "Epoch 9/30\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.1970 - accuracy: 0.8998 - val_loss: 0.5486 - val_accuracy: 0.8464\n",
      "Epoch 10/30\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.2111 - accuracy: 0.9020 - val_loss: 0.5969 - val_accuracy: 0.8268\n",
      "Epoch 11/30\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1889 - accuracy: 0.9107 - val_loss: 0.7453 - val_accuracy: 0.8333\n",
      "Epoch 12/30\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2035 - accuracy: 0.9129 - val_loss: 0.6942 - val_accuracy: 0.8333\n",
      "Epoch 13/30\n",
      "15/15 [==============================] - 0s 24ms/step - loss: 0.1925 - accuracy: 0.9129 - val_loss: 0.6096 - val_accuracy: 0.8301\n",
      "Epoch 14/30\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1915 - accuracy: 0.9085 - val_loss: 0.8126 - val_accuracy: 0.8268\n",
      "Epoch 15/30\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.2214 - accuracy: 0.9063 - val_loss: 0.7266 - val_accuracy: 0.8268\n",
      "Epoch 16/30\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.2013 - accuracy: 0.8998 - val_loss: 0.7308 - val_accuracy: 0.8333\n",
      "Epoch 17/30\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1826 - accuracy: 0.9129 - val_loss: 0.7983 - val_accuracy: 0.8366\n",
      "Epoch 18/30\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.1754 - accuracy: 0.9107 - val_loss: 0.8584 - val_accuracy: 0.8301\n",
      "Epoch 19/30\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.1803 - accuracy: 0.9172 - val_loss: 1.0086 - val_accuracy: 0.8235\n",
      "Epoch 20/30\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1768 - accuracy: 0.9172 - val_loss: 0.9956 - val_accuracy: 0.8301\n",
      "Epoch 21/30\n",
      "15/15 [==============================] - 0s 27ms/step - loss: 0.1863 - accuracy: 0.9172 - val_loss: 0.9166 - val_accuracy: 0.8301\n",
      "Epoch 22/30\n",
      "15/15 [==============================] - 0s 32ms/step - loss: 0.1653 - accuracy: 0.9150 - val_loss: 0.9017 - val_accuracy: 0.8301\n",
      "Epoch 23/30\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.1785 - accuracy: 0.9172 - val_loss: 0.9942 - val_accuracy: 0.8301\n",
      "Epoch 24/30\n",
      "15/15 [==============================] - 0s 30ms/step - loss: 0.1734 - accuracy: 0.9129 - val_loss: 1.0644 - val_accuracy: 0.8268\n",
      "Epoch 25/30\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.1677 - accuracy: 0.9172 - val_loss: 1.0554 - val_accuracy: 0.8301\n",
      "Epoch 26/30\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1785 - accuracy: 0.9194 - val_loss: 1.0474 - val_accuracy: 0.8268\n",
      "Epoch 27/30\n",
      "15/15 [==============================] - 0s 29ms/step - loss: 0.1740 - accuracy: 0.9172 - val_loss: 1.1036 - val_accuracy: 0.8301\n",
      "Epoch 28/30\n",
      "15/15 [==============================] - 0s 28ms/step - loss: 0.1731 - accuracy: 0.9150 - val_loss: 1.0311 - val_accuracy: 0.8268\n",
      "Epoch 29/30\n",
      "15/15 [==============================] - 0s 25ms/step - loss: 0.1635 - accuracy: 0.9150 - val_loss: 0.9943 - val_accuracy: 0.8301\n",
      "Epoch 30/30\n",
      "15/15 [==============================] - 0s 26ms/step - loss: 0.1681 - accuracy: 0.9150 - val_loss: 1.1444 - val_accuracy: 0.8301\n"
     ]
    }
   ],
   "source": [
    "#train model\n",
    "history = model.fit(X_train, y_train, validation_split=0.4, epochs=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YQDKmJQ_kmdh"
   },
   "source": [
    "## plot with train and test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "id": "mi0f_JObgC4C",
    "outputId": "12c6e756-db0a-45e5-f5aa-3a6a9cf38307"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light",
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylim(0,1)\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RwVgSUc6uC6Y"
   },
   "source": [
    "### Save model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Z2XZ1N0JuIop"
   },
   "outputs": [],
   "source": [
    "model.save('featureModelPlPresup.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SecondModelPlPressuposition.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
