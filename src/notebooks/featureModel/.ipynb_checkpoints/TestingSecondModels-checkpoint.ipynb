{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kri6U3txHmaY"
   },
   "source": [
    "# You can test model here "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SUdthTl_cq1a"
   },
   "source": [
    "Steps to use model! \n",
    "\n",
    "\n",
    "1.   Run \"Read libraries\" cell\n",
    "2.   Check you have models to read in your directory. (You should have featureModelEng.h5 and featureModelPl.h5 here) \n",
    "3.   Run \"Read models\" \n",
    "4.   Input data into an \"Input data\" cell and run it \n",
    "5.   Check you have engData.csv and plData.csv in your directory \n",
    "6.   Run \"Input data preprocess\" cell \n",
    "7.   Run \"Model test\" cell \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "nw2SUkIvIBP3"
   },
   "source": [
    "## Read libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QwHBIwzBIAoB"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dense\n",
    "import pandas as pd \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kjCWJkdjHrda"
   },
   "source": [
    "## Read models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "0rZLc6TQHtgd",
    "outputId": "e3a56297-2c4f-4401-9b9e-9b2d9ce4d9a1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model featureModelEng.h5 read successfully!\n",
      "Model featureModelPl.h5 read successfully!\n",
      "Model featureModelPl.h5 read successfully!\n"
     ]
    }
   ],
   "source": [
    "try: \n",
    "  feature_model_eng = tf.keras.models.load_model('featureModelEng.h5',custom_objects={'LeakyReLU': keras.layers.LeakyReLU })\n",
    "  print(\"Model featureModelEng.h5 read successfully!\")\n",
    "except: \n",
    "  print(\"Error occured during reading file!\")\n",
    "  print(\"Probably you don't have featureModelEng.h5 in your working directory!\\n\")\n",
    "try:\n",
    "  feature_model_pl = tf.keras.models.load_model('featureModelPl.h5', custom_objects={\"LeakyReLU\": keras.layers.LeakyReLU})\n",
    "  print(\"Model featureModelPl.h5 read successfully!\")\n",
    "except: \n",
    "  print(\"Error occured during reading file!\")\n",
    "  print(\"Probably you don't have featureModelPl.h5 in your working directory!\\n\")\n",
    "try:\n",
    "  feature_model_pl_presup = tf.keras.models.load_model('featureModelPlPresup.h5', custom_objects={\"LeakyReLU\": keras.layers.LeakyReLU})\n",
    "  print(\"Model featureModelPl.h5 read successfully!\")\n",
    "except: \n",
    "  print(\"Error occured during reading file!\")\n",
    "  print(\"Probably you don't have featureModelPlPresup.h5 in your working directory!\\n\")  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "MKXEa4gKLNdM"
   },
   "source": [
    "## Input data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CNoa00FsLQdb"
   },
   "source": [
    "### Model ENG "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BmoQ4__DLUZm"
   },
   "outputs": [],
   "source": [
    "eng_verb_veridical_positive       = \"\" # possible values (o, ?, +, -)\n",
    "eng_verb_veridical_negative       = \"\" # possible values (o, ?, +, -)\n",
    "eng_semantic_characteristic       = \"\" # possible values (epistemiczny, emotywny, mówienia, ontyczn, ...y)\n",
    "eng_standford_signature_for_that  = \"\" # possible values (o/o, none, nie ma, +/o, +/+, o/+)\n",
    "eng_standford_signature_for_to    = \"\" # possible values (none, o/o)\n",
    "eng_complementizer                = \"\" # possible values (that, to)\n",
    "eng_verb_tense                    = \"\" # possible values (present, past, none, future, ?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "soyw5MgRLSHd"
   },
   "source": [
    "### Model PL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qf-wBSniM-5_"
   },
   "outputs": [],
   "source": [
    "pl_type_of_sentence           = \"\" # possible values (eliptyczne, pytajne, modalne, ... , 1, ?)\n",
    "pl_verb_main_semantic_class   = \"\" # possible values (mówienia, epistemiczny, percepcyjny, ... , ?)\n",
    "pl_verb_second_semantic_class = \"\" # possible values (none <brak>,  percepcyjny, epistemiczny, ...)\n",
    "pl_verb_third_semantic_class  = \"\" # possible values (none <brak>, percepcyjny, epistemiczny, emotywny ...)\n",
    "pl_verb_veridical_positive    = \"\" # possible values (o, ?, +, -)\n",
    "pl_verb_veridical_negative    = \"\" # possible values (o, ?, +, -)\n",
    "pl_verb_tense                 = \"\" # possible values (brak, past, present, future)\n",
    "pl_t_negation                 = \"\" # possible values (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "XSxoRA8i9Qsn"
   },
   "source": [
    "### Model PL Presupposition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tJfe8YXK9Qs6"
   },
   "outputs": [],
   "source": [
    "pl_presup_type_of_sentence           = \"\" # possible values (eliptyczne, pytajne, modalne, ... , 1, ?)\n",
    "pl_presup_verb_main_semantic_class   = \"\" # possible values (mówienia, epistemiczny, percepcyjny, ... , ?)\n",
    "pl_presup_verb_second_semantic_class = \"\" # possible values (none <brak>,  percepcyjny, epistemiczny, ...)\n",
    "pl_presup_verb_third_semantic_class  = \"\" # possible values (none <brak>, percepcyjny, epistemiczny, emotywny ...)\n",
    "pl_presup_verb_veridical_positive    = \"\" # possible values (o, ?, +, -)\n",
    "pl_presup_verb_veridical_negative    = \"\" # possible values (o, ?, +, -)\n",
    "pl_presup_verb_tense                 = \"\" # possible values (brak, past, present, future)\n",
    "pl_presup_t_negation                 = \"\" # possible values (0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a3uUV9zaVr0I"
   },
   "source": [
    "## Preprocess input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "s-EsnuR7bPDt",
    "outputId": "4b16ba84-1b76-438b-fc65-c43a56befe8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data prepared to use in model. Run cell \"Model test\"\n"
     ]
    }
   ],
   "source": [
    "training_eng_data = pd.read_csv(\"engData.csv\", index_col=None)\n",
    "training_pl_data = pd.read_csv(\"plData.csv\", index_col=None)\n",
    "training_pl_presup_data = pd.read_csv(\"plDataPresup.csv\", index_col=None)\n",
    "\n",
    "#Check values \n",
    "# eng \n",
    "if eng_verb_veridical_positive not in training_eng_data.verb_veridial_positive.unique():\n",
    "  eng_verb_veridical_positive = \"?\"\n",
    "if eng_verb_veridical_negative not in training_eng_data.verb_veridical_negative.unique():\n",
    "  eng_verb_veridical_negative = \"?\"\n",
    "if eng_semantic_characteristic not in training_eng_data.semantic_characteristic.unique():\n",
    "  eng_semantic_characteristic = \"epistemiczny\"\n",
    "if eng_standford_signature_for_that not in training_eng_data.standford_signature_for_that.unique():\n",
    "  eng_standford_signature_for_that = \"none\"\n",
    "if eng_standford_signature_for_to  not in training_eng_data.standford_signature_for_to.unique():\n",
    "  eng_standford_signature_for_to = \"none\"\n",
    "if eng_complementizer  not in training_eng_data.complementizer.unique():\n",
    "  eng_complementizer = \"that\"\n",
    "if eng_verb_tense not in training_eng_data.verb_tense.unique():\n",
    "  eng_verb_tense = \"none\"\n",
    "\n",
    "# pl \n",
    "if pl_type_of_sentence not in training_pl_data.type_of_sentence.unique():\n",
    "  pl_type_of_sentence = \"?\"\n",
    "if pl_verb_main_semantic_class not in training_pl_data.verb_main_semantic_class.unique():\n",
    "  pl_verb_main_semantic_class = \"?\"\n",
    "if pl_verb_second_semantic_class not in training_pl_data.verb_second_semantic_class.unique():\n",
    "  pl_verb_second_semantic_class = \"none\"\n",
    "if pl_verb_third_semantic_class not in training_pl_data.verb_third_semantic_class.unique():\n",
    "  pl_verb_third_semantic_class = \"none\"\n",
    "if pl_verb_veridical_positive not in training_pl_data.verb_veridical_positive.unique():\n",
    "  pl_verb_veridical_positive = \"?\"\n",
    "if pl_verb_veridical_negative not in training_pl_data.verb_veridical_negative.unique():\n",
    "  pl_verb_veridical_negative = \"?\"\n",
    "if pl_verb_tense not in training_pl_data.verb_tense.unique():\n",
    "  pl_verb_tense = \"brak\"\n",
    "try:\n",
    "  if int(pl_t_negation) not in training_pl_data.t_negation.unique():\n",
    "    pl_t_negation = 0\n",
    "except:\n",
    "  pl_t_negation = 0\n",
    "\n",
    "# pl presup \n",
    "if pl_presup_type_of_sentence not in training_pl_presup_data.type_of_sentence.unique():\n",
    "  pl_presup_type_of_sentence = \"?\"\n",
    "if pl_presup_verb_main_semantic_class not in training_pl_presup_data.verb_main_semantic_class.unique():\n",
    "  pl_presup_verb_main_semantic_class = \"?\"\n",
    "if pl_presup_verb_second_semantic_class not in training_pl_presup_data.verb_second_semantic_class.unique():\n",
    "  pl_presup_verb_second_semantic_class = \"none\"\n",
    "if pl_presup_verb_third_semantic_class not in training_pl_presup_data.verb_third_semantic_class.unique():\n",
    "  pl_presup_verb_third_semantic_class = \"none\"\n",
    "if pl_presup_verb_veridical_positive not in training_pl_presup_data.verb_veridical_positive.unique():\n",
    "  pl_presup_verb_veridical_positive = \"?\"\n",
    "if pl_presup_verb_veridical_negative not in training_pl_presup_data.verb_veridical_negative.unique():\n",
    "  pl_presup_verb_veridical_negative = \"?\"\n",
    "if pl_presup_verb_tense not in training_pl_presup_data.verb_tense.unique():\n",
    "  pl_presup_verb_tense = \"brak\"\n",
    "try:\n",
    "  if int(pl_presup_t_negation) not in training_pl_presup_data.t_negation.unique():\n",
    "    pl_presup_t_negation = 0\n",
    "except:\n",
    "  pl_presup_t_negation = 0\n",
    "\n",
    "# append to datasets\n",
    "# eng\n",
    "training_eng_data = training_eng_data.append({\n",
    " 'verb_veridial_positive': eng_verb_veridical_positive,\n",
    " 'verb_veridical_negative': eng_verb_veridical_negative,\n",
    " 'semantic_characteristic': eng_semantic_characteristic,\n",
    " 'standford_signature_for_that': eng_standford_signature_for_that,\n",
    " 'standford_signature_for_to': eng_standford_signature_for_to,\n",
    " 'complementizer': eng_complementizer,\n",
    " 'verb_tense': eng_verb_tense,\n",
    " 'semantic_relation': \"?\"                                            \n",
    "},\n",
    "ignore_index=True)\n",
    "\n",
    "# pl\n",
    "training_pl_data = training_pl_data.append({\n",
    " 'type_of_sentence': pl_type_of_sentence,\n",
    " 'verb_main_semantic_class': pl_verb_main_semantic_class,\n",
    " 'verb_second_semantic_class': pl_verb_second_semantic_class,\n",
    " 'verb_third_semantic_class': pl_verb_third_semantic_class,\n",
    " 'verb_veridical_positive': pl_verb_veridical_positive,\n",
    " 'verb_veridical_negative': pl_verb_veridical_negative,\n",
    " 'verb_tense': pl_verb_tense,\n",
    " 't_negation': pl_t_negation,\n",
    " 'semantic_relation': \"?\"                                      \n",
    "},\n",
    "ignore_index=True)\n",
    "\n",
    "#pl presup\n",
    "training_pl_presup_data = training_pl_presup_data.append({\n",
    " 'type_of_sentence': pl_presup_type_of_sentence,\n",
    " 'verb_main_semantic_class': pl_presup_verb_main_semantic_class,\n",
    " 'verb_second_semantic_class': pl_presup_verb_second_semantic_class,\n",
    " 'verb_third_semantic_class': pl_presup_verb_third_semantic_class,\n",
    " 'verb_veridical_positive': pl_presup_verb_veridical_positive,\n",
    " 'verb_veridical_negative': pl_presup_verb_veridical_negative,\n",
    " 'verb_tense': pl_presup_verb_tense,\n",
    " 't_negation': pl_presup_t_negation,\n",
    " 'presupposition': \"no\"                                      \n",
    "},\n",
    "ignore_index=True)\n",
    "\n",
    "# vectorize\n",
    "eng_vectorized = pd.get_dummies(training_eng_data)\n",
    "pl_vectorized = pd.get_dummies(training_pl_data)\n",
    "pl_presup_vectorized = pd.get_dummies(training_pl_presup_data)\n",
    "\n",
    "# get only last row\n",
    "eng_entry_model = eng_vectorized.tail(1)\n",
    "pl_entry_model = pl_vectorized.tail(1)\n",
    "pl_presup_entry_model = pl_presup_vectorized.tail(1)\n",
    "\n",
    "# get features\n",
    "eng_input_model = eng_entry_model.iloc[:,1:-4] \n",
    "pl_input_model = pl_entry_model.iloc[:,1:-4]\n",
    "pl_presup_input_model = pl_presup_entry_model.iloc[:,1:-2]\n",
    "print(\"Data prepared to use in model. Run cell \\\"Model test\\\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "szps8k5yvP2F"
   },
   "source": [
    "## Model test "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "Zey8w5GbvRQd",
    "outputId": "7138b475-ec94-456e-a73e-ebc124012552"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Your predicted semantic relation class in english model is: E\n",
      "Your predicted semantic relation class in polish model is E\n",
      "Your predicted presupposition in polish model is \"no\"\n"
     ]
    }
   ],
   "source": [
    "eng_prediction = feature_model_eng.predict_classes(eng_input_model)\n",
    "pl_prediction = feature_model_pl.predict_classes(pl_input_model)\n",
    "pl_presup_prediction = feature_model_pl_presup.predict_classes(pl_presup_input_model)\n",
    "\n",
    "# eng prediction\n",
    "if 0 in eng_prediction:\n",
    "  eng_prediction_class = \"?\"\n",
    "elif 1 in eng_prediction:\n",
    "  eng_prediction_class = \"C\"\n",
    "elif 2 in eng_prediction:\n",
    "  eng_prediction_class = \"E\"\n",
    "else:\n",
    "  eng_prediction_class = \"N\"\n",
    "\n",
    "# pl prediction\n",
    "if 0 in pl_prediction:\n",
    "  pl_prediction_class = \"?\"\n",
    "elif 1 in pl_prediction:\n",
    "  pl_prediction_class = \"C\"\n",
    "elif 2 in pl_prediction:\n",
    "  pl_prediction_class = \"E\"\n",
    "else:\n",
    "  pl_prediction_class = \"N\"\n",
    "\n",
    "# pl presup prediction \n",
    "if 0 in pl_presup_prediction:\n",
    "  pl_presup_prediction_class = \"\\\"no\\\"\"\n",
    "else:\n",
    "  pl_presup_prediction_class = \"\\\"yes\\\"\"\n",
    "\n",
    "\n",
    "print(\"Your predicted semantic relation class in english model is: {}\".format(eng_prediction_class))\n",
    "print(\"Your predicted semantic relation class in polish model is {}\".format(pl_prediction_class))\n",
    "print(\"Your predicted presupposition in polish model is {}\".format(pl_presup_prediction_class))"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "TestingSecondModels.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
