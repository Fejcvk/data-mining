{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondModelPlPressuposition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i61b34AJ1zPY",
        "colab_type": "text"
      },
      "source": [
        "# Second model presupposition - Polish Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLg6EMKN2D0x",
        "colab_type": "code",
        "outputId": "c5fe06cc-c392-48cc-e7ef-6376fb348289",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 409
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install -q pyyaml h5py\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.8.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.46)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.41)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.46 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.46)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.46->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr2zJmEf2Eh3",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLXojV3K5Y1U",
        "colab_type": "text"
      },
      "source": [
        "*   Reading data\n",
        "*   Change columns names\n",
        "*   Drop NaN rows\n",
        "*   Fill others NaN values by special sign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j--zuCZf2HvJ",
        "colab_type": "code",
        "outputId": "b7930036-1b78-443c-e9b5-de4bbd36e4cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "df = pd.read_excel('polishOriginalDataset.xlsx')\n",
        "df.reset_index()\n",
        "df = df.iloc[:,[6,8,9,10,15,16,19,21,23]]\n",
        "df.columns = [\n",
        "              \"type_of_sentence\",\n",
        "              \"verb_main_semantic_class\",\n",
        "              \"verb_second_semantic_class\",\n",
        "              \"verb_third_semantic_class\",\n",
        "              \"verb_veridical_positive\",\n",
        "              \"verb_veridical_negative\",\n",
        "              \"verb_tense\",\n",
        "              \"t_negation\",\n",
        "              \"presupposition\"\n",
        "              ]\n",
        "df.dropna(inplace=True, axis = 0, how = 'all')\n",
        "df.fillna(axis = 0, inplace =True, value=\"none\")\n",
        "df.head()"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_of_sentence</th>\n",
              "      <th>verb_main_semantic_class</th>\n",
              "      <th>verb_second_semantic_class</th>\n",
              "      <th>verb_third_semantic_class</th>\n",
              "      <th>verb_veridical_positive</th>\n",
              "      <th>verb_veridical_negative</th>\n",
              "      <th>verb_tense</th>\n",
              "      <th>t_negation</th>\n",
              "      <th>presupposition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>mówienia</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>o?</td>\n",
              "      <td>?</td>\n",
              "      <td>brak</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>past</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>mówienia</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>past</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>percepcyjny</td>\n",
              "      <td>none</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>past</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>percepcyjny</td>\n",
              "      <td>none</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>present</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  type_of_sentence verb_main_semantic_class  ... t_negation presupposition\n",
              "0       eliptyczne                 mówienia  ...          0    nie dotyczy\n",
              "1       eliptyczne             epistemiczny  ...          0             no\n",
              "2       eliptyczne                 mówienia  ...          0    nie dotyczy\n",
              "3                1             epistemiczny  ...          0    nie dotyczy\n",
              "4                1             epistemiczny  ...          0    nie dotyczy\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTXvttwo5v0D",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning data by deleting uncertainty - simplification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewr4Z-ZH8e6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.type_of_sentence.unique() cleaning not needed \n",
        "\n",
        "# df.verb_main_semantic_class - only (epistemiczny, mówienia, ?)\n",
        "main_semantic_class_unique = df.verb_main_semantic_class.unique()\n",
        "main_semantic_class_unique = main_semantic_class_unique[main_semantic_class_unique != \"epistemiczny\"]\n",
        "main_semantic_class_unique = main_semantic_class_unique[main_semantic_class_unique != \"mówienia\"]\n",
        "df.verb_main_semantic_class = df.verb_main_semantic_class.apply(lambda x: '?' if x in main_semantic_class_unique else x )\n",
        "\n",
        "# df.verb_second_semantic_class.unique() cleaning not needed \n",
        "# df.verb_third_semantic_class.unique() cleaning not needed\n",
        "\n",
        "# verb veridical positive cleaning\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '+' if '+' in x else x)\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '-' if '-' in x else x)\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: 'o' if 'o' in x else x)\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '?' if '?' in x else x)\n",
        "\n",
        "# verb veridical negative cleaning\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '+' if '+' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: 'o' if 'o' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '-' if '-' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '?' if '?' in x else x)\n",
        "\n",
        "# df.verb_tense.unique() cleaning not needed\n",
        "# df.t_negation.unique() cleaning not needed\n",
        "# df.semantic_relation.unique() cleaning not needed \n",
        "\n",
        "df = df[df[\"presupposition\"] != \"nie dotyczy\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq5Zke-TO3zd",
        "colab_type": "text"
      },
      "source": [
        "#### Possible feature values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVbjgIUMOXXi",
        "colab_type": "code",
        "outputId": "d3822fb5-585d-423c-ff8c-04347f8e282a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(df.type_of_sentence.unique())\n",
        "print(df.verb_main_semantic_class.unique())\n",
        "print(df.verb_second_semantic_class.unique())\n",
        "print(df.verb_third_semantic_class.unique())\n",
        "print(df.verb_veridical_positive.unique())\n",
        "print(df.verb_veridical_negative.unique())\n",
        "print(df.verb_tense.unique())\n",
        "print(df.t_negation.unique())\n"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['eliptyczne' 1 'modalne' 'powinnościowe' 'none' '?' 'warunkowe; pytajne'\n",
            " 'performatyw' 'imperatyw' 'pytajne' 'wolitywne' 'warunkowe; modalne'\n",
            " 'generalne' 'modalne; pytajne' 'imperatyw ' 'warunkowe']\n",
            "['epistemiczny' '?' 'mówienia']\n",
            "['none' 'percepcyjny' 'epistemiczny' 'emotywny' 'wolicjonalny'\n",
            " 'wnioskowania' 'pamięciowy' 'zdarzeniowy' 'mówienia']\n",
            "['none' 'mówienia' 'epistemiczny' 'percepcyjny']\n",
            "['?' 'o' '+' '-']\n",
            "['?' 'o' '+' '-']\n",
            "['past' 'brak' 'present' 'future']\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0yf4jWrgB4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[[\n",
        "         \"verb_main_semantic_class\",\n",
        "         \"verb_veridical_positive\",\n",
        "         \"verb_veridical_negative\",\n",
        "         \"verb_tense\",\n",
        "         \"presupposition\"\n",
        "         ]]\n",
        "df.to_csv(\"plDataPresup.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mBdk6j7_tTV",
        "colab_type": "code",
        "outputId": "5513fda5-d289-4114-f313-cf89a4dac02f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['verb_main_semantic_class', 'verb_veridical_positive',\n",
              "       'verb_veridical_negative', 'verb_tense', 'presupposition'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOi5V_fDAJBS",
        "colab_type": "text"
      },
      "source": [
        "### Vactorize data and split to features and target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YokPfvoJxWoR",
        "colab_type": "text"
      },
      "source": [
        "#### Vectorize (one =hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7NRdcwkIX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.get_dummies(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9f1MRWJxhBA",
        "colab_type": "text"
      },
      "source": [
        "#### Split to features and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp6eOyEdxlMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,0:-2]\n",
        "y = df.iloc[:,-2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjQvT5PtxsFz",
        "colab_type": "text"
      },
      "source": [
        "#### Features columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLqFLidq0YLV",
        "colab_type": "code",
        "outputId": "7f536354-f610-4c73-8a02-029c641ec054",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X.columns"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['verb_main_semantic_class_?', 'verb_main_semantic_class_epistemiczny',\n",
              "       'verb_main_semantic_class_mówienia', 'verb_veridical_positive_+',\n",
              "       'verb_veridical_positive_-', 'verb_veridical_positive_?',\n",
              "       'verb_veridical_positive_o', 'verb_veridical_negative_+',\n",
              "       'verb_veridical_negative_-', 'verb_veridical_negative_?',\n",
              "       'verb_veridical_negative_o', 'verb_tense_brak', 'verb_tense_future',\n",
              "       'verb_tense_past', 'verb_tense_present'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4896Jynxyew",
        "colab_type": "text"
      },
      "source": [
        "#### Target columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxEJ6K-fxkTU",
        "colab_type": "code",
        "outputId": "cf6545b7-abb9-444d-85d8-ac326c3f414b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.columns"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['presupposition_no', 'presupposition_yes'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jmoU__ZsXtC",
        "colab_type": "text"
      },
      "source": [
        "## k-fold crossvalidation preparing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUp3OdBNsdn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k=7\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits = k, shuffle=True)\n",
        "\n",
        "acc_per_fold = []\n",
        "loss_per_fold = [] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xi8QfyAkbiN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Keras model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVN5IeMLEn4w",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amhvtjnZQwhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H15DIedMCgOC",
        "colab_type": "text"
      },
      "source": [
        "It takes only 1-2 minutes to train this model with 7-crossvalidation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ZB5xOvAZbu",
        "colab_type": "code",
        "outputId": "8b15fc33-d26d-46fc-85d7-1967cc4b4ef7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fold_no = 1 \n",
        "\n",
        "#get number of columns in training data\n",
        "n_cols = X.shape[1]\n",
        "print(n_cols)\n",
        "\n",
        "for train, test in kfold.split(X,y):\n",
        "  # FOLD PRINTOUT\n",
        "  print(100*'_')\n",
        "  print (f\"FOLD NO {fold_no} START\")  \n",
        "\n",
        "  # model architecture  \n",
        "  model = tf.keras.Sequential()\n",
        "  #add model layers\n",
        "  model.add(Dense(8, activation='relu', input_shape=(n_cols,)))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  # model compile \n",
        "  model.compile(optimizer = 'adam', loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
        "  \n",
        "  # training\n",
        "  history = model.fit(X.iloc[train], y.iloc[train], validation_split=0.2, epochs=70)\n",
        "\n",
        "  # scores \n",
        "  scores = model.evaluate(X.iloc[test], y.iloc[test], verbose=0)\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # iterator up\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 1 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6531 - accuracy: 0.6031 - val_loss: 0.6324 - val_accuracy: 0.8244\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6136 - accuracy: 0.7901 - val_loss: 0.5497 - val_accuracy: 0.9008\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5727 - accuracy: 0.8397 - val_loss: 0.5058 - val_accuracy: 0.9008\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5361 - accuracy: 0.8397 - val_loss: 0.4459 - val_accuracy: 0.9008\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4875 - accuracy: 0.8454 - val_loss: 0.3935 - val_accuracy: 0.9008\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4501 - accuracy: 0.8321 - val_loss: 0.3448 - val_accuracy: 0.9008\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4206 - accuracy: 0.8416 - val_loss: 0.3130 - val_accuracy: 0.9008\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4033 - accuracy: 0.8416 - val_loss: 0.3010 - val_accuracy: 0.9008\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3821 - accuracy: 0.8416 - val_loss: 0.2943 - val_accuracy: 0.8931\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3727 - accuracy: 0.8416 - val_loss: 0.2859 - val_accuracy: 0.8931\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8416 - val_loss: 0.2814 - val_accuracy: 0.8931\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8416 - val_loss: 0.2898 - val_accuracy: 0.8931\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3673 - accuracy: 0.8416 - val_loss: 0.2807 - val_accuracy: 0.8931\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8416 - val_loss: 0.2832 - val_accuracy: 0.8931\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3575 - accuracy: 0.8416 - val_loss: 0.2906 - val_accuracy: 0.8931\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8416 - val_loss: 0.2821 - val_accuracy: 0.8931\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3554 - accuracy: 0.8435 - val_loss: 0.2848 - val_accuracy: 0.8931\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3586 - accuracy: 0.8416 - val_loss: 0.2904 - val_accuracy: 0.8931\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3485 - accuracy: 0.8435 - val_loss: 0.2860 - val_accuracy: 0.8931\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3454 - accuracy: 0.8454 - val_loss: 0.2823 - val_accuracy: 0.8931\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8435 - val_loss: 0.2887 - val_accuracy: 0.8931\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3431 - accuracy: 0.8435 - val_loss: 0.2866 - val_accuracy: 0.8931\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3453 - accuracy: 0.8435 - val_loss: 0.2897 - val_accuracy: 0.8931\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8416 - val_loss: 0.2836 - val_accuracy: 0.9008\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8435 - val_loss: 0.2921 - val_accuracy: 0.8931\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3333 - accuracy: 0.8454 - val_loss: 0.2882 - val_accuracy: 0.8931\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3428 - accuracy: 0.8454 - val_loss: 0.2882 - val_accuracy: 0.8931\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8492 - val_loss: 0.2907 - val_accuracy: 0.8931\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8511 - val_loss: 0.2884 - val_accuracy: 0.8931\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8492 - val_loss: 0.2888 - val_accuracy: 0.9008\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8511 - val_loss: 0.2956 - val_accuracy: 0.8931\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8511 - val_loss: 0.2948 - val_accuracy: 0.8931\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3325 - accuracy: 0.8511 - val_loss: 0.2834 - val_accuracy: 0.9008\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8588 - val_loss: 0.2889 - val_accuracy: 0.9008\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3456 - accuracy: 0.8569 - val_loss: 0.2912 - val_accuracy: 0.9008\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3324 - accuracy: 0.8531 - val_loss: 0.2905 - val_accuracy: 0.9008\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8550 - val_loss: 0.2967 - val_accuracy: 0.8931\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8569 - val_loss: 0.2932 - val_accuracy: 0.9008\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3384 - accuracy: 0.8588 - val_loss: 0.2933 - val_accuracy: 0.9008\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8588 - val_loss: 0.2946 - val_accuracy: 0.9008\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8569 - val_loss: 0.2996 - val_accuracy: 0.9008\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3266 - accuracy: 0.8588 - val_loss: 0.2929 - val_accuracy: 0.9008\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3183 - accuracy: 0.8588 - val_loss: 0.2946 - val_accuracy: 0.9008\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8588 - val_loss: 0.2963 - val_accuracy: 0.9008\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3190 - accuracy: 0.8588 - val_loss: 0.2984 - val_accuracy: 0.9008\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8588 - val_loss: 0.2973 - val_accuracy: 0.9008\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8588 - val_loss: 0.2942 - val_accuracy: 0.9008\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3206 - accuracy: 0.8588 - val_loss: 0.2968 - val_accuracy: 0.9008\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8569 - val_loss: 0.2995 - val_accuracy: 0.9008\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.8588 - val_loss: 0.2960 - val_accuracy: 0.9008\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8588 - val_loss: 0.3003 - val_accuracy: 0.9008\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3183 - accuracy: 0.8607 - val_loss: 0.2987 - val_accuracy: 0.9008\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8607 - val_loss: 0.2972 - val_accuracy: 0.9008\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3114 - accuracy: 0.8607 - val_loss: 0.2960 - val_accuracy: 0.9008\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8607 - val_loss: 0.2960 - val_accuracy: 0.9008\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8664 - val_loss: 0.2990 - val_accuracy: 0.9008\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3177 - accuracy: 0.8607 - val_loss: 0.3007 - val_accuracy: 0.9008\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8626 - val_loss: 0.3005 - val_accuracy: 0.9008\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8607 - val_loss: 0.2987 - val_accuracy: 0.9008\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8569 - val_loss: 0.3025 - val_accuracy: 0.9008\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8607 - val_loss: 0.2964 - val_accuracy: 0.9008\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3171 - accuracy: 0.8607 - val_loss: 0.3015 - val_accuracy: 0.9008\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8607 - val_loss: 0.3006 - val_accuracy: 0.9008\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8569 - val_loss: 0.2999 - val_accuracy: 0.9008\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8511 - val_loss: 0.3003 - val_accuracy: 0.9008\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8607 - val_loss: 0.3019 - val_accuracy: 0.9008\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3225 - accuracy: 0.8569 - val_loss: 0.2983 - val_accuracy: 0.9008\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8607 - val_loss: 0.3008 - val_accuracy: 0.9008\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8588 - val_loss: 0.3044 - val_accuracy: 0.9008\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8626 - val_loss: 0.3004 - val_accuracy: 0.9008\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 2 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7298 - accuracy: 0.4141 - val_loss: 0.7478 - val_accuracy: 0.1221\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6977 - accuracy: 0.4523 - val_loss: 0.7005 - val_accuracy: 0.5649\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6823 - accuracy: 0.6107 - val_loss: 0.6813 - val_accuracy: 0.7557\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6733 - accuracy: 0.6489 - val_loss: 0.6650 - val_accuracy: 0.8550\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6618 - accuracy: 0.7424 - val_loss: 0.6440 - val_accuracy: 0.8550\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6503 - accuracy: 0.7576 - val_loss: 0.6228 - val_accuracy: 0.9084\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6299 - accuracy: 0.8015 - val_loss: 0.5866 - val_accuracy: 0.9084\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6043 - accuracy: 0.7500 - val_loss: 0.5331 - val_accuracy: 0.8855\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5745 - accuracy: 0.7958 - val_loss: 0.4889 - val_accuracy: 0.9084\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5387 - accuracy: 0.8073 - val_loss: 0.4256 - val_accuracy: 0.9160\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5026 - accuracy: 0.8092 - val_loss: 0.3678 - val_accuracy: 0.9160\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4674 - accuracy: 0.8073 - val_loss: 0.3187 - val_accuracy: 0.9160\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4389 - accuracy: 0.8034 - val_loss: 0.2922 - val_accuracy: 0.9160\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4262 - accuracy: 0.7996 - val_loss: 0.2697 - val_accuracy: 0.9160\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8092 - val_loss: 0.2647 - val_accuracy: 0.9160\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3932 - accuracy: 0.8111 - val_loss: 0.2556 - val_accuracy: 0.9160\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8168 - val_loss: 0.2547 - val_accuracy: 0.9160\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3859 - accuracy: 0.8206 - val_loss: 0.2490 - val_accuracy: 0.9160\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3665 - accuracy: 0.8225 - val_loss: 0.2511 - val_accuracy: 0.9160\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3674 - accuracy: 0.8378 - val_loss: 0.2493 - val_accuracy: 0.9160\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3694 - accuracy: 0.8378 - val_loss: 0.2482 - val_accuracy: 0.9160\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3510 - accuracy: 0.8378 - val_loss: 0.2481 - val_accuracy: 0.9160\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3664 - accuracy: 0.8435 - val_loss: 0.2463 - val_accuracy: 0.9160\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8435 - val_loss: 0.2470 - val_accuracy: 0.9160\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8435 - val_loss: 0.2470 - val_accuracy: 0.9160\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3619 - accuracy: 0.8435 - val_loss: 0.2455 - val_accuracy: 0.9160\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8435 - val_loss: 0.2446 - val_accuracy: 0.9160\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8435 - val_loss: 0.2445 - val_accuracy: 0.9160\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3392 - accuracy: 0.8435 - val_loss: 0.2446 - val_accuracy: 0.9160\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3390 - accuracy: 0.8435 - val_loss: 0.2475 - val_accuracy: 0.9008\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3412 - accuracy: 0.8397 - val_loss: 0.2425 - val_accuracy: 0.9160\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8454 - val_loss: 0.2474 - val_accuracy: 0.9008\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8454 - val_loss: 0.2449 - val_accuracy: 0.9008\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8435 - val_loss: 0.2453 - val_accuracy: 0.9008\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8473 - val_loss: 0.2453 - val_accuracy: 0.9008\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8435 - val_loss: 0.2463 - val_accuracy: 0.9008\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8435 - val_loss: 0.2439 - val_accuracy: 0.9008\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3365 - accuracy: 0.8435 - val_loss: 0.2474 - val_accuracy: 0.9008\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3527 - accuracy: 0.8454 - val_loss: 0.2492 - val_accuracy: 0.9008\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3312 - accuracy: 0.8531 - val_loss: 0.2447 - val_accuracy: 0.9008\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8550 - val_loss: 0.2464 - val_accuracy: 0.9008\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8550 - val_loss: 0.2480 - val_accuracy: 0.9008\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3214 - accuracy: 0.8511 - val_loss: 0.2473 - val_accuracy: 0.9008\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8550 - val_loss: 0.2445 - val_accuracy: 0.9008\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3408 - accuracy: 0.8416 - val_loss: 0.2489 - val_accuracy: 0.9008\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8550 - val_loss: 0.2484 - val_accuracy: 0.9008\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8550 - val_loss: 0.2460 - val_accuracy: 0.9008\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3265 - accuracy: 0.8550 - val_loss: 0.2502 - val_accuracy: 0.9008\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8569 - val_loss: 0.2491 - val_accuracy: 0.9008\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8550 - val_loss: 0.2499 - val_accuracy: 0.9008\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8531 - val_loss: 0.2476 - val_accuracy: 0.9008\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8569 - val_loss: 0.2480 - val_accuracy: 0.9008\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3204 - accuracy: 0.8569 - val_loss: 0.2517 - val_accuracy: 0.9008\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8569 - val_loss: 0.2496 - val_accuracy: 0.9008\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8569 - val_loss: 0.2519 - val_accuracy: 0.9008\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8550 - val_loss: 0.2486 - val_accuracy: 0.9008\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8569 - val_loss: 0.2516 - val_accuracy: 0.9008\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3180 - accuracy: 0.8569 - val_loss: 0.2528 - val_accuracy: 0.9008\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8569 - val_loss: 0.2486 - val_accuracy: 0.9008\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8550 - val_loss: 0.2517 - val_accuracy: 0.9008\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8550 - val_loss: 0.2538 - val_accuracy: 0.9008\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3163 - accuracy: 0.8569 - val_loss: 0.2514 - val_accuracy: 0.9008\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8569 - val_loss: 0.2541 - val_accuracy: 0.9008\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8550 - val_loss: 0.2493 - val_accuracy: 0.9008\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.8511 - val_loss: 0.2538 - val_accuracy: 0.9008\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8588 - val_loss: 0.2510 - val_accuracy: 0.9008\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8569 - val_loss: 0.2513 - val_accuracy: 0.9008\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8531 - val_loss: 0.2526 - val_accuracy: 0.9008\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8550 - val_loss: 0.2555 - val_accuracy: 0.9008\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8550 - val_loss: 0.2500 - val_accuracy: 0.9008\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 3 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.7367 - accuracy: 0.4370 - val_loss: 0.7391 - val_accuracy: 0.3409\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6782 - accuracy: 0.5363 - val_loss: 0.6041 - val_accuracy: 0.8712\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6476 - accuracy: 0.6336 - val_loss: 0.5382 - val_accuracy: 0.9167\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6296 - accuracy: 0.5821 - val_loss: 0.4967 - val_accuracy: 0.8939\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6103 - accuracy: 0.5782 - val_loss: 0.4596 - val_accuracy: 0.8939\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5884 - accuracy: 0.6355 - val_loss: 0.4235 - val_accuracy: 0.9167\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5597 - accuracy: 0.6813 - val_loss: 0.3955 - val_accuracy: 0.9242\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5312 - accuracy: 0.7595 - val_loss: 0.3539 - val_accuracy: 0.9167\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5041 - accuracy: 0.7863 - val_loss: 0.3136 - val_accuracy: 0.9015\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4772 - accuracy: 0.8111 - val_loss: 0.2838 - val_accuracy: 0.9015\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4549 - accuracy: 0.8053 - val_loss: 0.2633 - val_accuracy: 0.9015\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4303 - accuracy: 0.8340 - val_loss: 0.2523 - val_accuracy: 0.9015\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4096 - accuracy: 0.8359 - val_loss: 0.2508 - val_accuracy: 0.9015\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3901 - accuracy: 0.8378 - val_loss: 0.2488 - val_accuracy: 0.9015\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3834 - accuracy: 0.8378 - val_loss: 0.2514 - val_accuracy: 0.9015\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3741 - accuracy: 0.8321 - val_loss: 0.2501 - val_accuracy: 0.9015\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3755 - accuracy: 0.8340 - val_loss: 0.2507 - val_accuracy: 0.9015\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8435 - val_loss: 0.2540 - val_accuracy: 0.9015\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3563 - accuracy: 0.8435 - val_loss: 0.2551 - val_accuracy: 0.9015\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3663 - accuracy: 0.8435 - val_loss: 0.2551 - val_accuracy: 0.9015\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8435 - val_loss: 0.2580 - val_accuracy: 0.9015\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8435 - val_loss: 0.2610 - val_accuracy: 0.9015\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3538 - accuracy: 0.8435 - val_loss: 0.2554 - val_accuracy: 0.9015\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8416 - val_loss: 0.2587 - val_accuracy: 0.9015\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3480 - accuracy: 0.8435 - val_loss: 0.2608 - val_accuracy: 0.9015\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8435 - val_loss: 0.2612 - val_accuracy: 0.9015\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3470 - accuracy: 0.8416 - val_loss: 0.2617 - val_accuracy: 0.9015\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8473 - val_loss: 0.2650 - val_accuracy: 0.9015\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3407 - accuracy: 0.8416 - val_loss: 0.2633 - val_accuracy: 0.9015\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8454 - val_loss: 0.2623 - val_accuracy: 0.9015\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8378 - val_loss: 0.2606 - val_accuracy: 0.9015\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3474 - accuracy: 0.8416 - val_loss: 0.2601 - val_accuracy: 0.9015\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3411 - accuracy: 0.8416 - val_loss: 0.2598 - val_accuracy: 0.9015\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3378 - accuracy: 0.8473 - val_loss: 0.2580 - val_accuracy: 0.9015\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8435 - val_loss: 0.2624 - val_accuracy: 0.9015\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8454 - val_loss: 0.2596 - val_accuracy: 0.9015\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8454 - val_loss: 0.2630 - val_accuracy: 0.9015\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3329 - accuracy: 0.8435 - val_loss: 0.2600 - val_accuracy: 0.9015\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3295 - accuracy: 0.8492 - val_loss: 0.2544 - val_accuracy: 0.9015\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8473 - val_loss: 0.2577 - val_accuracy: 0.9015\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8511 - val_loss: 0.2594 - val_accuracy: 0.9015\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8416 - val_loss: 0.2626 - val_accuracy: 0.9015\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3297 - accuracy: 0.8511 - val_loss: 0.2552 - val_accuracy: 0.9015\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8473 - val_loss: 0.2601 - val_accuracy: 0.9015\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8511 - val_loss: 0.2563 - val_accuracy: 0.9015\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8511 - val_loss: 0.2567 - val_accuracy: 0.9015\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8511 - val_loss: 0.2557 - val_accuracy: 0.9015\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8511 - val_loss: 0.2585 - val_accuracy: 0.9015\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8454 - val_loss: 0.2612 - val_accuracy: 0.9015\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8511 - val_loss: 0.2546 - val_accuracy: 0.9015\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8511 - val_loss: 0.2550 - val_accuracy: 0.9015\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8511 - val_loss: 0.2560 - val_accuracy: 0.9015\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8511 - val_loss: 0.2570 - val_accuracy: 0.9015\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3259 - accuracy: 0.8550 - val_loss: 0.2586 - val_accuracy: 0.9015\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8550 - val_loss: 0.2591 - val_accuracy: 0.9015\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8550 - val_loss: 0.2581 - val_accuracy: 0.9015\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8511 - val_loss: 0.2552 - val_accuracy: 0.9015\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8550 - val_loss: 0.2605 - val_accuracy: 0.9015\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3196 - accuracy: 0.8550 - val_loss: 0.2570 - val_accuracy: 0.9015\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3311 - accuracy: 0.8531 - val_loss: 0.2607 - val_accuracy: 0.9015\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8550 - val_loss: 0.2551 - val_accuracy: 0.9015\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8550 - val_loss: 0.2564 - val_accuracy: 0.9015\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3214 - accuracy: 0.8607 - val_loss: 0.2604 - val_accuracy: 0.9015\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3291 - accuracy: 0.8588 - val_loss: 0.2600 - val_accuracy: 0.9015\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8588 - val_loss: 0.2584 - val_accuracy: 0.9015\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8588 - val_loss: 0.2561 - val_accuracy: 0.9015\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8588 - val_loss: 0.2586 - val_accuracy: 0.9015\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3176 - accuracy: 0.8588 - val_loss: 0.2589 - val_accuracy: 0.9015\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3174 - accuracy: 0.8550 - val_loss: 0.2613 - val_accuracy: 0.9015\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8588 - val_loss: 0.2588 - val_accuracy: 0.9015\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 4 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7362 - accuracy: 0.4198 - val_loss: 0.7668 - val_accuracy: 0.1212\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6922 - accuracy: 0.5363 - val_loss: 0.6835 - val_accuracy: 0.5227\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6621 - accuracy: 0.8168 - val_loss: 0.6256 - val_accuracy: 0.8939\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6326 - accuracy: 0.8435 - val_loss: 0.5877 - val_accuracy: 0.8939\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6013 - accuracy: 0.8244 - val_loss: 0.5470 - val_accuracy: 0.8939\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5596 - accuracy: 0.8168 - val_loss: 0.4998 - val_accuracy: 0.8939\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5105 - accuracy: 0.8168 - val_loss: 0.4489 - val_accuracy: 0.8939\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4705 - accuracy: 0.8187 - val_loss: 0.4009 - val_accuracy: 0.8939\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4246 - accuracy: 0.8149 - val_loss: 0.3628 - val_accuracy: 0.8939\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3999 - accuracy: 0.8244 - val_loss: 0.3330 - val_accuracy: 0.8939\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8378 - val_loss: 0.3144 - val_accuracy: 0.8939\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3591 - accuracy: 0.8473 - val_loss: 0.3127 - val_accuracy: 0.8939\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3503 - accuracy: 0.8531 - val_loss: 0.3120 - val_accuracy: 0.8939\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3440 - accuracy: 0.8531 - val_loss: 0.3096 - val_accuracy: 0.8939\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8569 - val_loss: 0.3120 - val_accuracy: 0.8939\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3292 - accuracy: 0.8645 - val_loss: 0.3125 - val_accuracy: 0.8939\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3228 - accuracy: 0.8645 - val_loss: 0.3072 - val_accuracy: 0.8939\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3226 - accuracy: 0.8607 - val_loss: 0.3082 - val_accuracy: 0.8939\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8645 - val_loss: 0.3095 - val_accuracy: 0.8939\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8664 - val_loss: 0.3055 - val_accuracy: 0.8939\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8664 - val_loss: 0.3041 - val_accuracy: 0.8939\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8626 - val_loss: 0.3116 - val_accuracy: 0.8939\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8626 - val_loss: 0.2957 - val_accuracy: 0.8939\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3124 - accuracy: 0.8626 - val_loss: 0.3010 - val_accuracy: 0.8939\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3072 - accuracy: 0.8664 - val_loss: 0.3045 - val_accuracy: 0.8939\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8626 - val_loss: 0.3009 - val_accuracy: 0.8939\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3065 - accuracy: 0.8664 - val_loss: 0.3029 - val_accuracy: 0.8939\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3060 - accuracy: 0.8683 - val_loss: 0.3023 - val_accuracy: 0.8939\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3129 - accuracy: 0.8721 - val_loss: 0.2996 - val_accuracy: 0.8939\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8702 - val_loss: 0.2990 - val_accuracy: 0.8939\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8664 - val_loss: 0.2953 - val_accuracy: 0.8939\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3137 - accuracy: 0.8664 - val_loss: 0.2970 - val_accuracy: 0.8939\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3064 - accuracy: 0.8760 - val_loss: 0.3004 - val_accuracy: 0.8939\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3092 - accuracy: 0.8740 - val_loss: 0.2974 - val_accuracy: 0.8939\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8683 - val_loss: 0.2891 - val_accuracy: 0.8939\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8740 - val_loss: 0.3041 - val_accuracy: 0.8939\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8779 - val_loss: 0.2914 - val_accuracy: 0.8939\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3191 - accuracy: 0.8721 - val_loss: 0.2921 - val_accuracy: 0.8939\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3014 - accuracy: 0.8760 - val_loss: 0.2979 - val_accuracy: 0.8939\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8760 - val_loss: 0.2913 - val_accuracy: 0.8939\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8760 - val_loss: 0.2930 - val_accuracy: 0.8939\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8779 - val_loss: 0.2940 - val_accuracy: 0.8939\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8740 - val_loss: 0.2915 - val_accuracy: 0.8939\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3024 - accuracy: 0.8702 - val_loss: 0.2919 - val_accuracy: 0.8939\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8779 - val_loss: 0.3014 - val_accuracy: 0.8939\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8779 - val_loss: 0.2905 - val_accuracy: 0.8939\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8779 - val_loss: 0.2945 - val_accuracy: 0.8939\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3030 - accuracy: 0.8779 - val_loss: 0.2913 - val_accuracy: 0.8939\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2998 - accuracy: 0.8760 - val_loss: 0.2958 - val_accuracy: 0.8939\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8798 - val_loss: 0.2895 - val_accuracy: 0.8939\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8798 - val_loss: 0.2964 - val_accuracy: 0.8939\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2947 - accuracy: 0.8798 - val_loss: 0.2869 - val_accuracy: 0.8939\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8779 - val_loss: 0.2891 - val_accuracy: 0.8939\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.8779 - val_loss: 0.2929 - val_accuracy: 0.8939\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8798 - val_loss: 0.2992 - val_accuracy: 0.8939\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3017 - accuracy: 0.8798 - val_loss: 0.2871 - val_accuracy: 0.8939\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8779 - val_loss: 0.2864 - val_accuracy: 0.8939\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.8760 - val_loss: 0.2930 - val_accuracy: 0.8939\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8779 - val_loss: 0.2922 - val_accuracy: 0.8939\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8779 - val_loss: 0.2970 - val_accuracy: 0.8939\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2891 - accuracy: 0.8779 - val_loss: 0.2891 - val_accuracy: 0.8939\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3156 - accuracy: 0.8779 - val_loss: 0.2922 - val_accuracy: 0.8939\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8798 - val_loss: 0.2911 - val_accuracy: 0.8939\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8798 - val_loss: 0.2905 - val_accuracy: 0.8939\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2953 - accuracy: 0.8798 - val_loss: 0.2880 - val_accuracy: 0.8939\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8798 - val_loss: 0.2927 - val_accuracy: 0.8939\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2896 - accuracy: 0.8798 - val_loss: 0.3006 - val_accuracy: 0.8939\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8779 - val_loss: 0.2916 - val_accuracy: 0.8939\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8760 - val_loss: 0.2883 - val_accuracy: 0.8939\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2877 - accuracy: 0.8798 - val_loss: 0.2957 - val_accuracy: 0.8939\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 5 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6927 - accuracy: 0.5935 - val_loss: 0.6320 - val_accuracy: 0.8864\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5954 - val_loss: 0.6128 - val_accuracy: 0.8864\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6528 - accuracy: 0.5954 - val_loss: 0.5904 - val_accuracy: 0.8864\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6398 - accuracy: 0.5954 - val_loss: 0.5628 - val_accuracy: 0.8864\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6375 - accuracy: 0.5954 - val_loss: 0.5300 - val_accuracy: 0.8864\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 17ms/step - loss: 0.6192 - accuracy: 0.5954 - val_loss: 0.5072 - val_accuracy: 0.8864\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5974 - accuracy: 0.5954 - val_loss: 0.4662 - val_accuracy: 0.8864\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5691 - accuracy: 0.5954 - val_loss: 0.4214 - val_accuracy: 0.8864\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5459 - accuracy: 0.6126 - val_loss: 0.3838 - val_accuracy: 0.8788\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5364 - accuracy: 0.7137 - val_loss: 0.3552 - val_accuracy: 0.8939\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5082 - accuracy: 0.8397 - val_loss: 0.3333 - val_accuracy: 0.8939\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5041 - accuracy: 0.8416 - val_loss: 0.3141 - val_accuracy: 0.8939\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4822 - accuracy: 0.8492 - val_loss: 0.3130 - val_accuracy: 0.8939\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4686 - accuracy: 0.8473 - val_loss: 0.3019 - val_accuracy: 0.8939\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4565 - accuracy: 0.8473 - val_loss: 0.2947 - val_accuracy: 0.8939\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4282 - accuracy: 0.8626 - val_loss: 0.2988 - val_accuracy: 0.8939\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8607 - val_loss: 0.2850 - val_accuracy: 0.8939\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4009 - accuracy: 0.8588 - val_loss: 0.2848 - val_accuracy: 0.8939\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3843 - accuracy: 0.8588 - val_loss: 0.2829 - val_accuracy: 0.8939\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3743 - accuracy: 0.8607 - val_loss: 0.2805 - val_accuracy: 0.8939\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3617 - accuracy: 0.8588 - val_loss: 0.2926 - val_accuracy: 0.8939\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3528 - accuracy: 0.8569 - val_loss: 0.2831 - val_accuracy: 0.8939\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8588 - val_loss: 0.2859 - val_accuracy: 0.8939\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3380 - accuracy: 0.8588 - val_loss: 0.2884 - val_accuracy: 0.8939\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3362 - accuracy: 0.8569 - val_loss: 0.2922 - val_accuracy: 0.8939\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3325 - accuracy: 0.8569 - val_loss: 0.2903 - val_accuracy: 0.8939\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3340 - accuracy: 0.8588 - val_loss: 0.2949 - val_accuracy: 0.8939\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3296 - accuracy: 0.8588 - val_loss: 0.2945 - val_accuracy: 0.8939\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8588 - val_loss: 0.2975 - val_accuracy: 0.8939\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8569 - val_loss: 0.2955 - val_accuracy: 0.8939\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3202 - accuracy: 0.8531 - val_loss: 0.2978 - val_accuracy: 0.8939\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8511 - val_loss: 0.2982 - val_accuracy: 0.8939\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8569 - val_loss: 0.3010 - val_accuracy: 0.8939\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3205 - accuracy: 0.8607 - val_loss: 0.3006 - val_accuracy: 0.8939\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8607 - val_loss: 0.3029 - val_accuracy: 0.8939\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8626 - val_loss: 0.3025 - val_accuracy: 0.8939\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8645 - val_loss: 0.3031 - val_accuracy: 0.8939\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3172 - accuracy: 0.8626 - val_loss: 0.3046 - val_accuracy: 0.8939\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3116 - accuracy: 0.8664 - val_loss: 0.3130 - val_accuracy: 0.8939\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3076 - accuracy: 0.8607 - val_loss: 0.3066 - val_accuracy: 0.8939\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.8664 - val_loss: 0.3121 - val_accuracy: 0.8939\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8626 - val_loss: 0.3087 - val_accuracy: 0.8939\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3063 - accuracy: 0.8645 - val_loss: 0.3122 - val_accuracy: 0.8939\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8645 - val_loss: 0.3094 - val_accuracy: 0.8939\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3025 - accuracy: 0.8645 - val_loss: 0.3145 - val_accuracy: 0.8939\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8626 - val_loss: 0.3114 - val_accuracy: 0.8939\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.8626 - val_loss: 0.3117 - val_accuracy: 0.8939\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3003 - accuracy: 0.8626 - val_loss: 0.3178 - val_accuracy: 0.8939\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8588 - val_loss: 0.3131 - val_accuracy: 0.8939\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3049 - accuracy: 0.8664 - val_loss: 0.3227 - val_accuracy: 0.8939\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8626 - val_loss: 0.3218 - val_accuracy: 0.8939\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3016 - accuracy: 0.8607 - val_loss: 0.3168 - val_accuracy: 0.8939\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8588 - val_loss: 0.3217 - val_accuracy: 0.8939\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2924 - accuracy: 0.8607 - val_loss: 0.3185 - val_accuracy: 0.8939\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2949 - accuracy: 0.8664 - val_loss: 0.3267 - val_accuracy: 0.8939\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2925 - accuracy: 0.8645 - val_loss: 0.3224 - val_accuracy: 0.8939\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8645 - val_loss: 0.3256 - val_accuracy: 0.8939\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8607 - val_loss: 0.3217 - val_accuracy: 0.8939\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.8607 - val_loss: 0.3251 - val_accuracy: 0.8939\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2919 - accuracy: 0.8645 - val_loss: 0.3242 - val_accuracy: 0.8939\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2951 - accuracy: 0.8645 - val_loss: 0.3242 - val_accuracy: 0.8939\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8645 - val_loss: 0.3258 - val_accuracy: 0.8939\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8645 - val_loss: 0.3241 - val_accuracy: 0.8939\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2862 - accuracy: 0.8683 - val_loss: 0.3304 - val_accuracy: 0.8939\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8626 - val_loss: 0.3276 - val_accuracy: 0.8939\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3058 - accuracy: 0.8664 - val_loss: 0.3322 - val_accuracy: 0.8939\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8607 - val_loss: 0.3299 - val_accuracy: 0.8939\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3053 - accuracy: 0.8607 - val_loss: 0.3293 - val_accuracy: 0.8939\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2935 - accuracy: 0.8626 - val_loss: 0.3376 - val_accuracy: 0.8939\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8664 - val_loss: 0.3338 - val_accuracy: 0.8939\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 6 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6871 - accuracy: 0.5172 - val_loss: 0.6627 - val_accuracy: 0.6818\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.6622 - val_loss: 0.6299 - val_accuracy: 0.9318\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6501 - accuracy: 0.6660 - val_loss: 0.5956 - val_accuracy: 0.9318\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6289 - accuracy: 0.6698 - val_loss: 0.5544 - val_accuracy: 0.9318\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6054 - accuracy: 0.7576 - val_loss: 0.5160 - val_accuracy: 0.9318\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5815 - accuracy: 0.7805 - val_loss: 0.4755 - val_accuracy: 0.9318\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5481 - accuracy: 0.8053 - val_loss: 0.4484 - val_accuracy: 0.9091\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.5212 - accuracy: 0.8321 - val_loss: 0.4084 - val_accuracy: 0.9091\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4801 - accuracy: 0.8340 - val_loss: 0.3755 - val_accuracy: 0.9091\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4567 - accuracy: 0.8340 - val_loss: 0.3446 - val_accuracy: 0.9091\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4289 - accuracy: 0.8321 - val_loss: 0.3203 - val_accuracy: 0.9091\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4147 - accuracy: 0.8263 - val_loss: 0.2929 - val_accuracy: 0.9091\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3985 - accuracy: 0.8302 - val_loss: 0.2883 - val_accuracy: 0.9091\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3919 - accuracy: 0.8321 - val_loss: 0.2667 - val_accuracy: 0.9318\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3863 - accuracy: 0.8359 - val_loss: 0.2685 - val_accuracy: 0.9318\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3698 - accuracy: 0.8359 - val_loss: 0.2622 - val_accuracy: 0.9318\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3658 - accuracy: 0.8340 - val_loss: 0.2567 - val_accuracy: 0.9318\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3601 - accuracy: 0.8321 - val_loss: 0.2566 - val_accuracy: 0.9318\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3580 - accuracy: 0.8321 - val_loss: 0.2502 - val_accuracy: 0.9318\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3626 - accuracy: 0.8378 - val_loss: 0.2488 - val_accuracy: 0.9318\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8225 - val_loss: 0.2432 - val_accuracy: 0.9318\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3490 - accuracy: 0.8397 - val_loss: 0.2547 - val_accuracy: 0.9318\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8416 - val_loss: 0.2371 - val_accuracy: 0.9318\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3634 - accuracy: 0.8302 - val_loss: 0.2397 - val_accuracy: 0.9318\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3491 - accuracy: 0.8397 - val_loss: 0.2413 - val_accuracy: 0.9318\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3561 - accuracy: 0.8397 - val_loss: 0.2387 - val_accuracy: 0.9318\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8321 - val_loss: 0.2389 - val_accuracy: 0.9318\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3388 - accuracy: 0.8397 - val_loss: 0.2395 - val_accuracy: 0.9318\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3404 - accuracy: 0.8321 - val_loss: 0.2346 - val_accuracy: 0.9318\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3330 - accuracy: 0.8397 - val_loss: 0.2374 - val_accuracy: 0.9318\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3298 - accuracy: 0.8359 - val_loss: 0.2414 - val_accuracy: 0.9318\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8454 - val_loss: 0.2311 - val_accuracy: 0.9318\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8397 - val_loss: 0.2412 - val_accuracy: 0.9318\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8435 - val_loss: 0.2329 - val_accuracy: 0.9318\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3231 - accuracy: 0.8473 - val_loss: 0.2326 - val_accuracy: 0.9318\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8416 - val_loss: 0.2330 - val_accuracy: 0.9318\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3279 - accuracy: 0.8454 - val_loss: 0.2383 - val_accuracy: 0.9318\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8473 - val_loss: 0.2407 - val_accuracy: 0.9318\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3289 - accuracy: 0.8435 - val_loss: 0.2317 - val_accuracy: 0.9318\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8454 - val_loss: 0.2318 - val_accuracy: 0.9318\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3169 - accuracy: 0.8321 - val_loss: 0.2380 - val_accuracy: 0.9318\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3199 - accuracy: 0.8492 - val_loss: 0.2347 - val_accuracy: 0.9318\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3238 - accuracy: 0.8416 - val_loss: 0.2292 - val_accuracy: 0.9318\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8492 - val_loss: 0.2408 - val_accuracy: 0.9318\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8531 - val_loss: 0.2322 - val_accuracy: 0.9318\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3168 - accuracy: 0.8511 - val_loss: 0.2286 - val_accuracy: 0.9318\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8531 - val_loss: 0.2318 - val_accuracy: 0.9318\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3203 - accuracy: 0.8550 - val_loss: 0.2342 - val_accuracy: 0.9318\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3123 - accuracy: 0.8511 - val_loss: 0.2366 - val_accuracy: 0.9318\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8550 - val_loss: 0.2370 - val_accuracy: 0.9318\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8473 - val_loss: 0.2346 - val_accuracy: 0.9318\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8569 - val_loss: 0.2305 - val_accuracy: 0.9318\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8645 - val_loss: 0.2396 - val_accuracy: 0.9318\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8550 - val_loss: 0.2348 - val_accuracy: 0.9318\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3143 - accuracy: 0.8454 - val_loss: 0.2367 - val_accuracy: 0.9318\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3186 - accuracy: 0.8569 - val_loss: 0.2370 - val_accuracy: 0.9318\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3144 - accuracy: 0.8569 - val_loss: 0.2348 - val_accuracy: 0.9318\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3167 - accuracy: 0.8569 - val_loss: 0.2371 - val_accuracy: 0.9318\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3160 - accuracy: 0.8492 - val_loss: 0.2373 - val_accuracy: 0.9318\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3170 - accuracy: 0.8588 - val_loss: 0.2385 - val_accuracy: 0.9318\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3136 - accuracy: 0.8550 - val_loss: 0.2401 - val_accuracy: 0.9318\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8531 - val_loss: 0.2390 - val_accuracy: 0.9318\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8550 - val_loss: 0.2341 - val_accuracy: 0.9318\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3095 - accuracy: 0.8588 - val_loss: 0.2388 - val_accuracy: 0.9318\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3112 - accuracy: 0.8569 - val_loss: 0.2365 - val_accuracy: 0.9318\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3212 - accuracy: 0.8626 - val_loss: 0.2386 - val_accuracy: 0.9318\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3112 - accuracy: 0.8588 - val_loss: 0.2405 - val_accuracy: 0.9318\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8607 - val_loss: 0.2341 - val_accuracy: 0.9318\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3129 - accuracy: 0.8588 - val_loss: 0.2352 - val_accuracy: 0.9318\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8626 - val_loss: 0.2425 - val_accuracy: 0.9318\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 7 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6611 - accuracy: 0.7061 - val_loss: 0.5860 - val_accuracy: 0.8561\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6351 - accuracy: 0.7252 - val_loss: 0.5287 - val_accuracy: 0.8561\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.7271 - val_loss: 0.4950 - val_accuracy: 0.8561\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5876 - accuracy: 0.7691 - val_loss: 0.4564 - val_accuracy: 0.9015\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5671 - accuracy: 0.7901 - val_loss: 0.4170 - val_accuracy: 0.9015\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5380 - accuracy: 0.7901 - val_loss: 0.3738 - val_accuracy: 0.9015\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5068 - accuracy: 0.7882 - val_loss: 0.3478 - val_accuracy: 0.9015\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4860 - accuracy: 0.7882 - val_loss: 0.3168 - val_accuracy: 0.8939\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4577 - accuracy: 0.7882 - val_loss: 0.2995 - val_accuracy: 0.8939\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4387 - accuracy: 0.7958 - val_loss: 0.2849 - val_accuracy: 0.8939\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4229 - accuracy: 0.7958 - val_loss: 0.2796 - val_accuracy: 0.8939\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4056 - accuracy: 0.7996 - val_loss: 0.2768 - val_accuracy: 0.8939\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4058 - accuracy: 0.7805 - val_loss: 0.2741 - val_accuracy: 0.8939\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.7844 - val_loss: 0.2760 - val_accuracy: 0.8939\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3851 - accuracy: 0.7882 - val_loss: 0.2734 - val_accuracy: 0.8939\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3866 - accuracy: 0.8073 - val_loss: 0.2785 - val_accuracy: 0.8939\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3812 - accuracy: 0.8282 - val_loss: 0.2767 - val_accuracy: 0.8939\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3797 - accuracy: 0.8282 - val_loss: 0.2805 - val_accuracy: 0.8939\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3872 - accuracy: 0.8282 - val_loss: 0.2819 - val_accuracy: 0.8939\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3763 - accuracy: 0.8282 - val_loss: 0.2816 - val_accuracy: 0.8939\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3773 - accuracy: 0.8302 - val_loss: 0.2833 - val_accuracy: 0.8939\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3740 - accuracy: 0.8263 - val_loss: 0.2834 - val_accuracy: 0.8939\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3648 - accuracy: 0.8244 - val_loss: 0.2870 - val_accuracy: 0.8939\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8397 - val_loss: 0.2806 - val_accuracy: 0.8939\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3621 - accuracy: 0.8397 - val_loss: 0.2849 - val_accuracy: 0.8939\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3716 - accuracy: 0.8397 - val_loss: 0.2889 - val_accuracy: 0.8939\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8435 - val_loss: 0.2921 - val_accuracy: 0.8939\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3689 - accuracy: 0.8397 - val_loss: 0.2912 - val_accuracy: 0.8939\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3557 - accuracy: 0.8397 - val_loss: 0.2904 - val_accuracy: 0.8939\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3535 - accuracy: 0.8397 - val_loss: 0.2909 - val_accuracy: 0.8939\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8454 - val_loss: 0.2931 - val_accuracy: 0.8939\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3603 - accuracy: 0.8454 - val_loss: 0.2938 - val_accuracy: 0.8939\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3516 - accuracy: 0.8416 - val_loss: 0.3016 - val_accuracy: 0.8939\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3469 - accuracy: 0.8454 - val_loss: 0.2991 - val_accuracy: 0.8939\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3436 - accuracy: 0.8454 - val_loss: 0.3007 - val_accuracy: 0.8939\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8435 - val_loss: 0.2999 - val_accuracy: 0.8939\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3460 - accuracy: 0.8454 - val_loss: 0.3011 - val_accuracy: 0.8939\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3526 - accuracy: 0.8454 - val_loss: 0.3056 - val_accuracy: 0.8939\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3393 - accuracy: 0.8454 - val_loss: 0.3039 - val_accuracy: 0.8939\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8435 - val_loss: 0.3033 - val_accuracy: 0.8939\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3365 - accuracy: 0.8435 - val_loss: 0.3083 - val_accuracy: 0.8939\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3367 - accuracy: 0.8473 - val_loss: 0.3061 - val_accuracy: 0.8939\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3372 - accuracy: 0.8531 - val_loss: 0.3047 - val_accuracy: 0.8939\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8531 - val_loss: 0.3113 - val_accuracy: 0.8939\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3530 - accuracy: 0.8531 - val_loss: 0.3151 - val_accuracy: 0.8939\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3348 - accuracy: 0.8550 - val_loss: 0.3104 - val_accuracy: 0.8939\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3349 - accuracy: 0.8435 - val_loss: 0.3125 - val_accuracy: 0.8939\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3313 - accuracy: 0.8569 - val_loss: 0.3103 - val_accuracy: 0.8939\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8569 - val_loss: 0.3163 - val_accuracy: 0.8939\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3267 - accuracy: 0.8588 - val_loss: 0.3132 - val_accuracy: 0.8939\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3239 - accuracy: 0.8588 - val_loss: 0.3195 - val_accuracy: 0.8939\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8588 - val_loss: 0.3218 - val_accuracy: 0.8939\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8588 - val_loss: 0.3183 - val_accuracy: 0.8939\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3234 - accuracy: 0.8588 - val_loss: 0.3273 - val_accuracy: 0.8939\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8588 - val_loss: 0.3332 - val_accuracy: 0.8939\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3256 - accuracy: 0.8569 - val_loss: 0.3239 - val_accuracy: 0.8939\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.8569 - val_loss: 0.3331 - val_accuracy: 0.8939\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8569 - val_loss: 0.3276 - val_accuracy: 0.8939\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8569 - val_loss: 0.3264 - val_accuracy: 0.8939\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3251 - accuracy: 0.8569 - val_loss: 0.3298 - val_accuracy: 0.8939\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8550 - val_loss: 0.3385 - val_accuracy: 0.8939\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.8569 - val_loss: 0.3290 - val_accuracy: 0.8939\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8569 - val_loss: 0.3352 - val_accuracy: 0.8939\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3133 - accuracy: 0.8531 - val_loss: 0.3334 - val_accuracy: 0.8939\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8569 - val_loss: 0.3421 - val_accuracy: 0.8939\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8550 - val_loss: 0.3442 - val_accuracy: 0.8939\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3128 - accuracy: 0.8588 - val_loss: 0.3323 - val_accuracy: 0.8939\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8531 - val_loss: 0.3453 - val_accuracy: 0.8939\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3260 - accuracy: 0.8588 - val_loss: 0.3399 - val_accuracy: 0.8939\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8588 - val_loss: 0.3475 - val_accuracy: 0.8939\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZF1RHlg1v3X",
        "colab_type": "text"
      },
      "source": [
        "### Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3V3QdWu0VG",
        "colab_type": "code",
        "outputId": "089b8123-e7b8-4498-938d-ad0edd65dd46",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# == Provide average scores ==\n",
        "print('Score per fold:')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score per fold:\n",
            "> Fold 1 - Loss: 0.26865407824516296 - Accuracy: 86.36363744735718%\n",
            "> Fold 2 - Loss: 0.35512107610702515 - Accuracy: 83.63636136054993%\n",
            "> Fold 3 - Loss: 0.3521234691143036 - Accuracy: 83.48624110221863%\n",
            "> Fold 4 - Loss: 0.4441664516925812 - Accuracy: 77.98165082931519%\n",
            "> Fold 5 - Loss: 0.3467918038368225 - Accuracy: 78.899085521698%\n",
            "> Fold 6 - Loss: 0.48996666073799133 - Accuracy: 80.73394298553467%\n",
            "> Fold 7 - Loss: 0.26631051301956177 - Accuracy: 89.90825414657593%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 83.00131048474994 (+- 3.9063272620950724)\n",
            "> Loss: 0.3604477218219212\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQDKmJQ_kmdh",
        "colab_type": "text"
      },
      "source": [
        "## plot with train and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi0f_JObgC4C",
        "colab_type": "code",
        "outputId": "57d9c5c2-70cd-4b8b-fa24-8f9c5608937a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim(0,1)\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "09d56c01-aa6e-452b-dbb6-dd47f546e867",
        "id": "MZqTTLklFGp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwVgSUc6uC6Y",
        "colab_type": "text"
      },
      "source": [
        "### Save model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2XZ1N0JuIop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('featureModelPlPresup.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}