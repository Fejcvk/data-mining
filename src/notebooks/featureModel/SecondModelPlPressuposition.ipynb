{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SecondModelPlPressuposition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i61b34AJ1zPY",
        "colab_type": "text"
      },
      "source": [
        "# Second model presupposition - Polish Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QLg6EMKN2D0x",
        "colab_type": "code",
        "outputId": "e3c8203a-7fba-40cf-c4f1-33dfb8de67b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 306
        }
      },
      "source": [
        "!pip install transformers\n",
        "!pip install -q pyyaml h5py\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.9.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tokenizers==0.7.0 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.86)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.4.5.1)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qr2zJmEf2Eh3",
        "colab_type": "text"
      },
      "source": [
        "## Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vLXojV3K5Y1U",
        "colab_type": "text"
      },
      "source": [
        "*   Reading data\n",
        "*   Change columns names\n",
        "*   Drop NaN rows\n",
        "*   Fill others NaN values by special sign"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j--zuCZf2HvJ",
        "colab_type": "code",
        "outputId": "1039fe9b-5de9-4858-87d9-4ce706e0c40e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df = pd.read_excel('polishOriginalDataset.xlsx')\n",
        "df.reset_index()\n",
        "df = df.iloc[:,[6,8,9,10,15,16,19,21,23]]\n",
        "df.columns = [\n",
        "              \"type_of_sentence\",\n",
        "              \"verb_main_semantic_class\",\n",
        "              \"verb_second_semantic_class\",\n",
        "              \"verb_third_semantic_class\",\n",
        "              \"verb_veridical_positive\",\n",
        "              \"verb_veridical_negative\",\n",
        "              \"verb_tense\",\n",
        "              \"t_negation\",\n",
        "              \"presupposition\"\n",
        "              ]\n",
        "df.dropna(inplace=True, axis = 0, how = 'all')\n",
        "df.fillna(axis = 0, inplace =True, value=\"none\")\n",
        "df.head()"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>type_of_sentence</th>\n",
              "      <th>verb_main_semantic_class</th>\n",
              "      <th>verb_second_semantic_class</th>\n",
              "      <th>verb_third_semantic_class</th>\n",
              "      <th>verb_veridical_positive</th>\n",
              "      <th>verb_veridical_negative</th>\n",
              "      <th>verb_tense</th>\n",
              "      <th>t_negation</th>\n",
              "      <th>presupposition</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>mówienia</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>o?</td>\n",
              "      <td>?</td>\n",
              "      <td>brak</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>past</td>\n",
              "      <td>0</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>mówienia</td>\n",
              "      <td>none</td>\n",
              "      <td>none</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>past</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>percepcyjny</td>\n",
              "      <td>none</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>past</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>percepcyjny</td>\n",
              "      <td>none</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>present</td>\n",
              "      <td>0</td>\n",
              "      <td>nie dotyczy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  type_of_sentence verb_main_semantic_class  ... t_negation presupposition\n",
              "0       eliptyczne                 mówienia  ...          0    nie dotyczy\n",
              "1       eliptyczne             epistemiczny  ...          0             no\n",
              "2       eliptyczne                 mówienia  ...          0    nie dotyczy\n",
              "3                1             epistemiczny  ...          0    nie dotyczy\n",
              "4                1             epistemiczny  ...          0    nie dotyczy\n",
              "\n",
              "[5 rows x 9 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fTXvttwo5v0D",
        "colab_type": "text"
      },
      "source": [
        "### Cleaning data by deleting uncertainty - simplification "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ewr4Z-ZH8e6Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# df.type_of_sentence.unique() cleaning not needed \n",
        "\n",
        "# df.verb_main_semantic_class - only (epistemiczny, mówienia, ?)\n",
        "main_semantic_class_unique = df.verb_main_semantic_class.unique()\n",
        "main_semantic_class_unique = main_semantic_class_unique[main_semantic_class_unique != \"epistemiczny\"]\n",
        "main_semantic_class_unique = main_semantic_class_unique[main_semantic_class_unique != \"mówienia\"]\n",
        "df.verb_main_semantic_class = df.verb_main_semantic_class.apply(lambda x: '?' if x in main_semantic_class_unique else x )\n",
        "\n",
        "# df.verb_second_semantic_class.unique() cleaning not needed \n",
        "# df.verb_third_semantic_class.unique() cleaning not needed\n",
        "\n",
        "# verb veridical positive cleaning\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '+' if '+' in x else x)\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '-' if '-' in x else x)\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: 'o' if 'o' in x else x)\n",
        "df.verb_veridical_positive = df.verb_veridical_positive.apply(lambda x: '?' if '?' in x else x)\n",
        "\n",
        "# verb veridical negative cleaning\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '+' if '+' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: 'o' if 'o' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '-' if '-' in x else x)\n",
        "df.verb_veridical_negative = df.verb_veridical_negative.apply(lambda x: '?' if '?' in x else x)\n",
        "\n",
        "# df.verb_tense.unique() cleaning not needed\n",
        "# df.t_negation.unique() cleaning not needed\n",
        "# df.semantic_relation.unique() cleaning not needed \n",
        "\n",
        "df = df[df[\"presupposition\"] != \"nie dotyczy\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eq5Zke-TO3zd",
        "colab_type": "text"
      },
      "source": [
        "#### Possible feature values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVbjgIUMOXXi",
        "colab_type": "code",
        "outputId": "81d2402d-edb1-47e5-95ba-5968dddca46e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "print(df.type_of_sentence.unique())\n",
        "print(df.verb_main_semantic_class.unique())\n",
        "print(df.verb_second_semantic_class.unique())\n",
        "print(df.verb_third_semantic_class.unique())\n",
        "print(df.verb_veridical_positive.unique())\n",
        "print(df.verb_veridical_negative.unique())\n",
        "print(df.verb_tense.unique())\n",
        "print(df.t_negation.unique())\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['eliptyczne' 1 'modalne' 'powinnościowe' 'none' '?' 'warunkowe; pytajne'\n",
            " 'performatyw' 'imperatyw' 'pytajne' 'wolitywne' 'warunkowe; modalne'\n",
            " 'generalne' 'modalne; pytajne' 'imperatyw ' 'warunkowe']\n",
            "['epistemiczny' '?' 'mówienia']\n",
            "['none' 'percepcyjny' 'epistemiczny' 'emotywny' 'wolicjonalny'\n",
            " 'wnioskowania' 'pamięciowy' 'zdarzeniowy' 'mówienia']\n",
            "['none' 'mówienia' 'epistemiczny' 'percepcyjny']\n",
            "['?' 'o' '+' '-']\n",
            "['?' 'o' '+' '-']\n",
            "['past' 'brak' 'present' 'future']\n",
            "[0 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0yf4jWrgB4D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = df[[\n",
        "         \"verb_main_semantic_class\",\n",
        "         \"verb_veridical_positive\",\n",
        "         \"verb_veridical_negative\",\n",
        "         \"verb_tense\",\n",
        "         \"presupposition\"\n",
        "         ]]\n",
        "df.to_csv(\"plDataPresup.csv\", index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0mBdk6j7_tTV",
        "colab_type": "code",
        "outputId": "32952341-5a7d-41a9-a8e9-ec49c2039de3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df.columns"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['verb_main_semantic_class', 'verb_veridical_positive',\n",
              "       'verb_veridical_negative', 'verb_tense', 'presupposition'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOi5V_fDAJBS",
        "colab_type": "text"
      },
      "source": [
        "### Vactorize data and split to features and target"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bNZdBxWgyu8t",
        "colab_type": "text"
      },
      "source": [
        "Ml classifier labels - target for RandomForest"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RSR0_iVM0ujy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ml_classifier_labels = df[\"presupposition\"]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YokPfvoJxWoR",
        "colab_type": "text"
      },
      "source": [
        "#### Vectorize (one =hot encoding)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5r7NRdcwkIX5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df = pd.get_dummies(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q9f1MRWJxhBA",
        "colab_type": "text"
      },
      "source": [
        "#### Split to features and target"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qp6eOyEdxlMO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = df.iloc[:,0:-2]\n",
        "y = df.iloc[:,-2:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KjQvT5PtxsFz",
        "colab_type": "text"
      },
      "source": [
        "#### Features columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yLqFLidq0YLV",
        "colab_type": "code",
        "outputId": "a20542ca-c78f-4606-cb3d-e64748245dff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "X.columns"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['verb_main_semantic_class_?', 'verb_main_semantic_class_epistemiczny',\n",
              "       'verb_main_semantic_class_mówienia', 'verb_veridical_positive_+',\n",
              "       'verb_veridical_positive_-', 'verb_veridical_positive_?',\n",
              "       'verb_veridical_positive_o', 'verb_veridical_negative_+',\n",
              "       'verb_veridical_negative_-', 'verb_veridical_negative_?',\n",
              "       'verb_veridical_negative_o', 'verb_tense_brak', 'verb_tense_future',\n",
              "       'verb_tense_past', 'verb_tense_present'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v4896Jynxyew",
        "colab_type": "text"
      },
      "source": [
        "#### Target columns"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxEJ6K-fxkTU",
        "colab_type": "code",
        "outputId": "4927e38e-8734-406f-99fb-7c66f19950f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "y.columns"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['presupposition_no', 'presupposition_yes'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_jmoU__ZsXtC",
        "colab_type": "text"
      },
      "source": [
        "## k-fold crossvalidation preparing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kbikRibEzvf1",
        "colab_type": "text"
      },
      "source": [
        "You can change number of validations here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUp3OdBNsdn5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "k=7\n",
        "from sklearn.model_selection import KFold\n",
        "kfold = KFold(n_splits = k, shuffle=True)\n",
        "\n",
        "acc_per_fold = []\n",
        "loss_per_fold = [] "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Xi8QfyAkbiN",
        "colab_type": "text"
      },
      "source": [
        "***\n",
        "# Keras model building"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pVN5IeMLEn4w",
        "colab_type": "text"
      },
      "source": [
        "### Train model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "amhvtjnZQwhz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf \n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from sklearn.metrics import confusion_matrix \n",
        "import seaborn as sns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H15DIedMCgOC",
        "colab_type": "text"
      },
      "source": [
        "It takes only 1-2 minutes to train this model with 7-crossvalidation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ZB5xOvAZbu",
        "colab_type": "code",
        "outputId": "7f4eb636-d6be-49e5-fa72-cd2bbda45f2f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "fold_no = 1 \n",
        "\n",
        "#get number of columns in training data\n",
        "n_cols = X.shape[1]\n",
        "print(n_cols)\n",
        "\n",
        "for train, test in kfold.split(X,y):\n",
        "  # FOLD PRINTOUT\n",
        "  print(100*'_')\n",
        "  print (f\"FOLD NO {fold_no} START\")  \n",
        "\n",
        "  # model architecture  \n",
        "  model = tf.keras.Sequential()\n",
        "  #add model layers\n",
        "  model.add(Dense(8, activation='relu', input_shape=(n_cols,)))\n",
        "  model.add(Dense(16, activation='relu'))\n",
        "  model.add(Dense(8, activation='relu'))\n",
        "  model.add(Dense(2, activation='softmax'))\n",
        "\n",
        "  # model compile \n",
        "  model.compile(optimizer = 'adam', loss=\"categorical_crossentropy\", metrics = ['accuracy'])\n",
        "  \n",
        "  # training\n",
        "  history = model.fit(X.iloc[train], y.iloc[train], validation_split=0.2, epochs=70)\n",
        "\n",
        "  # scores \n",
        "  scores = model.evaluate(X.iloc[test], y.iloc[test], verbose=0)\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # iterator up\n",
        "  fold_no = fold_no + 1"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "15\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 1 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7217 - accuracy: 0.4198 - val_loss: 0.6728 - val_accuracy: 0.6183\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6781 - accuracy: 0.5649 - val_loss: 0.5689 - val_accuracy: 0.9008\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6434 - accuracy: 0.6240 - val_loss: 0.5027 - val_accuracy: 0.9008\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6177 - accuracy: 0.6756 - val_loss: 0.4583 - val_accuracy: 0.9160\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5870 - accuracy: 0.6966 - val_loss: 0.4211 - val_accuracy: 0.9160\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5505 - accuracy: 0.6947 - val_loss: 0.3761 - val_accuracy: 0.9160\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5100 - accuracy: 0.7863 - val_loss: 0.3326 - val_accuracy: 0.9160\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4751 - accuracy: 0.7977 - val_loss: 0.2987 - val_accuracy: 0.9160\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4478 - accuracy: 0.7977 - val_loss: 0.2793 - val_accuracy: 0.9160\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4278 - accuracy: 0.8092 - val_loss: 0.2725 - val_accuracy: 0.9008\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4124 - accuracy: 0.8187 - val_loss: 0.2700 - val_accuracy: 0.9008\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3998 - accuracy: 0.8397 - val_loss: 0.2700 - val_accuracy: 0.9008\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3889 - accuracy: 0.8454 - val_loss: 0.2734 - val_accuracy: 0.9008\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3815 - accuracy: 0.8397 - val_loss: 0.2793 - val_accuracy: 0.9008\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3756 - accuracy: 0.8454 - val_loss: 0.2816 - val_accuracy: 0.9008\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3706 - accuracy: 0.8416 - val_loss: 0.2869 - val_accuracy: 0.9008\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3671 - accuracy: 0.8454 - val_loss: 0.2893 - val_accuracy: 0.9008\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8454 - val_loss: 0.2881 - val_accuracy: 0.9008\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3606 - accuracy: 0.8416 - val_loss: 0.2926 - val_accuracy: 0.9008\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3605 - accuracy: 0.8511 - val_loss: 0.2912 - val_accuracy: 0.9008\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3543 - accuracy: 0.8473 - val_loss: 0.3021 - val_accuracy: 0.9008\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3517 - accuracy: 0.8416 - val_loss: 0.2962 - val_accuracy: 0.9008\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3502 - accuracy: 0.8511 - val_loss: 0.2997 - val_accuracy: 0.9008\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3486 - accuracy: 0.8492 - val_loss: 0.3050 - val_accuracy: 0.9008\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3473 - accuracy: 0.8511 - val_loss: 0.2981 - val_accuracy: 0.9008\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3446 - accuracy: 0.8511 - val_loss: 0.3066 - val_accuracy: 0.9008\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3433 - accuracy: 0.8511 - val_loss: 0.2984 - val_accuracy: 0.9008\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8511 - val_loss: 0.3088 - val_accuracy: 0.9008\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3405 - accuracy: 0.8531 - val_loss: 0.3112 - val_accuracy: 0.9008\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3380 - accuracy: 0.8531 - val_loss: 0.3088 - val_accuracy: 0.9008\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3377 - accuracy: 0.8531 - val_loss: 0.3073 - val_accuracy: 0.9008\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8569 - val_loss: 0.3168 - val_accuracy: 0.9008\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3356 - accuracy: 0.8550 - val_loss: 0.3146 - val_accuracy: 0.9008\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3339 - accuracy: 0.8531 - val_loss: 0.3156 - val_accuracy: 0.9008\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8569 - val_loss: 0.3117 - val_accuracy: 0.9008\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3323 - accuracy: 0.8569 - val_loss: 0.3160 - val_accuracy: 0.9008\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3309 - accuracy: 0.8569 - val_loss: 0.3070 - val_accuracy: 0.9008\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8569 - val_loss: 0.3204 - val_accuracy: 0.9008\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3268 - accuracy: 0.8607 - val_loss: 0.3121 - val_accuracy: 0.9008\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3266 - accuracy: 0.8607 - val_loss: 0.3138 - val_accuracy: 0.9008\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8607 - val_loss: 0.3097 - val_accuracy: 0.9008\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8550 - val_loss: 0.3169 - val_accuracy: 0.9008\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8607 - val_loss: 0.3134 - val_accuracy: 0.9008\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8607 - val_loss: 0.3140 - val_accuracy: 0.9008\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8607 - val_loss: 0.3149 - val_accuracy: 0.9008\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8607 - val_loss: 0.3262 - val_accuracy: 0.9008\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3219 - accuracy: 0.8569 - val_loss: 0.3141 - val_accuracy: 0.9008\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3208 - accuracy: 0.8607 - val_loss: 0.3178 - val_accuracy: 0.9008\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8607 - val_loss: 0.3171 - val_accuracy: 0.9008\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3195 - accuracy: 0.8607 - val_loss: 0.3171 - val_accuracy: 0.9008\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3178 - accuracy: 0.8607 - val_loss: 0.3208 - val_accuracy: 0.9008\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3179 - accuracy: 0.8607 - val_loss: 0.3185 - val_accuracy: 0.9008\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8626 - val_loss: 0.3208 - val_accuracy: 0.9008\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8588 - val_loss: 0.3215 - val_accuracy: 0.9008\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3161 - accuracy: 0.8588 - val_loss: 0.3179 - val_accuracy: 0.9160\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3165 - accuracy: 0.8607 - val_loss: 0.3209 - val_accuracy: 0.9160\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3151 - accuracy: 0.8626 - val_loss: 0.3244 - val_accuracy: 0.9008\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3143 - accuracy: 0.8588 - val_loss: 0.3201 - val_accuracy: 0.9160\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8588 - val_loss: 0.3198 - val_accuracy: 0.9160\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3138 - accuracy: 0.8607 - val_loss: 0.3177 - val_accuracy: 0.9160\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3125 - accuracy: 0.8626 - val_loss: 0.3239 - val_accuracy: 0.9160\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8607 - val_loss: 0.3216 - val_accuracy: 0.9160\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3121 - accuracy: 0.8626 - val_loss: 0.3261 - val_accuracy: 0.9160\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8607 - val_loss: 0.3173 - val_accuracy: 0.9160\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8588 - val_loss: 0.3209 - val_accuracy: 0.9160\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3101 - accuracy: 0.8626 - val_loss: 0.3211 - val_accuracy: 0.9160\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8626 - val_loss: 0.3232 - val_accuracy: 0.9160\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8626 - val_loss: 0.3246 - val_accuracy: 0.9160\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3103 - accuracy: 0.8645 - val_loss: 0.3211 - val_accuracy: 0.9160\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3091 - accuracy: 0.8626 - val_loss: 0.3234 - val_accuracy: 0.9160\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 2 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 9ms/step - loss: 0.6902 - accuracy: 0.4466 - val_loss: 0.6476 - val_accuracy: 0.8931\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6661 - accuracy: 0.5821 - val_loss: 0.6007 - val_accuracy: 0.8931\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6473 - accuracy: 0.5840 - val_loss: 0.5575 - val_accuracy: 0.8931\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6286 - accuracy: 0.5840 - val_loss: 0.5083 - val_accuracy: 0.8931\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6066 - accuracy: 0.5840 - val_loss: 0.4656 - val_accuracy: 0.8931\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5833 - accuracy: 0.5840 - val_loss: 0.4261 - val_accuracy: 0.8855\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5549 - accuracy: 0.6641 - val_loss: 0.3928 - val_accuracy: 0.8855\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5266 - accuracy: 0.8015 - val_loss: 0.3580 - val_accuracy: 0.8779\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5003 - accuracy: 0.8187 - val_loss: 0.3383 - val_accuracy: 0.8779\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4781 - accuracy: 0.8053 - val_loss: 0.3311 - val_accuracy: 0.8779\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4554 - accuracy: 0.8092 - val_loss: 0.3384 - val_accuracy: 0.8779\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4257 - accuracy: 0.8187 - val_loss: 0.3429 - val_accuracy: 0.8779\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4055 - accuracy: 0.8111 - val_loss: 0.3515 - val_accuracy: 0.8779\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3922 - accuracy: 0.8263 - val_loss: 0.3600 - val_accuracy: 0.8779\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3845 - accuracy: 0.8206 - val_loss: 0.3697 - val_accuracy: 0.8779\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3766 - accuracy: 0.8225 - val_loss: 0.3775 - val_accuracy: 0.8779\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3705 - accuracy: 0.8263 - val_loss: 0.3817 - val_accuracy: 0.8779\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3670 - accuracy: 0.8397 - val_loss: 0.3858 - val_accuracy: 0.8779\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3632 - accuracy: 0.8378 - val_loss: 0.3956 - val_accuracy: 0.8779\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3602 - accuracy: 0.8359 - val_loss: 0.3863 - val_accuracy: 0.8779\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3562 - accuracy: 0.8397 - val_loss: 0.3837 - val_accuracy: 0.8779\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3540 - accuracy: 0.8397 - val_loss: 0.3889 - val_accuracy: 0.8779\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3518 - accuracy: 0.8416 - val_loss: 0.3931 - val_accuracy: 0.8779\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3492 - accuracy: 0.8454 - val_loss: 0.3886 - val_accuracy: 0.8779\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3476 - accuracy: 0.8435 - val_loss: 0.3853 - val_accuracy: 0.8779\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3471 - accuracy: 0.8416 - val_loss: 0.3933 - val_accuracy: 0.8779\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3445 - accuracy: 0.8416 - val_loss: 0.3875 - val_accuracy: 0.8779\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8359 - val_loss: 0.3960 - val_accuracy: 0.8779\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3419 - accuracy: 0.8340 - val_loss: 0.3951 - val_accuracy: 0.8779\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3412 - accuracy: 0.8416 - val_loss: 0.3967 - val_accuracy: 0.8779\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3406 - accuracy: 0.8416 - val_loss: 0.4009 - val_accuracy: 0.8779\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3387 - accuracy: 0.8416 - val_loss: 0.3998 - val_accuracy: 0.8779\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3376 - accuracy: 0.8378 - val_loss: 0.3970 - val_accuracy: 0.8779\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8454 - val_loss: 0.3999 - val_accuracy: 0.8779\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3366 - accuracy: 0.8416 - val_loss: 0.3999 - val_accuracy: 0.8779\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3381 - accuracy: 0.8397 - val_loss: 0.3863 - val_accuracy: 0.8779\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8454 - val_loss: 0.3815 - val_accuracy: 0.8779\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8416 - val_loss: 0.3970 - val_accuracy: 0.8779\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3334 - accuracy: 0.8454 - val_loss: 0.3955 - val_accuracy: 0.8779\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3338 - accuracy: 0.8473 - val_loss: 0.3929 - val_accuracy: 0.8779\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8454 - val_loss: 0.4006 - val_accuracy: 0.8779\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3318 - accuracy: 0.8435 - val_loss: 0.3976 - val_accuracy: 0.8779\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8492 - val_loss: 0.3979 - val_accuracy: 0.8779\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8492 - val_loss: 0.4028 - val_accuracy: 0.8779\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3310 - accuracy: 0.8435 - val_loss: 0.3899 - val_accuracy: 0.8779\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3298 - accuracy: 0.8435 - val_loss: 0.4001 - val_accuracy: 0.8779\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8492 - val_loss: 0.3916 - val_accuracy: 0.8779\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3290 - accuracy: 0.8416 - val_loss: 0.4025 - val_accuracy: 0.8779\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3281 - accuracy: 0.8492 - val_loss: 0.3996 - val_accuracy: 0.8779\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3277 - accuracy: 0.8473 - val_loss: 0.3953 - val_accuracy: 0.8779\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8473 - val_loss: 0.4010 - val_accuracy: 0.8779\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8511 - val_loss: 0.3987 - val_accuracy: 0.8779\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3270 - accuracy: 0.8473 - val_loss: 0.3972 - val_accuracy: 0.8779\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3269 - accuracy: 0.8416 - val_loss: 0.3973 - val_accuracy: 0.8779\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3255 - accuracy: 0.8588 - val_loss: 0.4027 - val_accuracy: 0.8779\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3252 - accuracy: 0.8550 - val_loss: 0.3951 - val_accuracy: 0.8779\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8511 - val_loss: 0.3991 - val_accuracy: 0.8779\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8511 - val_loss: 0.4006 - val_accuracy: 0.8779\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3239 - accuracy: 0.8550 - val_loss: 0.4046 - val_accuracy: 0.8779\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3236 - accuracy: 0.8550 - val_loss: 0.3991 - val_accuracy: 0.8779\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8531 - val_loss: 0.3947 - val_accuracy: 0.8779\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3236 - accuracy: 0.8531 - val_loss: 0.4015 - val_accuracy: 0.8779\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3230 - accuracy: 0.8492 - val_loss: 0.4044 - val_accuracy: 0.8779\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3224 - accuracy: 0.8531 - val_loss: 0.3956 - val_accuracy: 0.8779\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8454 - val_loss: 0.4018 - val_accuracy: 0.8779\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3220 - accuracy: 0.8473 - val_loss: 0.4031 - val_accuracy: 0.8779\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3211 - accuracy: 0.8550 - val_loss: 0.4037 - val_accuracy: 0.8779\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3233 - accuracy: 0.8492 - val_loss: 0.3959 - val_accuracy: 0.8779\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3209 - accuracy: 0.8550 - val_loss: 0.4030 - val_accuracy: 0.8779\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3206 - accuracy: 0.8531 - val_loss: 0.3996 - val_accuracy: 0.8779\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 3 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7329 - accuracy: 0.5706 - val_loss: 0.6118 - val_accuracy: 0.9242\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6913 - accuracy: 0.5706 - val_loss: 0.5875 - val_accuracy: 0.9242\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.6792 - accuracy: 0.5706 - val_loss: 0.5732 - val_accuracy: 0.9242\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6692 - accuracy: 0.5706 - val_loss: 0.5542 - val_accuracy: 0.9242\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6577 - accuracy: 0.5706 - val_loss: 0.5283 - val_accuracy: 0.9242\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.5706 - val_loss: 0.4932 - val_accuracy: 0.9242\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6256 - accuracy: 0.5706 - val_loss: 0.4605 - val_accuracy: 0.9242\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6030 - accuracy: 0.6126 - val_loss: 0.4249 - val_accuracy: 0.9242\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5752 - accuracy: 0.7347 - val_loss: 0.3763 - val_accuracy: 0.9167\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5451 - accuracy: 0.8034 - val_loss: 0.3489 - val_accuracy: 0.9015\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5148 - accuracy: 0.8149 - val_loss: 0.3231 - val_accuracy: 0.9015\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4847 - accuracy: 0.8149 - val_loss: 0.3019 - val_accuracy: 0.9015\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4597 - accuracy: 0.8168 - val_loss: 0.2901 - val_accuracy: 0.9015\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4406 - accuracy: 0.8225 - val_loss: 0.2885 - val_accuracy: 0.9015\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4261 - accuracy: 0.8397 - val_loss: 0.2906 - val_accuracy: 0.9015\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4143 - accuracy: 0.8397 - val_loss: 0.2913 - val_accuracy: 0.9015\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4045 - accuracy: 0.8416 - val_loss: 0.2921 - val_accuracy: 0.9015\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3981 - accuracy: 0.8435 - val_loss: 0.2931 - val_accuracy: 0.9015\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3908 - accuracy: 0.8416 - val_loss: 0.2960 - val_accuracy: 0.9015\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3842 - accuracy: 0.8435 - val_loss: 0.2989 - val_accuracy: 0.9015\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3801 - accuracy: 0.8435 - val_loss: 0.2997 - val_accuracy: 0.9015\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8435 - val_loss: 0.2997 - val_accuracy: 0.9015\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3701 - accuracy: 0.8416 - val_loss: 0.3057 - val_accuracy: 0.9015\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8435 - val_loss: 0.3067 - val_accuracy: 0.9015\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3627 - accuracy: 0.8454 - val_loss: 0.3108 - val_accuracy: 0.9015\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3605 - accuracy: 0.8473 - val_loss: 0.3139 - val_accuracy: 0.9015\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8473 - val_loss: 0.3149 - val_accuracy: 0.9015\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3555 - accuracy: 0.8473 - val_loss: 0.3170 - val_accuracy: 0.9015\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3544 - accuracy: 0.8454 - val_loss: 0.3244 - val_accuracy: 0.9015\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3523 - accuracy: 0.8473 - val_loss: 0.3216 - val_accuracy: 0.9015\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3506 - accuracy: 0.8473 - val_loss: 0.3193 - val_accuracy: 0.9015\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8454 - val_loss: 0.3264 - val_accuracy: 0.9015\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8473 - val_loss: 0.3242 - val_accuracy: 0.9015\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3498 - accuracy: 0.8454 - val_loss: 0.3202 - val_accuracy: 0.9015\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3472 - accuracy: 0.8492 - val_loss: 0.3274 - val_accuracy: 0.9015\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3468 - accuracy: 0.8511 - val_loss: 0.3281 - val_accuracy: 0.9015\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8511 - val_loss: 0.3272 - val_accuracy: 0.9015\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8492 - val_loss: 0.3255 - val_accuracy: 0.9015\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3432 - accuracy: 0.8454 - val_loss: 0.3290 - val_accuracy: 0.9015\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3449 - accuracy: 0.8492 - val_loss: 0.3290 - val_accuracy: 0.9015\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3438 - accuracy: 0.8550 - val_loss: 0.3372 - val_accuracy: 0.9015\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3427 - accuracy: 0.8511 - val_loss: 0.3292 - val_accuracy: 0.9015\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3421 - accuracy: 0.8569 - val_loss: 0.3348 - val_accuracy: 0.9015\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8492 - val_loss: 0.3313 - val_accuracy: 0.9015\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3400 - accuracy: 0.8569 - val_loss: 0.3351 - val_accuracy: 0.9015\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3397 - accuracy: 0.8550 - val_loss: 0.3300 - val_accuracy: 0.9015\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3389 - accuracy: 0.8626 - val_loss: 0.3341 - val_accuracy: 0.9015\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3387 - accuracy: 0.8531 - val_loss: 0.3333 - val_accuracy: 0.9015\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3382 - accuracy: 0.8550 - val_loss: 0.3365 - val_accuracy: 0.9015\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3375 - accuracy: 0.8531 - val_loss: 0.3384 - val_accuracy: 0.9015\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3368 - accuracy: 0.8550 - val_loss: 0.3342 - val_accuracy: 0.9015\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8550 - val_loss: 0.3370 - val_accuracy: 0.9015\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3364 - accuracy: 0.8531 - val_loss: 0.3388 - val_accuracy: 0.9015\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3347 - accuracy: 0.8511 - val_loss: 0.3335 - val_accuracy: 0.9015\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3361 - accuracy: 0.8588 - val_loss: 0.3345 - val_accuracy: 0.9015\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3355 - accuracy: 0.8531 - val_loss: 0.3342 - val_accuracy: 0.9015\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3341 - accuracy: 0.8607 - val_loss: 0.3378 - val_accuracy: 0.9015\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8550 - val_loss: 0.3432 - val_accuracy: 0.9015\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3331 - accuracy: 0.8569 - val_loss: 0.3332 - val_accuracy: 0.9015\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3344 - accuracy: 0.8569 - val_loss: 0.3388 - val_accuracy: 0.9015\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3327 - accuracy: 0.8550 - val_loss: 0.3379 - val_accuracy: 0.9015\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8588 - val_loss: 0.3406 - val_accuracy: 0.9015\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3322 - accuracy: 0.8588 - val_loss: 0.3393 - val_accuracy: 0.9015\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3317 - accuracy: 0.8588 - val_loss: 0.3386 - val_accuracy: 0.9015\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8550 - val_loss: 0.3402 - val_accuracy: 0.9015\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3302 - accuracy: 0.8550 - val_loss: 0.3425 - val_accuracy: 0.9015\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3321 - accuracy: 0.8588 - val_loss: 0.3450 - val_accuracy: 0.9015\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3294 - accuracy: 0.8588 - val_loss: 0.3448 - val_accuracy: 0.9015\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3286 - accuracy: 0.8588 - val_loss: 0.3415 - val_accuracy: 0.9015\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8569 - val_loss: 0.3405 - val_accuracy: 0.9015\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 4 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6701 - accuracy: 0.5916 - val_loss: 0.4941 - val_accuracy: 0.8939\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6403 - accuracy: 0.6031 - val_loss: 0.4518 - val_accuracy: 0.8939\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6158 - accuracy: 0.6031 - val_loss: 0.4163 - val_accuracy: 0.8939\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5927 - accuracy: 0.6031 - val_loss: 0.3869 - val_accuracy: 0.8939\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5704 - accuracy: 0.6031 - val_loss: 0.3556 - val_accuracy: 0.8864\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5463 - accuracy: 0.6031 - val_loss: 0.3356 - val_accuracy: 0.8864\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5239 - accuracy: 0.6927 - val_loss: 0.3139 - val_accuracy: 0.8864\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5022 - accuracy: 0.7519 - val_loss: 0.2967 - val_accuracy: 0.8864\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4855 - accuracy: 0.7672 - val_loss: 0.2852 - val_accuracy: 0.8864\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4719 - accuracy: 0.7844 - val_loss: 0.2785 - val_accuracy: 0.9091\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4630 - accuracy: 0.8282 - val_loss: 0.2748 - val_accuracy: 0.9091\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4541 - accuracy: 0.8302 - val_loss: 0.2752 - val_accuracy: 0.9091\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4442 - accuracy: 0.8511 - val_loss: 0.2735 - val_accuracy: 0.9091\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4371 - accuracy: 0.8550 - val_loss: 0.2720 - val_accuracy: 0.9091\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4294 - accuracy: 0.8511 - val_loss: 0.2708 - val_accuracy: 0.9091\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4222 - accuracy: 0.8492 - val_loss: 0.2703 - val_accuracy: 0.9091\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4156 - accuracy: 0.8492 - val_loss: 0.2696 - val_accuracy: 0.9091\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4089 - accuracy: 0.8492 - val_loss: 0.2691 - val_accuracy: 0.9091\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4013 - accuracy: 0.8511 - val_loss: 0.2702 - val_accuracy: 0.9091\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3954 - accuracy: 0.8492 - val_loss: 0.2705 - val_accuracy: 0.9091\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3904 - accuracy: 0.8492 - val_loss: 0.2710 - val_accuracy: 0.9091\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3840 - accuracy: 0.8511 - val_loss: 0.2726 - val_accuracy: 0.9091\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3791 - accuracy: 0.8511 - val_loss: 0.2753 - val_accuracy: 0.9091\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3722 - accuracy: 0.8511 - val_loss: 0.2752 - val_accuracy: 0.9091\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3662 - accuracy: 0.8511 - val_loss: 0.2762 - val_accuracy: 0.9091\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3633 - accuracy: 0.8511 - val_loss: 0.2793 - val_accuracy: 0.9091\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3581 - accuracy: 0.8511 - val_loss: 0.2802 - val_accuracy: 0.9091\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3511 - accuracy: 0.8511 - val_loss: 0.2843 - val_accuracy: 0.8939\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3479 - accuracy: 0.8531 - val_loss: 0.2881 - val_accuracy: 0.8939\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 5ms/step - loss: 0.3427 - accuracy: 0.8531 - val_loss: 0.2913 - val_accuracy: 0.8939\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3369 - accuracy: 0.8550 - val_loss: 0.2941 - val_accuracy: 0.8939\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8569 - val_loss: 0.2960 - val_accuracy: 0.8939\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3303 - accuracy: 0.8588 - val_loss: 0.3002 - val_accuracy: 0.8939\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8492 - val_loss: 0.3005 - val_accuracy: 0.8939\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3259 - accuracy: 0.8607 - val_loss: 0.3026 - val_accuracy: 0.8939\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3229 - accuracy: 0.8511 - val_loss: 0.3077 - val_accuracy: 0.8939\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8607 - val_loss: 0.3096 - val_accuracy: 0.8939\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3198 - accuracy: 0.8569 - val_loss: 0.3078 - val_accuracy: 0.8939\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3197 - accuracy: 0.8588 - val_loss: 0.3142 - val_accuracy: 0.8939\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3163 - accuracy: 0.8607 - val_loss: 0.3122 - val_accuracy: 0.8939\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8607 - val_loss: 0.3169 - val_accuracy: 0.8939\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3135 - accuracy: 0.8607 - val_loss: 0.3175 - val_accuracy: 0.8939\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8626 - val_loss: 0.3181 - val_accuracy: 0.8939\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3113 - accuracy: 0.8588 - val_loss: 0.3179 - val_accuracy: 0.8939\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8607 - val_loss: 0.3228 - val_accuracy: 0.8939\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3086 - accuracy: 0.8626 - val_loss: 0.3212 - val_accuracy: 0.8939\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8626 - val_loss: 0.3270 - val_accuracy: 0.8939\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3044 - accuracy: 0.8645 - val_loss: 0.3213 - val_accuracy: 0.8939\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3048 - accuracy: 0.8664 - val_loss: 0.3305 - val_accuracy: 0.8939\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3020 - accuracy: 0.8683 - val_loss: 0.3251 - val_accuracy: 0.8939\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3028 - accuracy: 0.8683 - val_loss: 0.3209 - val_accuracy: 0.8939\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3041 - accuracy: 0.8664 - val_loss: 0.3194 - val_accuracy: 0.8939\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2997 - accuracy: 0.8645 - val_loss: 0.3334 - val_accuracy: 0.8939\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8664 - val_loss: 0.3282 - val_accuracy: 0.8939\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3002 - accuracy: 0.8683 - val_loss: 0.3306 - val_accuracy: 0.8939\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8702 - val_loss: 0.3309 - val_accuracy: 0.8939\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8664 - val_loss: 0.3331 - val_accuracy: 0.8939\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2980 - accuracy: 0.8645 - val_loss: 0.3357 - val_accuracy: 0.8939\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.2985 - accuracy: 0.8702 - val_loss: 0.3382 - val_accuracy: 0.8939\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8702 - val_loss: 0.3352 - val_accuracy: 0.8939\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8664 - val_loss: 0.3374 - val_accuracy: 0.8939\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8683 - val_loss: 0.3364 - val_accuracy: 0.8939\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8702 - val_loss: 0.3427 - val_accuracy: 0.8939\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2955 - accuracy: 0.8645 - val_loss: 0.3356 - val_accuracy: 0.8939\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2986 - accuracy: 0.8683 - val_loss: 0.3366 - val_accuracy: 0.9091\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2960 - accuracy: 0.8683 - val_loss: 0.3455 - val_accuracy: 0.8939\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2971 - accuracy: 0.8645 - val_loss: 0.3389 - val_accuracy: 0.8939\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2945 - accuracy: 0.8702 - val_loss: 0.3427 - val_accuracy: 0.8939\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2939 - accuracy: 0.8683 - val_loss: 0.3457 - val_accuracy: 0.8939\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2932 - accuracy: 0.8683 - val_loss: 0.3446 - val_accuracy: 0.8939\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 5 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6814 - accuracy: 0.5973 - val_loss: 0.5816 - val_accuracy: 0.8788\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6582 - accuracy: 0.6622 - val_loss: 0.5482 - val_accuracy: 0.9015\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6401 - accuracy: 0.6832 - val_loss: 0.5045 - val_accuracy: 0.9015\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6207 - accuracy: 0.6832 - val_loss: 0.4608 - val_accuracy: 0.9015\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5911 - accuracy: 0.6813 - val_loss: 0.4166 - val_accuracy: 0.9015\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5544 - accuracy: 0.7920 - val_loss: 0.3691 - val_accuracy: 0.9091\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5097 - accuracy: 0.8034 - val_loss: 0.3287 - val_accuracy: 0.9091\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4726 - accuracy: 0.8053 - val_loss: 0.2928 - val_accuracy: 0.9091\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4452 - accuracy: 0.8053 - val_loss: 0.2808 - val_accuracy: 0.9091\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4236 - accuracy: 0.8015 - val_loss: 0.2718 - val_accuracy: 0.9091\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.4065 - accuracy: 0.8034 - val_loss: 0.2735 - val_accuracy: 0.9091\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3951 - accuracy: 0.8073 - val_loss: 0.2740 - val_accuracy: 0.9091\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3850 - accuracy: 0.8206 - val_loss: 0.2772 - val_accuracy: 0.9091\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3767 - accuracy: 0.8321 - val_loss: 0.2798 - val_accuracy: 0.9091\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3718 - accuracy: 0.8282 - val_loss: 0.2820 - val_accuracy: 0.9091\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3681 - accuracy: 0.8397 - val_loss: 0.2810 - val_accuracy: 0.9091\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3640 - accuracy: 0.8321 - val_loss: 0.2849 - val_accuracy: 0.9091\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3615 - accuracy: 0.8435 - val_loss: 0.2812 - val_accuracy: 0.9091\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3585 - accuracy: 0.8435 - val_loss: 0.2870 - val_accuracy: 0.9091\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8531 - val_loss: 0.2835 - val_accuracy: 0.9091\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3547 - accuracy: 0.8511 - val_loss: 0.2885 - val_accuracy: 0.9091\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3539 - accuracy: 0.8511 - val_loss: 0.2816 - val_accuracy: 0.9091\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3514 - accuracy: 0.8511 - val_loss: 0.2920 - val_accuracy: 0.9091\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3497 - accuracy: 0.8550 - val_loss: 0.2895 - val_accuracy: 0.9091\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3465 - accuracy: 0.8550 - val_loss: 0.2822 - val_accuracy: 0.9091\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3463 - accuracy: 0.8550 - val_loss: 0.2856 - val_accuracy: 0.9091\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3448 - accuracy: 0.8569 - val_loss: 0.2932 - val_accuracy: 0.9091\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3439 - accuracy: 0.8569 - val_loss: 0.2879 - val_accuracy: 0.9091\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3420 - accuracy: 0.8569 - val_loss: 0.2911 - val_accuracy: 0.9091\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3426 - accuracy: 0.8569 - val_loss: 0.2897 - val_accuracy: 0.9091\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3409 - accuracy: 0.8569 - val_loss: 0.2945 - val_accuracy: 0.9091\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3399 - accuracy: 0.8569 - val_loss: 0.2952 - val_accuracy: 0.9091\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3391 - accuracy: 0.8569 - val_loss: 0.2880 - val_accuracy: 0.9091\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8569 - val_loss: 0.2937 - val_accuracy: 0.9091\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3370 - accuracy: 0.8569 - val_loss: 0.2967 - val_accuracy: 0.9091\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3378 - accuracy: 0.8569 - val_loss: 0.2973 - val_accuracy: 0.9091\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3360 - accuracy: 0.8569 - val_loss: 0.2934 - val_accuracy: 0.9091\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3361 - accuracy: 0.8569 - val_loss: 0.2936 - val_accuracy: 0.9091\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3357 - accuracy: 0.8569 - val_loss: 0.2974 - val_accuracy: 0.9091\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3340 - accuracy: 0.8569 - val_loss: 0.3002 - val_accuracy: 0.9091\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3335 - accuracy: 0.8569 - val_loss: 0.2965 - val_accuracy: 0.9091\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3333 - accuracy: 0.8569 - val_loss: 0.2988 - val_accuracy: 0.9091\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8569 - val_loss: 0.2995 - val_accuracy: 0.9091\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3318 - accuracy: 0.8569 - val_loss: 0.3074 - val_accuracy: 0.9091\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3320 - accuracy: 0.8569 - val_loss: 0.3020 - val_accuracy: 0.9091\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3320 - accuracy: 0.8569 - val_loss: 0.3032 - val_accuracy: 0.9091\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8569 - val_loss: 0.3044 - val_accuracy: 0.9091\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3308 - accuracy: 0.8569 - val_loss: 0.3064 - val_accuracy: 0.9091\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3306 - accuracy: 0.8569 - val_loss: 0.3065 - val_accuracy: 0.9091\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3299 - accuracy: 0.8569 - val_loss: 0.3005 - val_accuracy: 0.9091\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3285 - accuracy: 0.8569 - val_loss: 0.3048 - val_accuracy: 0.9091\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3290 - accuracy: 0.8588 - val_loss: 0.3070 - val_accuracy: 0.9091\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3280 - accuracy: 0.8569 - val_loss: 0.3040 - val_accuracy: 0.9091\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8569 - val_loss: 0.3066 - val_accuracy: 0.9091\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3275 - accuracy: 0.8569 - val_loss: 0.3080 - val_accuracy: 0.9091\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3279 - accuracy: 0.8588 - val_loss: 0.3055 - val_accuracy: 0.9091\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3263 - accuracy: 0.8569 - val_loss: 0.3096 - val_accuracy: 0.9091\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3262 - accuracy: 0.8569 - val_loss: 0.3059 - val_accuracy: 0.9091\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3264 - accuracy: 0.8588 - val_loss: 0.3048 - val_accuracy: 0.9091\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3254 - accuracy: 0.8588 - val_loss: 0.3064 - val_accuracy: 0.9091\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3257 - accuracy: 0.8569 - val_loss: 0.3142 - val_accuracy: 0.9091\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8569 - val_loss: 0.3089 - val_accuracy: 0.9091\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3260 - accuracy: 0.8550 - val_loss: 0.3113 - val_accuracy: 0.9091\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3240 - accuracy: 0.8569 - val_loss: 0.3058 - val_accuracy: 0.9091\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3253 - accuracy: 0.8550 - val_loss: 0.3115 - val_accuracy: 0.9091\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3242 - accuracy: 0.8569 - val_loss: 0.3099 - val_accuracy: 0.9091\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3241 - accuracy: 0.8550 - val_loss: 0.3076 - val_accuracy: 0.9091\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3243 - accuracy: 0.8550 - val_loss: 0.3034 - val_accuracy: 0.9091\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8569 - val_loss: 0.3138 - val_accuracy: 0.9091\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8569 - val_loss: 0.3092 - val_accuracy: 0.9091\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 6 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.6728 - accuracy: 0.6431 - val_loss: 0.5893 - val_accuracy: 0.9091\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6416 - accuracy: 0.6966 - val_loss: 0.5310 - val_accuracy: 0.9242\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6107 - accuracy: 0.7615 - val_loss: 0.4737 - val_accuracy: 0.9242\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5806 - accuracy: 0.8073 - val_loss: 0.4104 - val_accuracy: 0.9242\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5473 - accuracy: 0.8053 - val_loss: 0.3638 - val_accuracy: 0.9167\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5192 - accuracy: 0.8053 - val_loss: 0.3203 - val_accuracy: 0.9091\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4938 - accuracy: 0.8130 - val_loss: 0.2931 - val_accuracy: 0.9091\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4691 - accuracy: 0.8073 - val_loss: 0.2726 - val_accuracy: 0.9091\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4463 - accuracy: 0.8053 - val_loss: 0.2593 - val_accuracy: 0.9091\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4276 - accuracy: 0.8111 - val_loss: 0.2494 - val_accuracy: 0.9091\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4131 - accuracy: 0.8130 - val_loss: 0.2482 - val_accuracy: 0.9091\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4003 - accuracy: 0.8187 - val_loss: 0.2484 - val_accuracy: 0.9091\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3899 - accuracy: 0.8187 - val_loss: 0.2464 - val_accuracy: 0.9091\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3798 - accuracy: 0.8187 - val_loss: 0.2535 - val_accuracy: 0.9091\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3732 - accuracy: 0.8225 - val_loss: 0.2556 - val_accuracy: 0.9091\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3672 - accuracy: 0.8340 - val_loss: 0.2551 - val_accuracy: 0.9091\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3651 - accuracy: 0.8340 - val_loss: 0.2578 - val_accuracy: 0.9091\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3576 - accuracy: 0.8397 - val_loss: 0.2615 - val_accuracy: 0.9091\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3535 - accuracy: 0.8473 - val_loss: 0.2610 - val_accuracy: 0.9091\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3519 - accuracy: 0.8473 - val_loss: 0.2657 - val_accuracy: 0.9091\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3495 - accuracy: 0.8473 - val_loss: 0.2618 - val_accuracy: 0.9091\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3442 - accuracy: 0.8473 - val_loss: 0.2690 - val_accuracy: 0.9091\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3417 - accuracy: 0.8473 - val_loss: 0.2697 - val_accuracy: 0.9091\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3394 - accuracy: 0.8473 - val_loss: 0.2699 - val_accuracy: 0.9091\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3383 - accuracy: 0.8569 - val_loss: 0.2699 - val_accuracy: 0.9091\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3353 - accuracy: 0.8473 - val_loss: 0.2739 - val_accuracy: 0.9091\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3342 - accuracy: 0.8435 - val_loss: 0.2769 - val_accuracy: 0.9091\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3307 - accuracy: 0.8569 - val_loss: 0.2748 - val_accuracy: 0.9091\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3288 - accuracy: 0.8531 - val_loss: 0.2771 - val_accuracy: 0.9091\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8607 - val_loss: 0.2780 - val_accuracy: 0.9091\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3248 - accuracy: 0.8626 - val_loss: 0.2806 - val_accuracy: 0.9091\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8607 - val_loss: 0.2826 - val_accuracy: 0.9091\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8645 - val_loss: 0.2755 - val_accuracy: 0.9091\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3217 - accuracy: 0.8607 - val_loss: 0.2810 - val_accuracy: 0.9091\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8588 - val_loss: 0.2803 - val_accuracy: 0.9091\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3216 - accuracy: 0.8626 - val_loss: 0.2766 - val_accuracy: 0.9091\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3200 - accuracy: 0.8550 - val_loss: 0.2837 - val_accuracy: 0.9091\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3195 - accuracy: 0.8473 - val_loss: 0.2847 - val_accuracy: 0.9091\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8607 - val_loss: 0.2823 - val_accuracy: 0.9091\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3150 - accuracy: 0.8626 - val_loss: 0.2846 - val_accuracy: 0.9091\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3147 - accuracy: 0.8588 - val_loss: 0.2862 - val_accuracy: 0.9091\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3141 - accuracy: 0.8531 - val_loss: 0.2870 - val_accuracy: 0.9091\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8607 - val_loss: 0.2859 - val_accuracy: 0.9091\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3134 - accuracy: 0.8607 - val_loss: 0.2871 - val_accuracy: 0.9091\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8626 - val_loss: 0.2871 - val_accuracy: 0.9091\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8607 - val_loss: 0.2831 - val_accuracy: 0.9091\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3092 - accuracy: 0.8626 - val_loss: 0.2872 - val_accuracy: 0.9091\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3082 - accuracy: 0.8588 - val_loss: 0.2918 - val_accuracy: 0.9091\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3088 - accuracy: 0.8550 - val_loss: 0.2857 - val_accuracy: 0.9091\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3079 - accuracy: 0.8588 - val_loss: 0.2898 - val_accuracy: 0.9091\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3059 - accuracy: 0.8626 - val_loss: 0.2851 - val_accuracy: 0.9091\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3061 - accuracy: 0.8664 - val_loss: 0.2869 - val_accuracy: 0.9091\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3050 - accuracy: 0.8607 - val_loss: 0.2864 - val_accuracy: 0.9091\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3045 - accuracy: 0.8664 - val_loss: 0.2884 - val_accuracy: 0.9091\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3038 - accuracy: 0.8664 - val_loss: 0.2899 - val_accuracy: 0.9091\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8645 - val_loss: 0.2919 - val_accuracy: 0.9091\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3027 - accuracy: 0.8626 - val_loss: 0.2911 - val_accuracy: 0.9091\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8645 - val_loss: 0.2900 - val_accuracy: 0.9091\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3016 - accuracy: 0.8683 - val_loss: 0.2896 - val_accuracy: 0.9091\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3035 - accuracy: 0.8721 - val_loss: 0.2942 - val_accuracy: 0.9091\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3013 - accuracy: 0.8702 - val_loss: 0.2893 - val_accuracy: 0.9091\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3009 - accuracy: 0.8664 - val_loss: 0.2930 - val_accuracy: 0.9091\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3008 - accuracy: 0.8721 - val_loss: 0.2928 - val_accuracy: 0.9091\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8626 - val_loss: 0.2928 - val_accuracy: 0.9091\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2993 - accuracy: 0.8740 - val_loss: 0.3009 - val_accuracy: 0.9091\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3024 - accuracy: 0.8740 - val_loss: 0.2891 - val_accuracy: 0.9091\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2978 - accuracy: 0.8721 - val_loss: 0.2980 - val_accuracy: 0.9091\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2982 - accuracy: 0.8740 - val_loss: 0.2956 - val_accuracy: 0.9091\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2981 - accuracy: 0.8740 - val_loss: 0.2945 - val_accuracy: 0.9091\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8721 - val_loss: 0.2950 - val_accuracy: 0.9091\n",
            "____________________________________________________________________________________________________\n",
            "FOLD NO 7 START\n",
            "Epoch 1/70\n",
            "17/17 [==============================] - 0s 8ms/step - loss: 0.7384 - accuracy: 0.5859 - val_loss: 0.5292 - val_accuracy: 0.8939\n",
            "Epoch 2/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6730 - accuracy: 0.5859 - val_loss: 0.4806 - val_accuracy: 0.8939\n",
            "Epoch 3/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.6199 - accuracy: 0.5859 - val_loss: 0.4317 - val_accuracy: 0.8939\n",
            "Epoch 4/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5824 - accuracy: 0.6489 - val_loss: 0.3909 - val_accuracy: 0.8939\n",
            "Epoch 5/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5523 - accuracy: 0.7080 - val_loss: 0.3529 - val_accuracy: 0.8939\n",
            "Epoch 6/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5267 - accuracy: 0.7385 - val_loss: 0.3190 - val_accuracy: 0.9091\n",
            "Epoch 7/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.5057 - accuracy: 0.7863 - val_loss: 0.2967 - val_accuracy: 0.9091\n",
            "Epoch 8/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4896 - accuracy: 0.8206 - val_loss: 0.2810 - val_accuracy: 0.9015\n",
            "Epoch 9/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4769 - accuracy: 0.8244 - val_loss: 0.2739 - val_accuracy: 0.9015\n",
            "Epoch 10/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4672 - accuracy: 0.8263 - val_loss: 0.2675 - val_accuracy: 0.9015\n",
            "Epoch 11/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4598 - accuracy: 0.8263 - val_loss: 0.2655 - val_accuracy: 0.9015\n",
            "Epoch 12/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4515 - accuracy: 0.8397 - val_loss: 0.2683 - val_accuracy: 0.9015\n",
            "Epoch 13/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4410 - accuracy: 0.8550 - val_loss: 0.2656 - val_accuracy: 0.9015\n",
            "Epoch 14/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4308 - accuracy: 0.8550 - val_loss: 0.2651 - val_accuracy: 0.9015\n",
            "Epoch 15/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4196 - accuracy: 0.8550 - val_loss: 0.2694 - val_accuracy: 0.9015\n",
            "Epoch 16/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.4093 - accuracy: 0.8511 - val_loss: 0.2716 - val_accuracy: 0.9015\n",
            "Epoch 17/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3995 - accuracy: 0.8531 - val_loss: 0.2727 - val_accuracy: 0.9015\n",
            "Epoch 18/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3906 - accuracy: 0.8416 - val_loss: 0.2767 - val_accuracy: 0.9015\n",
            "Epoch 19/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3824 - accuracy: 0.8531 - val_loss: 0.2776 - val_accuracy: 0.9015\n",
            "Epoch 20/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3739 - accuracy: 0.8531 - val_loss: 0.2828 - val_accuracy: 0.9015\n",
            "Epoch 21/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3675 - accuracy: 0.8511 - val_loss: 0.2883 - val_accuracy: 0.9015\n",
            "Epoch 22/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3606 - accuracy: 0.8492 - val_loss: 0.2915 - val_accuracy: 0.9015\n",
            "Epoch 23/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3565 - accuracy: 0.8492 - val_loss: 0.2986 - val_accuracy: 0.9015\n",
            "Epoch 24/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3488 - accuracy: 0.8531 - val_loss: 0.3024 - val_accuracy: 0.9015\n",
            "Epoch 25/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3461 - accuracy: 0.8492 - val_loss: 0.3075 - val_accuracy: 0.9015\n",
            "Epoch 26/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3405 - accuracy: 0.8492 - val_loss: 0.3085 - val_accuracy: 0.9015\n",
            "Epoch 27/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8531 - val_loss: 0.3139 - val_accuracy: 0.9015\n",
            "Epoch 28/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3359 - accuracy: 0.8492 - val_loss: 0.3184 - val_accuracy: 0.9015\n",
            "Epoch 29/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3336 - accuracy: 0.8531 - val_loss: 0.3220 - val_accuracy: 0.9015\n",
            "Epoch 30/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3301 - accuracy: 0.8531 - val_loss: 0.3275 - val_accuracy: 0.9015\n",
            "Epoch 31/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3283 - accuracy: 0.8492 - val_loss: 0.3352 - val_accuracy: 0.9015\n",
            "Epoch 32/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3268 - accuracy: 0.8569 - val_loss: 0.3345 - val_accuracy: 0.9015\n",
            "Epoch 33/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3250 - accuracy: 0.8588 - val_loss: 0.3398 - val_accuracy: 0.9015\n",
            "Epoch 34/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3237 - accuracy: 0.8550 - val_loss: 0.3395 - val_accuracy: 0.9015\n",
            "Epoch 35/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3223 - accuracy: 0.8588 - val_loss: 0.3459 - val_accuracy: 0.8864\n",
            "Epoch 36/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3232 - accuracy: 0.8569 - val_loss: 0.3444 - val_accuracy: 0.9015\n",
            "Epoch 37/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3213 - accuracy: 0.8569 - val_loss: 0.3508 - val_accuracy: 0.8864\n",
            "Epoch 38/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8588 - val_loss: 0.3486 - val_accuracy: 0.9015\n",
            "Epoch 39/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3192 - accuracy: 0.8607 - val_loss: 0.3502 - val_accuracy: 0.9015\n",
            "Epoch 40/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8607 - val_loss: 0.3521 - val_accuracy: 0.9015\n",
            "Epoch 41/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3188 - accuracy: 0.8569 - val_loss: 0.3538 - val_accuracy: 0.9015\n",
            "Epoch 42/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8626 - val_loss: 0.3560 - val_accuracy: 0.9015\n",
            "Epoch 43/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3164 - accuracy: 0.8645 - val_loss: 0.3590 - val_accuracy: 0.9015\n",
            "Epoch 44/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3166 - accuracy: 0.8607 - val_loss: 0.3574 - val_accuracy: 0.9015\n",
            "Epoch 45/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3159 - accuracy: 0.8569 - val_loss: 0.3604 - val_accuracy: 0.9015\n",
            "Epoch 46/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8626 - val_loss: 0.3574 - val_accuracy: 0.9015\n",
            "Epoch 47/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8645 - val_loss: 0.3619 - val_accuracy: 0.9015\n",
            "Epoch 48/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8664 - val_loss: 0.3618 - val_accuracy: 0.9015\n",
            "Epoch 49/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3140 - accuracy: 0.8645 - val_loss: 0.3625 - val_accuracy: 0.9015\n",
            "Epoch 50/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3142 - accuracy: 0.8588 - val_loss: 0.3622 - val_accuracy: 0.9015\n",
            "Epoch 51/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3126 - accuracy: 0.8664 - val_loss: 0.3661 - val_accuracy: 0.9015\n",
            "Epoch 52/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3118 - accuracy: 0.8664 - val_loss: 0.3660 - val_accuracy: 0.9015\n",
            "Epoch 53/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3154 - accuracy: 0.8645 - val_loss: 0.3724 - val_accuracy: 0.9015\n",
            "Epoch 54/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3127 - accuracy: 0.8626 - val_loss: 0.3618 - val_accuracy: 0.9015\n",
            "Epoch 55/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3107 - accuracy: 0.8702 - val_loss: 0.3715 - val_accuracy: 0.9015\n",
            "Epoch 56/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8664 - val_loss: 0.3709 - val_accuracy: 0.9015\n",
            "Epoch 57/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3108 - accuracy: 0.8702 - val_loss: 0.3705 - val_accuracy: 0.9015\n",
            "Epoch 58/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3102 - accuracy: 0.8702 - val_loss: 0.3755 - val_accuracy: 0.9015\n",
            "Epoch 59/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3100 - accuracy: 0.8664 - val_loss: 0.3751 - val_accuracy: 0.9015\n",
            "Epoch 60/70\n",
            "17/17 [==============================] - 0s 4ms/step - loss: 0.3085 - accuracy: 0.8683 - val_loss: 0.3786 - val_accuracy: 0.9015\n",
            "Epoch 61/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3081 - accuracy: 0.8664 - val_loss: 0.3742 - val_accuracy: 0.9015\n",
            "Epoch 62/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3084 - accuracy: 0.8683 - val_loss: 0.3747 - val_accuracy: 0.9015\n",
            "Epoch 63/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8683 - val_loss: 0.3776 - val_accuracy: 0.9015\n",
            "Epoch 64/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3080 - accuracy: 0.8683 - val_loss: 0.3799 - val_accuracy: 0.9015\n",
            "Epoch 65/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3069 - accuracy: 0.8683 - val_loss: 0.3812 - val_accuracy: 0.9015\n",
            "Epoch 66/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3071 - accuracy: 0.8683 - val_loss: 0.3806 - val_accuracy: 0.9015\n",
            "Epoch 67/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8683 - val_loss: 0.3785 - val_accuracy: 0.9015\n",
            "Epoch 68/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3066 - accuracy: 0.8683 - val_loss: 0.3790 - val_accuracy: 0.9015\n",
            "Epoch 69/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3057 - accuracy: 0.8683 - val_loss: 0.3821 - val_accuracy: 0.9015\n",
            "Epoch 70/70\n",
            "17/17 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8683 - val_loss: 0.3827 - val_accuracy: 0.9015\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fZF1RHlg1v3X",
        "colab_type": "text"
      },
      "source": [
        "### Scores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh3V3QdWu0VG",
        "colab_type": "code",
        "outputId": "6560a6cb-83a6-4ff3-d495-dc5fc19bba23",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        }
      },
      "source": [
        "# == Provide average scores ==\n",
        "print('Score per fold:')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Score per fold:\n",
            "> Fold 1 - Loss: 0.3937595784664154 - Accuracy: 86.36363744735718%\n",
            "> Fold 2 - Loss: 0.2673208713531494 - Accuracy: 86.36363744735718%\n",
            "> Fold 3 - Loss: 0.22840748727321625 - Accuracy: 89.90825414657593%\n",
            "> Fold 4 - Loss: 0.41978636384010315 - Accuracy: 82.56880640983582%\n",
            "> Fold 5 - Loss: 0.35698917508125305 - Accuracy: 84.40366983413696%\n",
            "> Fold 6 - Loss: 0.47559353709220886 - Accuracy: 78.899085521698%\n",
            "> Fold 7 - Loss: 0.3228831887245178 - Accuracy: 82.56880640983582%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 84.43941388811383 (+- 3.273450497239789)\n",
            "> Loss: 0.35210574311869486\n",
            "------------------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YQDKmJQ_kmdh",
        "colab_type": "text"
      },
      "source": [
        "## plot with train and test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mi0f_JObgC4C",
        "colab_type": "code",
        "outputId": "e0598f11-ebd2-499e-a7b7-c9e835ca231f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('model accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.ylim(0,1)\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "outputId": "bd043086-eb9d-408d-c345-babf93856a6e",
        "id": "MZqTTLklFGp6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "\n",
        "plt.legend(['train', 'test'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W7jx7N_ZwHgm",
        "colab_type": "text"
      },
      "source": [
        "Confusion matrix "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWH11sjmwJ4P",
        "colab_type": "code",
        "outputId": "b04a3934-92ba-4444-8615-fa28c0c12e0d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        }
      },
      "source": [
        "X_conf_matrix = X.iloc[test]\n",
        "y_conf_matrix = y.iloc[test]\n",
        "predicted_conf_matrix = model.predict_classes(X_conf_matrix)\n",
        "\n",
        "conf_matrix = confusion_matrix(y_conf_matrix.values.argmax(axis=1), predicted_conf_matrix)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a33ebbdd8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RwVgSUc6uC6Y",
        "colab_type": "text"
      },
      "source": [
        "### Save model \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2XZ1N0JuIop",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save('featureModelPlPresup.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ey04c2ykpMf6",
        "colab_type": "text"
      },
      "source": [
        "## Check RANDOM FOREST Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkLf7YkgpiMc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qLVy_y00pm_s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "random_forest = RandomForestClassifier(\n",
        "    n_estimators = 2000, \n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "psCPtOdbpPzU",
        "colab_type": "code",
        "outputId": "f95bdd3e-0597-41a2-dfa8-daea97dd1480",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        " X_train, X_test, y_train, y_test = train_test_split(X, ml_classifier_labels, test_size=0.33, random_state=42)\n",
        "random_forest.fit(X_train, y_train)"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
              "                       criterion='gini', max_depth=None, max_features='auto',\n",
              "                       max_leaf_nodes=None, max_samples=None,\n",
              "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
              "                       min_samples_leaf=1, min_samples_split=2,\n",
              "                       min_weight_fraction_leaf=0.0, n_estimators=2000,\n",
              "                       n_jobs=None, oob_score=False, random_state=None,\n",
              "                       verbose=0, warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r7eal1FbzzLu",
        "colab_type": "code",
        "outputId": "8c277d08-c38e-4d63-f837-4516d3fb2c95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        }
      },
      "source": [
        "predict = random_forest.predict(X_test)\n",
        "print(predict.shape)\n",
        "print(np.unique(predict))\n",
        "print(y_test.shape)\n",
        "print(np.unique(y_test, return_counts = True))\n",
        "conf_matrix = confusion_matrix(y_test, predict)\n",
        "sns.heatmap(conf_matrix, annot=True, fmt=\"d\")"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(253,)\n",
            "['no' 'yes']\n",
            "(253,)\n",
            "(array(['no', 'yes'], dtype=object), array([ 97, 156]))\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f6a33c99a90>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LO2MtVpmqexD",
        "colab_type": "code",
        "outputId": "1132e8ac-99cf-41a7-8c53-35d8ba8c7219",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "random_forest.score(X_test, y_test)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8142292490118577"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    }
  ]
}