{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "bert-poc.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fejcvk/data-mining/blob/polbert-experiment/src/notebookes/bert_poc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LS8rpwLvQJjN",
        "colab_type": "text"
      },
      "source": [
        "# Preprocessing\n",
        "\n",
        "For now we need just pandas for parsing dataset and transformers for BERT"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lAuMoWx0QJjO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "outputId": "a1ec1dae-6236-48c8-c144-7db323c4bc64"
      },
      "source": [
        "!pip install transformers\n",
        "import pandas as pd\n",
        "from transformers import *\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch.utils.tensorboard import SummaryWriter\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (2.7.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.85)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.12.31)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.38.0)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.38)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.21.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tokenizers==0.5.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: botocore<1.16.0,>=1.15.31 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (1.15.31)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.9.5)\n",
            "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.6/dist-packages (from boto3->transformers) (0.3.3)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.14.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.12.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2019.11.28)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (2.8.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.16.0,>=1.15.31->boto3->transformers) (0.15.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s0lj_syhQJjU",
        "colab_type": "text"
      },
      "source": [
        "Read excel file, skip headers and 1st row with column nasmes\n",
        "\n",
        "PS : Small hack with deleting biggest files from dataset. Gonna be fixed after obtaining bigger resources"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtWjVFAHQJjU",
        "colab_type": "code",
        "outputId": "91ac5788-444e-4de9-a5f8-ccc4487a7fe5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "df= pd.read_excel('dataset.xlsx', header=None, skiprows=1)\n",
        "df.drop(df[df[4].map(len) > 160 ].index, inplace=True)\n",
        "df.reset_index()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>index</th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>1203</td>\n",
              "      <td>I said, \"I have a test, I'm gonna fail biology...</td>\n",
              "      <td>1</td>\n",
              "      <td>To which I said that I was to write a class te...</td>\n",
              "      <td>Ja na to, że mam klasówkę, że zawalę biologię ...</td>\n",
              "      <td>N</td>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>2531</td>\n",
              "      <td>mówienia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>nie ma hasła</td>\n",
              "      <td>[elipsa]</td>\n",
              "      <td>o?</td>\n",
              "      <td>?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>mam klasówkę</td>\n",
              "      <td>brak</td>\n",
              "      <td>na to</td>\n",
              "      <td>0</td>\n",
              "      <td>future</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>E</td>\n",
              "      <td>?</td>\n",
              "      <td>N</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>1671</td>\n",
              "      <td>Gliński did not have to turn his head to guess...</td>\n",
              "      <td>1</td>\n",
              "      <td>Gliński did not have to turn his head to guess...</td>\n",
              "      <td>Ani że na progu stanął właśnie Romanyczko.</td>\n",
              "      <td>?</td>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>2978</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>?</td>\n",
              "      <td>nie ma hasła</td>\n",
              "      <td>[elipsa]</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>Gliński nie musiał odwracać głowy, by nie domy...</td>\n",
              "      <td>na progu stanął właśnie Romanyczko.</td>\n",
              "      <td>past</td>\n",
              "      <td>nie musiał odwracać głowy, by domyślić się,</td>\n",
              "      <td>0</td>\n",
              "      <td>past</td>\n",
              "      <td>no</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>2441</td>\n",
              "      <td>Then he'll bring the Chinese back.</td>\n",
              "      <td>1</td>\n",
              "      <td>Earlier Ukrainians were said to come and work,...</td>\n",
              "      <td>Potem, że się przywiezie Chińczyków.</td>\n",
              "      <td>N</td>\n",
              "      <td>eliptyczne</td>\n",
              "      <td>3489</td>\n",
              "      <td>mówienia</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>nie ma hasła</td>\n",
              "      <td>[elipsa]</td>\n",
              "      <td>?</td>\n",
              "      <td>?</td>\n",
              "      <td>NaN</td>\n",
              "      <td>się przywiezie Chińczyków.</td>\n",
              "      <td>past</td>\n",
              "      <td>elipsa (mówiło się)</td>\n",
              "      <td>0</td>\n",
              "      <td>future</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>945</td>\n",
              "      <td>He got weaker and weaker and felt that it was ...</td>\n",
              "      <td>0</td>\n",
              "      <td>He got weaker and weaker and felt that it was ...</td>\n",
              "      <td>Słabł coraz bardziej, czuł, że to kwestia zale...</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>2119</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>percepcyjny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>http://plwordnet.pwr.wroc.pl/wordnet/b8d08aa2-...</td>\n",
              "      <td>[e] czuć, że_</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>Słabł coraz bardziej, nie czuł, że to kwestia ...</td>\n",
              "      <td>to kwestia zaledwie minut.</td>\n",
              "      <td>past</td>\n",
              "      <td>czuł</td>\n",
              "      <td>0</td>\n",
              "      <td>inne</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>947</td>\n",
              "      <td>However, people who are very seriously ill, wh...</td>\n",
              "      <td>0</td>\n",
              "      <td>However, people who are very seriously ill, wh...</td>\n",
              "      <td>Jednak ludzie bardzo ciężko chorzy, gdy już cz...</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>2123</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>percepcyjny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>2</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>http://plwordnet.pwr.wroc.pl/wordnet/b8d08aa2-...</td>\n",
              "      <td>[e] czuć, że_</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>medycyna też nie może im już pomóc</td>\n",
              "      <td>present</td>\n",
              "      <td>czują</td>\n",
              "      <td>0</td>\n",
              "      <td>present</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>N</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1974</th>\n",
              "      <td>2590</td>\n",
              "      <td>1004</td>\n",
              "      <td>The police immediately established that the ca...</td>\n",
              "      <td>1</td>\n",
              "      <td>The police immediately found out the car to be...</td>\n",
              "      <td>Policjanci natychmiast ustalili, że samochód n...</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>2377</td>\n",
              "      <td>wnioskowania</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>410</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>http://plwordnet.pwr.wroc.pl/wordnet/bc2c6ba8-...</td>\n",
              "      <td>ustalić [na podstawie czego], że_</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>samochód należy do jednego ze szczecińskich pr...</td>\n",
              "      <td>past</td>\n",
              "      <td>ustalili</td>\n",
              "      <td>0</td>\n",
              "      <td>present</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1975</th>\n",
              "      <td>2591</td>\n",
              "      <td>1045</td>\n",
              "      <td>It was established that both girls could stay ...</td>\n",
              "      <td>1</td>\n",
              "      <td>It has been established that both girls accomp...</td>\n",
              "      <td>Udało się ustalić, że obie dziewczynki mogą pr...</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>2407</td>\n",
              "      <td>wnioskowania</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>410</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>http://plwordnet.pwr.wroc.pl/wordnet/bc2c6ba8-...</td>\n",
              "      <td>ustalić [na podstawie czego], że_</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>obie dziewczynki mogą przebywać w mieszkaniu p...</td>\n",
              "      <td>past</td>\n",
              "      <td>Udało się ustalić</td>\n",
              "      <td>0</td>\n",
              "      <td>present</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1976</th>\n",
              "      <td>2592</td>\n",
              "      <td>2258</td>\n",
              "      <td>It was established that he had close social re...</td>\n",
              "      <td>1</td>\n",
              "      <td>It was established that he had close social re...</td>\n",
              "      <td>Ustalono, że łączą go z niektórymi członkami g...</td>\n",
              "      <td>N</td>\n",
              "      <td>1</td>\n",
              "      <td>3369</td>\n",
              "      <td>wnioskowania</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>410</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>http://plwordnet.pwr.wroc.pl/wordnet/bc2c6ba8-...</td>\n",
              "      <td>ustalić [na podstawie czego], że_</td>\n",
              "      <td>o</td>\n",
              "      <td>o</td>\n",
              "      <td>NaN</td>\n",
              "      <td>łączą go z niektórymi członkami grupy bliskie...</td>\n",
              "      <td>past</td>\n",
              "      <td>ustalono</td>\n",
              "      <td>0</td>\n",
              "      <td>present</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1977</th>\n",
              "      <td>2594</td>\n",
              "      <td>443</td>\n",
              "      <td>Of course you can love if you see that this lo...</td>\n",
              "      <td>1</td>\n",
              "      <td>Of course you can love someone if you see that...</td>\n",
              "      <td>Oczywiście, że można kochać, jeśli zobaczy się...</td>\n",
              "      <td>N</td>\n",
              "      <td>warunkowe</td>\n",
              "      <td>436</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>411</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>http://plwordnet.pwr.wroc.pl/wordnet/b9e36504-...</td>\n",
              "      <td>[e] zobaczyć, że_</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ona miała do niej prawo.</td>\n",
              "      <td>future</td>\n",
              "      <td>zobaczy się</td>\n",
              "      <td>0</td>\n",
              "      <td>past</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1978</th>\n",
              "      <td>2595</td>\n",
              "      <td>444</td>\n",
              "      <td>Of course you can love if you see that this lo...</td>\n",
              "      <td>1</td>\n",
              "      <td>Of course you can love someone if you see that...</td>\n",
              "      <td>Oczywiście, że można kochać, jeśli zobaczy się...</td>\n",
              "      <td>N</td>\n",
              "      <td>warunkowe</td>\n",
              "      <td>436</td>\n",
              "      <td>epistemiczny</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>411</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>http://plwordnet.pwr.wroc.pl/wordnet/b9e36504-...</td>\n",
              "      <td>[e] zobaczyć, że_</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>\"+\"</td>\n",
              "      <td>NaN</td>\n",
              "      <td>ta miłość nie wzięła się z niczego</td>\n",
              "      <td>future</td>\n",
              "      <td>zobaczy się</td>\n",
              "      <td>0</td>\n",
              "      <td>past</td>\n",
              "      <td>nie dotyczy</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>N</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>E</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1979 rows × 34 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      index     0  ...   31  32\n",
              "0         0  1203  ...    N NaN\n",
              "1         1  1671  ...  NaN NaN\n",
              "2         2  2441  ...  NaN NaN\n",
              "3         3   945  ...  NaN NaN\n",
              "4         4   947  ...    E NaN\n",
              "...     ...   ...  ...  ...  ..\n",
              "1974   2590  1004  ...  NaN NaN\n",
              "1975   2591  1045  ...  NaN NaN\n",
              "1976   2592  2258  ...  NaN NaN\n",
              "1977   2594   443  ...    E NaN\n",
              "1978   2595   444  ...    E NaN\n",
              "\n",
              "[1979 rows x 34 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7N8cby-nQJjY",
        "colab_type": "text"
      },
      "source": [
        "For our smaller version of dataset just take two features that we are interested in, namely T PL and GOLD<T,H>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ojgr5FaqQJjZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = df[[4, 5]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "77iv84InQJjc",
        "colab_type": "code",
        "outputId": "d476a928-1df7-4e07-9449-cf23f434f4fa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        }
      },
      "source": [
        "dataset.head"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<bound method NDFrame.head of                                                       4  5\n",
              "0     Ja na to, że mam klasówkę, że zawalę biologię ...  N\n",
              "1            Ani że na progu stanął właśnie Romanyczko.  ?\n",
              "2                  Potem, że się przywiezie Chińczyków.  N\n",
              "3     Słabł coraz bardziej, czuł, że to kwestia zale...  N\n",
              "4     Jednak ludzie bardzo ciężko chorzy, gdy już cz...  N\n",
              "...                                                 ... ..\n",
              "2590  Policjanci natychmiast ustalili, że samochód n...  N\n",
              "2591  Udało się ustalić, że obie dziewczynki mogą pr...  N\n",
              "2592  Ustalono, że łączą go z niektórymi członkami g...  N\n",
              "2594  Oczywiście, że można kochać, jeśli zobaczy się...  N\n",
              "2595  Oczywiście, że można kochać, jeśli zobaczy się...  N\n",
              "\n",
              "[1979 rows x 2 columns]>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lm3X0MrYQJjf",
        "colab_type": "text"
      },
      "source": [
        "Change labels of ECN for numeric values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hUBnlvgIQJjg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labels = {'E':0,'C':1,'N':2,'?':3}\n",
        "\n",
        "for idx, row in dataset.iterrows():\n",
        "    row[5] = labels[row[5]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jDFnAzgCQJjj",
        "colab_type": "code",
        "outputId": "bd559d13-04fe-4501-eaf4-39e169e797b0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "dataset"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Ja na to, że mam klasówkę, że zawalę biologię ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Ani że na progu stanął właśnie Romanyczko.</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Potem, że się przywiezie Chińczyków.</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Słabł coraz bardziej, czuł, że to kwestia zale...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Jednak ludzie bardzo ciężko chorzy, gdy już cz...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2590</th>\n",
              "      <td>Policjanci natychmiast ustalili, że samochód n...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2591</th>\n",
              "      <td>Udało się ustalić, że obie dziewczynki mogą pr...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2592</th>\n",
              "      <td>Ustalono, że łączą go z niektórymi członkami g...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2594</th>\n",
              "      <td>Oczywiście, że można kochać, jeśli zobaczy się...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2595</th>\n",
              "      <td>Oczywiście, że można kochać, jeśli zobaczy się...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1979 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                      4  5\n",
              "0     Ja na to, że mam klasówkę, że zawalę biologię ...  2\n",
              "1            Ani że na progu stanął właśnie Romanyczko.  3\n",
              "2                  Potem, że się przywiezie Chińczyków.  2\n",
              "3     Słabł coraz bardziej, czuł, że to kwestia zale...  2\n",
              "4     Jednak ludzie bardzo ciężko chorzy, gdy już cz...  2\n",
              "...                                                 ... ..\n",
              "2590  Policjanci natychmiast ustalili, że samochód n...  2\n",
              "2591  Udało się ustalić, że obie dziewczynki mogą pr...  2\n",
              "2592  Ustalono, że łączą go z niektórymi członkami g...  2\n",
              "2594  Oczywiście, że można kochać, jeśli zobaczy się...  2\n",
              "2595  Oczywiście, że można kochać, jeśli zobaczy się...  2\n",
              "\n",
              "[1979 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMzTSIRrQJjm",
        "colab_type": "code",
        "outputId": "363dce4d-ac70-4361-c365-c20da1327824",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "dataset[5].value_counts()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    1214\n",
              "0     634\n",
              "3      73\n",
              "1      58\n",
              "Name: 5, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mj_Fsx6RQJjp",
        "colab_type": "code",
        "outputId": "83a6ff32-e545-45fe-8981-afdfaf838151",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len = 0\n",
        "m_idx = 0\n",
        "for idx,row in dataset.iterrows():\n",
        "    l = len(row[4])\n",
        "    if l > max_len:\n",
        "        max_len = l\n",
        "        m_idx = idx\n",
        "print(m_idx)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "37\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DMGWi_5oQJjr",
        "colab_type": "code",
        "outputId": "3777b468-d41a-4b8e-d36d-67f6969a1e1a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "print(dataset[4][m_idx])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Za tę moją słabość stokrotnie Cię przepraszam, ale musisz już brać pod uwagę, że jestem stary, zmęczony, przepracowany, chory i nie mam już tyle sił co dawniej.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jnyxW57oQJju",
        "colab_type": "code",
        "outputId": "431f0f19-4d1f-465d-fc23-04e572950898",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "!pip install sklearn\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.6/dist-packages (0.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.11.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (1.18.2)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->sklearn) (0.14.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gWyQKEhGQJjx",
        "colab_type": "text"
      },
      "source": [
        "# Polbert\n",
        "\n",
        "Here we import pretrained version of Bert for Polish language"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0MH6jDKQJjx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = BertForMaskedLM.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"dkleczek/bert-base-polish-uncased-v1\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FTDjTaE9QJj1",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "Tokenize every sentence from our dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynst0zmtQJj2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenized = dataset[4].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mZPS_Q89QJj5",
        "colab_type": "code",
        "outputId": "9fa515e4-d29d-47d9-d1ed-a2105a0075a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "tokenized.values"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([list([2, 2055, 1898, 1907, 16, 2095, 2040, 15701, 1889, 3118, 16, 2095, 32091, 1014, 12071, 1014, 51, 1893, 15887, 1012, 1906, 27508, 2165, 4785, 18, 4]),\n",
              "       list([2, 2937, 2095, 1898, 26468, 40126, 1019, 29480, 6977, 1013, 7150, 18, 4]),\n",
              "       list([2, 3006, 16, 2095, 2243, 11319, 2713, 11007, 8572, 1889, 18, 4]),\n",
              "       ...,\n",
              "       list([2, 21075, 16, 2095, 34538, 2126, 2015, 68, 3694, 2818, 1998, 20444, 5233, 26559, 17765, 39327, 51, 2095, 4384, 1937, 12294, 2047, 38360, 2713, 1910, 68, 43080, 9916, 5134, 12522, 3942, 18, 4]),\n",
              "       list([2, 31040, 16, 2095, 29801, 6289, 1015, 16, 10865, 3403, 2243, 16, 2095, 2259, 16879, 1015, 1893, 40065, 1923, 2243, 68, 4109, 16, 2095, 2499, 3089, 1906, 3115, 3410, 18, 4]),\n",
              "       list([2, 31040, 16, 2095, 29801, 6289, 1015, 16, 10865, 3403, 2243, 16, 2095, 2259, 16879, 1015, 1893, 40065, 1923, 2243, 68, 4109, 16, 2095, 2499, 3089, 1906, 3115, 3410, 18, 4])],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaDi0KStQJj8",
        "colab_type": "text"
      },
      "source": [
        "## Padding\n",
        "\n",
        "We need to have input of the same lenght in order to feed BERT once (we will get performance speed). This will be some simple python string manipulations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5aSvvbmTQJj8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len = 0\n",
        "for i in tokenized.values:\n",
        "    if len(i) > max_len:\n",
        "        max_len = len(i)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGx5Tv89QJj_",
        "colab_type": "code",
        "outputId": "a4352b2e-b43a-4f56-8f00-a0fd9db4a57b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "max_len"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "47"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m6khNyYFQJkC",
        "colab_type": "text"
      },
      "source": [
        "Maybe we can consider shortening some sentences here"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrk93wfaQJkC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kKCOSXjXQJkF",
        "colab_type": "code",
        "outputId": "36e6de7a-e281-4a24-e2df-dc7b54e0fc27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "padded"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[    2,  2055,  1898, ...,     0,     0,     0],\n",
              "       [    2,  2937,  2095, ...,     0,     0,     0],\n",
              "       [    2,  3006,    16, ...,     0,     0,     0],\n",
              "       ...,\n",
              "       [    2, 21075,    16, ...,     0,     0,     0],\n",
              "       [    2, 31040,    16, ...,     0,     0,     0],\n",
              "       [    2, 31040,    16, ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ziFFn1CAQJkI",
        "colab_type": "code",
        "outputId": "218dc6b4-345f-4557-9db7-38d373d34375",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "np.array(padded).shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1979, 47)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iFdLTJj4SX0-",
        "colab_type": "text"
      },
      "source": [
        "## Computing embedding using BERT\n",
        "\n",
        "Now we do create cube of 146(tokens per row) * 768 (hidden layers) * 2596"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydNiAHljQJkK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "input_ids = torch.tensor(np.array(padded))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8wHwKIMGQJkM",
        "colab_type": "code",
        "outputId": "5bb767a1-87a2-4d21-d577-600d4b0a621c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 136
        }
      },
      "source": [
        "input_ids"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[    2,  2055,  1898,  ...,     0,     0,     0],\n",
              "        [    2,  2937,  2095,  ...,     0,     0,     0],\n",
              "        [    2,  3006,    16,  ...,     0,     0,     0],\n",
              "        ...,\n",
              "        [    2, 21075,    16,  ...,     0,     0,     0],\n",
              "        [    2, 31040,    16,  ...,     0,     0,     0],\n",
              "        [    2, 31040,    16,  ...,     0,     0,     0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RhaInBWiQJkP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "    last_hidden_states = model(input_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a6yN8AJkwCTT",
        "colab_type": "text"
      },
      "source": [
        "We will extract two sets of embeddings. One for CSL only (2D array) and one for the whole cube"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7J8kG1XwNyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "features = last_hidden_states[0][:,:,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARcBn555mnQm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cls_features = last_hidden_states[0][:,0,:]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTMLzojKmuno",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "2581c62b-b71b-492c-9d7e-c72a4c8b3835"
      },
      "source": [
        "features.shape"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1979, 47, 60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1sQC37m4wYK2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e44ace33-5d4b-43aa-e063-8fac02f3b4cc"
      },
      "source": [
        "cls_features.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1979, 60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xxR7-ir-wlDy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_labes = np.array(dataset[5], dtype=np.int64)\n",
        "y_labes.shape\n",
        "y_labes = torch.from_numpy(y_labes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFndQqv-xLNy",
        "colab_type": "text"
      },
      "source": [
        "## Feed Forward Neural Network\n",
        "Creating Feed Forward Neural Network which will take as an input vector of embeddings and return one of semantic classes. Firstly we will do it for 2d CLS matrix"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iY8WmSEkxZV2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.datasets as ds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4vFWqVXTxuk2",
        "colab_type": "text"
      },
      "source": [
        "### Creating dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ITzN8xfvxihR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 181
        },
        "outputId": "49d19f80-5173-4565-ed3e-648547d4b543"
      },
      "source": [
        "train_features, test_features, train_labels, test_labels = train_test_split(cls_features, y_labes)\n",
        "print(train_labels)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-449f65f03378>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_labes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_test_split' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qct6HbphyCVV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = int(train_features.shape[0] / 100)\n",
        "n_iters = batch_size * 100\n",
        "epochs = int(n_iters / (len(train_features) / batch_size))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hGGi59u1E62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class FeedforwardNeuralNetModel(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
        "        super(FeedforwardNeuralNetModel, self).__init__()\n",
        "        # Linear function\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
        "        # Non-linearity\n",
        "        self.relu = nn.ReLU()\n",
        "        # Linear function (readout)\n",
        "        self.fc2 = nn.Linear(hidden_dim, output_dim)  \n",
        "\n",
        "    def forward(self, x):\n",
        "        # Linear function\n",
        "        out = self.fc1(x)\n",
        "        # Non-linearity\n",
        "        out = self.relu(out)\n",
        "        # Linear function (readout)\n",
        "        out = self.fc2(out)\n",
        "        return out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6F86gYor1z_p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f57176fb-9de1-40f3-cd78-36d6e137d3c3"
      },
      "source": [
        "input_dim = 60000\n",
        "hidden_dim = 100\n",
        "output_dim = len(labels)\n",
        "\n",
        "input_dim"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "60000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EDy7hQfj2ciB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ffnn = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cf5LG44b4C7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "loss_fn = nn.BCELoss()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WsxNME414HUA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learning_rate = 0.1\n",
        "optimizer = torch.optim.SGD(ffnn.parameters(), lr=learning_rate) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTTTazHA-HOX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def generate_batch_data(x, y, batch_size):\n",
        "    i, batch = 0, 0\n",
        "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
        "        x_batch = x[i : i + batch_size]\n",
        "        y_batch = y[i : i + batch_size]\n",
        "        yield x_batch, y_batch, batch\n",
        "    if i + batch_size < len(x):\n",
        "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
        "    if batch == 0:\n",
        "        yield x, y, 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tnz6d-894cqm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 684
        },
        "outputId": "61b3f6b5-ebc9-4444-8272-3014150d35b0"
      },
      "source": [
        "for epoch in range(0,epochs):\n",
        "  ffnn.train(True)\n",
        "  train_loss = 0 \n",
        "  for x_batch, y_batch, batch in generate_batch_data(train_features, train_labels, batch_size):\n",
        "    y_pred = ffnn(x_batch)\n",
        "    print(y_pred)\n",
        "    print(y_batch)\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_fn(y_pred, y_batch)\n",
        "\n",
        "    # Getting gradients w.r.t. parameters\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    train_loss += loss.item()"
      ],
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-0.0239,  0.8916,  0.7854,  1.7021],\n",
            "        [-0.4758,  0.8637,  0.2449,  0.8873],\n",
            "        [ 0.1192,  1.2056,  0.3283,  1.1945],\n",
            "        [-0.2715,  0.9123,  0.4954,  0.9474],\n",
            "        [-0.3159,  0.8381,  0.6775,  0.5324],\n",
            "        [-0.3117,  0.7091,  0.4444,  0.6947],\n",
            "        [-0.2734,  0.8192,  0.5182,  0.5749],\n",
            "        [-0.3396,  0.9162,  0.5793,  0.8510],\n",
            "        [-0.3934,  1.3569,  0.6973,  0.4621],\n",
            "        [-0.2140,  0.9693,  0.5053,  1.2807],\n",
            "        [-0.1567,  0.5827,  0.3734,  0.6932],\n",
            "        [-0.3501,  0.8327,  0.5674,  0.7219],\n",
            "        [-0.3085,  0.8453,  0.6104,  0.9911],\n",
            "        [-0.1493,  0.7515,  0.5648,  0.8816]], grad_fn=<AddmmBackward>)\n",
            "tensor([0, 0, 2, 0, 0, 0, 2, 2, 2, 2, 2, 1, 2, 0])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py:498: UserWarning: Using a target size (torch.Size([14])) that is different to the input size (torch.Size([14, 4])) is deprecated. Please ensure they have the same size.\n",
            "  return F.binary_cross_entropy(input, target, weight=self.weight, reduction=self.reduction)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-c70ad0f8c756>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0;31m# Getting gradients w.r.t. parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    497\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy\u001b[0;34m(input, target, weight, size_average, reduce, reduction)\u001b[0m\n\u001b[1;32m   2068\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2069\u001b[0m         raise ValueError(\"Target and input must have the same number of elements. target nelement ({}) \"\n\u001b[0;32m-> 2070\u001b[0;31m                          \"!= input nelement ({})\".format(target.numel(), input.numel()))\n\u001b[0m\u001b[1;32m   2071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2072\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mweight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target and input must have the same number of elements. target nelement (14) != input nelement (56)"
          ]
        }
      ]
    }
  ]
}