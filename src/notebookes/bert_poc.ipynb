{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/Fejcvk/data-mining/blob/polbert-experiment/src/notebookes/bert_poc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LS8rpwLvQJjN"
   },
   "source": [
    "# Preprocessing\n",
    "\n",
    "For now we need just pandas for parsing dataset and transformers for BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 408
    },
    "colab_type": "code",
    "id": "lAuMoWx0QJjO",
    "outputId": "a1ec1dae-6236-48c8-c144-7db323c4bc64"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Solving environment: done\n",
      "\n",
      "\n",
      "==> WARNING: A newer version of conda exists. <==\n",
      "  current version: 4.5.12\n",
      "  latest version: 4.8.3\n",
      "\n",
      "Please update conda by running\n",
      "\n",
      "    $ conda update -n base -c defaults conda\n",
      "\n",
      "\n",
      "\n",
      "# All requested packages already installed.\n",
      "\n",
      "Requirement already satisfied: transformers in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (2.7.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: boto3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (1.12.27)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (3.0.4)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.6)\n",
      "Requirement already satisfied: tokenizers==0.5.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.5.2)\n",
      "Requirement already satisfied: requests in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2.20.0)\n",
      "Requirement already satisfied: sacremoses in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.0.38)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (2020.2.20)\n",
      "Requirement already satisfied: sentencepiece in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (0.1.85)\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from transformers) (1.15.4)\n",
      "Requirement already satisfied: s3transfer<0.4.0,>=0.3.0 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->transformers) (0.3.3)\n",
      "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->transformers) (0.9.4)\n",
      "Requirement already satisfied: botocore<1.16.0,>=1.15.27 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from boto3->transformers) (1.15.27)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2019.11.28)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (2.6)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from requests->transformers) (1.23)\n",
      "Requirement already satisfied: click in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (6.7)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (1.11.0)\n",
      "Requirement already satisfied: joblib in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sacremoses->transformers) (0.14.1)\n",
      "Requirement already satisfied: docutils<0.16,>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (0.14)\n",
      "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from botocore<1.16.0,>=1.15.27->boto3->transformers) (2.7.3)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!conda update nbformat -y\n",
    "!pip install transformers\n",
    "import pandas as pd\n",
    "from transformers import *\n",
    "import numpy as np\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "s0lj_syhQJjU"
   },
   "source": [
    "Read excel file, skip headers and 1st row with column nasmes\n",
    "\n",
    "PS : Small hack with deleting biggest files from dataset. Gonna be fixed after obtaining bigger resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "vtWjVFAHQJjU",
    "outputId": "91ac5788-444e-4de9-a5f8-ccc4487a7fe5",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df= pd.read_excel('dataset.xlsx', header=None, skiprows=1)\n",
    "# df.drop(df[df[4].map(len) > 250 ].index, inplace=True)\n",
    "# df.reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7N8cby-nQJjY"
   },
   "source": [
    "For our smaller version of dataset just take two features that we are interested in, namely T PL and GOLD<T,H>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ojgr5FaqQJjZ"
   },
   "outputs": [],
   "source": [
    "dataset = df[[4, 5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "colab_type": "code",
    "id": "77iv84InQJjc",
    "outputId": "d476a928-1df7-4e07-9449-cf23f434f4fa"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of                                                       4  5\n",
       "0     Ja na to, że mam klasówkę, że zawalę biologię ...  N\n",
       "1            Ani że na progu stanął właśnie Romanyczko.  ?\n",
       "2                  Potem, że się przywiezie Chińczyków.  N\n",
       "3     Słabł coraz bardziej, czuł, że to kwestia zale...  N\n",
       "4     Jednak ludzie bardzo ciężko chorzy, gdy już cz...  N\n",
       "5     To znaczy, że szatan jest w desperacji, przeds...  N\n",
       "6     Zresztą, w celi wcale nie czuło się, że jest maj.  E\n",
       "7                      Czuję, że już mnie nie kochasz.   N\n",
       "8                 A ja czuję, że nic z tego nie będzie.  N\n",
       "9     Choć \"Polskie Requiem\" wykonywano już w bardzo...  N\n",
       "10                  Czuję, że idą naprawdę dobre czasy.  N\n",
       "11                    czułem że coś mi brakuje że jakoś  N\n",
       "12    Ja patrzę na to tak: Niemcy czują, że ciągle m...  N\n",
       "13    Odradzam czystość, jeśli czuję, że za tym kryj...  N\n",
       "14    Po prostu czuję, że powinienem zgnić w krymina...  N\n",
       "15    Spotkaliśmy też ludzi, którzy grają w Orkiestr...  N\n",
       "16    Zarządzam trzema zespołami ludzkimi, więc czas...  N\n",
       "17    To dotyczy ludzi, którzy na co dzień mają kłop...  ?\n",
       "18    czy czujesz że jesteś stworzona do rodzenia ch...  N\n",
       "19         Czuł, że maszynistka nie spuszczają zeń oczu  E\n",
       "20    Trochę po północy ksiądz Suryn obudził się gwa...  E\n",
       "21    To oni - zagrożeni konkurencją - alarmowali, ż...  N\n",
       "22    Nie zgodzili się, argumentując, że nie stać ic...  N\n",
       "23    Sąd sprawę oddalił, argumentując, że zamiast c...  N\n",
       "24              Boję się, że to nie tylko moja porażka…  N\n",
       "25    Też miałam coś podobnego...tylko że nie bałam ...  N\n",
       "26    Magda to wtedy jak już po tym pierwszym piwie ...  N\n",
       "27     bo przede wszystkim Rosjanie boją się że wyro...  N\n",
       "28           A ja się boję, że wtedy zostanę odrzucona.  N\n",
       "29    Boimy się, że zaatakują nas bakterie, że coś n...  N\n",
       "...                                                 ... ..\n",
       "2566    Maria widzi, że atmosfera jest bardzo napięta.   E\n",
       "2567  Pomysł na opowiadanie: facet się budzi i widzi...  E\n",
       "2568                     Teraz widzę, że to bez sensu.   E\n",
       "2569         Tylko... widzę, że się z czymś męczysz...   E\n",
       "2570                            widzimy że tego nie ma.  E\n",
       "2571  Widzimy, że Jolka, tańcząc z Karolem widzi, że...  E\n",
       "2572  Widzimy, że Jolka, tańcząc z Karolem widzi, że...  E\n",
       "2573  Widzimy, że przed chwilą się poprztykali. Ela ...  E\n",
       "2574  widzisz że taka jest też w sumie nie powinna b...  E\n",
       "2575  Wraca Agnieszka. Widzi, że Łukasz śmieje się z...  E\n",
       "2576  Wszystkie inne rozróżnienia Bergsona dzielą te...  E\n",
       "2577  Przecież widziałem w twoich oczach, że mnie ko...  ?\n",
       "2578  Czasami jednak widzę, że zdanie wytrzymało pró...  E\n",
       "2579  Gołym okiem jednak widać, że poruszające się p...  E\n",
       "2580  Patrząc na fundamenty podtopionych budynków pa...  E\n",
       "2581  Widać było, że nie ustoi, że jak badyl złamany...  E\n",
       "2582  Widać było, że nie ustoi, że jak badyl złamany...  E\n",
       "2583            Widać, że jest już na ostatnich nogach.  E\n",
       "2584  Zdołał jedynie ustalić, iż system oparty jest ...  E\n",
       "2585  Ustalono, że łączą go z niektórymi członkami g...  N\n",
       "2586  Bergson gani uczonych z powodu ich \"manii wtła...  N\n",
       "2587  Nam udało się ustalić, że Malex dostał jeszcze...  N\n",
       "2588  Nieoficjalnie ustaliliśmy, że rozważane są tak...  N\n",
       "2589  Pan twierdzi na to, że pan ustalił, analizując...  N\n",
       "2590  Policjanci natychmiast ustalili, że samochód n...  N\n",
       "2591  Udało się ustalić, że obie dziewczynki mogą pr...  N\n",
       "2592  Ustalono, że łączą go z niektórymi członkami g...  N\n",
       "2593  Tu będą mogli zobaczyć, że Państwo Izrael ma k...  E\n",
       "2594  Oczywiście, że można kochać, jeśli zobaczy się...  N\n",
       "2595  Oczywiście, że można kochać, jeśli zobaczy się...  N\n",
       "\n",
       "[2596 rows x 2 columns]>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lm3X0MrYQJjf"
   },
   "source": [
    "Change labels of ECN for numeric values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hUBnlvgIQJjg"
   },
   "outputs": [],
   "source": [
    "labels = {'E':0,'C':1,'N':2,'?':3}\n",
    "\n",
    "for idx, row in dataset.iterrows():\n",
    "    row[5] = labels[row[5]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 419
    },
    "colab_type": "code",
    "id": "jDFnAzgCQJjj",
    "outputId": "bd559d13-04fe-4501-eaf4-39e169e797b0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ja na to, że mam klasówkę, że zawalę biologię ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ani że na progu stanął właśnie Romanyczko.</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Potem, że się przywiezie Chińczyków.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Słabł coraz bardziej, czuł, że to kwestia zale...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jednak ludzie bardzo ciężko chorzy, gdy już cz...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>To znaczy, że szatan jest w desperacji, przeds...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Zresztą, w celi wcale nie czuło się, że jest maj.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Czuję, że już mnie nie kochasz.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>A ja czuję, że nic z tego nie będzie.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Choć \"Polskie Requiem\" wykonywano już w bardzo...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Czuję, że idą naprawdę dobre czasy.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>czułem że coś mi brakuje że jakoś</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Ja patrzę na to tak: Niemcy czują, że ciągle m...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Odradzam czystość, jeśli czuję, że za tym kryj...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Po prostu czuję, że powinienem zgnić w krymina...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Spotkaliśmy też ludzi, którzy grają w Orkiestr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Zarządzam trzema zespołami ludzkimi, więc czas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>To dotyczy ludzi, którzy na co dzień mają kłop...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>czy czujesz że jesteś stworzona do rodzenia ch...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Czuł, że maszynistka nie spuszczają zeń oczu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Trochę po północy ksiądz Suryn obudził się gwa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>To oni - zagrożeni konkurencją - alarmowali, ż...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Nie zgodzili się, argumentując, że nie stać ic...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Sąd sprawę oddalił, argumentując, że zamiast c...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>Boję się, że to nie tylko moja porażka…</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Też miałam coś podobnego...tylko że nie bałam ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Magda to wtedy jak już po tym pierwszym piwie ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>bo przede wszystkim Rosjanie boją się że wyro...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>A ja się boję, że wtedy zostanę odrzucona.</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Boimy się, że zaatakują nas bakterie, że coś n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2566</th>\n",
       "      <td>Maria widzi, że atmosfera jest bardzo napięta.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2567</th>\n",
       "      <td>Pomysł na opowiadanie: facet się budzi i widzi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2568</th>\n",
       "      <td>Teraz widzę, że to bez sensu.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2569</th>\n",
       "      <td>Tylko... widzę, że się z czymś męczysz...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2570</th>\n",
       "      <td>widzimy że tego nie ma.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2571</th>\n",
       "      <td>Widzimy, że Jolka, tańcząc z Karolem widzi, że...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2572</th>\n",
       "      <td>Widzimy, że Jolka, tańcząc z Karolem widzi, że...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2573</th>\n",
       "      <td>Widzimy, że przed chwilą się poprztykali. Ela ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2574</th>\n",
       "      <td>widzisz że taka jest też w sumie nie powinna b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2575</th>\n",
       "      <td>Wraca Agnieszka. Widzi, że Łukasz śmieje się z...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2576</th>\n",
       "      <td>Wszystkie inne rozróżnienia Bergsona dzielą te...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2577</th>\n",
       "      <td>Przecież widziałem w twoich oczach, że mnie ko...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2578</th>\n",
       "      <td>Czasami jednak widzę, że zdanie wytrzymało pró...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2579</th>\n",
       "      <td>Gołym okiem jednak widać, że poruszające się p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2580</th>\n",
       "      <td>Patrząc na fundamenty podtopionych budynków pa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2581</th>\n",
       "      <td>Widać było, że nie ustoi, że jak badyl złamany...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2582</th>\n",
       "      <td>Widać było, że nie ustoi, że jak badyl złamany...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2583</th>\n",
       "      <td>Widać, że jest już na ostatnich nogach.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2584</th>\n",
       "      <td>Zdołał jedynie ustalić, iż system oparty jest ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2585</th>\n",
       "      <td>Ustalono, że łączą go z niektórymi członkami g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2586</th>\n",
       "      <td>Bergson gani uczonych z powodu ich \"manii wtła...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2587</th>\n",
       "      <td>Nam udało się ustalić, że Malex dostał jeszcze...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2588</th>\n",
       "      <td>Nieoficjalnie ustaliliśmy, że rozważane są tak...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2589</th>\n",
       "      <td>Pan twierdzi na to, że pan ustalił, analizując...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2590</th>\n",
       "      <td>Policjanci natychmiast ustalili, że samochód n...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>Udało się ustalić, że obie dziewczynki mogą pr...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2592</th>\n",
       "      <td>Ustalono, że łączą go z niektórymi członkami g...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2593</th>\n",
       "      <td>Tu będą mogli zobaczyć, że Państwo Izrael ma k...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>Oczywiście, że można kochać, jeśli zobaczy się...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>Oczywiście, że można kochać, jeśli zobaczy się...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2596 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      4  5\n",
       "0     Ja na to, że mam klasówkę, że zawalę biologię ...  2\n",
       "1            Ani że na progu stanął właśnie Romanyczko.  3\n",
       "2                  Potem, że się przywiezie Chińczyków.  2\n",
       "3     Słabł coraz bardziej, czuł, że to kwestia zale...  2\n",
       "4     Jednak ludzie bardzo ciężko chorzy, gdy już cz...  2\n",
       "5     To znaczy, że szatan jest w desperacji, przeds...  2\n",
       "6     Zresztą, w celi wcale nie czuło się, że jest maj.  0\n",
       "7                      Czuję, że już mnie nie kochasz.   2\n",
       "8                 A ja czuję, że nic z tego nie będzie.  2\n",
       "9     Choć \"Polskie Requiem\" wykonywano już w bardzo...  2\n",
       "10                  Czuję, że idą naprawdę dobre czasy.  2\n",
       "11                    czułem że coś mi brakuje że jakoś  2\n",
       "12    Ja patrzę na to tak: Niemcy czują, że ciągle m...  2\n",
       "13    Odradzam czystość, jeśli czuję, że za tym kryj...  2\n",
       "14    Po prostu czuję, że powinienem zgnić w krymina...  2\n",
       "15    Spotkaliśmy też ludzi, którzy grają w Orkiestr...  2\n",
       "16    Zarządzam trzema zespołami ludzkimi, więc czas...  2\n",
       "17    To dotyczy ludzi, którzy na co dzień mają kłop...  3\n",
       "18    czy czujesz że jesteś stworzona do rodzenia ch...  2\n",
       "19         Czuł, że maszynistka nie spuszczają zeń oczu  0\n",
       "20    Trochę po północy ksiądz Suryn obudził się gwa...  0\n",
       "21    To oni - zagrożeni konkurencją - alarmowali, ż...  2\n",
       "22    Nie zgodzili się, argumentując, że nie stać ic...  2\n",
       "23    Sąd sprawę oddalił, argumentując, że zamiast c...  2\n",
       "24              Boję się, że to nie tylko moja porażka…  2\n",
       "25    Też miałam coś podobnego...tylko że nie bałam ...  2\n",
       "26    Magda to wtedy jak już po tym pierwszym piwie ...  2\n",
       "27     bo przede wszystkim Rosjanie boją się że wyro...  2\n",
       "28           A ja się boję, że wtedy zostanę odrzucona.  2\n",
       "29    Boimy się, że zaatakują nas bakterie, że coś n...  2\n",
       "...                                                 ... ..\n",
       "2566    Maria widzi, że atmosfera jest bardzo napięta.   0\n",
       "2567  Pomysł na opowiadanie: facet się budzi i widzi...  0\n",
       "2568                     Teraz widzę, że to bez sensu.   0\n",
       "2569         Tylko... widzę, że się z czymś męczysz...   0\n",
       "2570                            widzimy że tego nie ma.  0\n",
       "2571  Widzimy, że Jolka, tańcząc z Karolem widzi, że...  0\n",
       "2572  Widzimy, że Jolka, tańcząc z Karolem widzi, że...  0\n",
       "2573  Widzimy, że przed chwilą się poprztykali. Ela ...  0\n",
       "2574  widzisz że taka jest też w sumie nie powinna b...  0\n",
       "2575  Wraca Agnieszka. Widzi, że Łukasz śmieje się z...  0\n",
       "2576  Wszystkie inne rozróżnienia Bergsona dzielą te...  0\n",
       "2577  Przecież widziałem w twoich oczach, że mnie ko...  3\n",
       "2578  Czasami jednak widzę, że zdanie wytrzymało pró...  0\n",
       "2579  Gołym okiem jednak widać, że poruszające się p...  0\n",
       "2580  Patrząc na fundamenty podtopionych budynków pa...  0\n",
       "2581  Widać było, że nie ustoi, że jak badyl złamany...  0\n",
       "2582  Widać było, że nie ustoi, że jak badyl złamany...  0\n",
       "2583            Widać, że jest już na ostatnich nogach.  0\n",
       "2584  Zdołał jedynie ustalić, iż system oparty jest ...  0\n",
       "2585  Ustalono, że łączą go z niektórymi członkami g...  2\n",
       "2586  Bergson gani uczonych z powodu ich \"manii wtła...  2\n",
       "2587  Nam udało się ustalić, że Malex dostał jeszcze...  2\n",
       "2588  Nieoficjalnie ustaliliśmy, że rozważane są tak...  2\n",
       "2589  Pan twierdzi na to, że pan ustalił, analizując...  2\n",
       "2590  Policjanci natychmiast ustalili, że samochód n...  2\n",
       "2591  Udało się ustalić, że obie dziewczynki mogą pr...  2\n",
       "2592  Ustalono, że łączą go z niektórymi członkami g...  2\n",
       "2593  Tu będą mogli zobaczyć, że Państwo Izrael ma k...  0\n",
       "2594  Oczywiście, że można kochać, jeśli zobaczy się...  2\n",
       "2595  Oczywiście, że można kochać, jeśli zobaczy się...  2\n",
       "\n",
       "[2596 rows x 2 columns]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "fMzTSIRrQJjm",
    "outputId": "363dce4d-ac70-4361-c365-c20da1327824"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2    1614\n",
       "0     830\n",
       "3      88\n",
       "1      64\n",
       "Name: 5, dtype: int64"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[5].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Mj_Fsx6RQJjp",
    "outputId": "83a6ff32-e545-45fe-8981-afdfaf838151"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360\n"
     ]
    }
   ],
   "source": [
    "max_len = 0\n",
    "m_idx = 0\n",
    "for idx,row in dataset.iterrows():\n",
    "    l = len(row[4])\n",
    "    if l > max_len:\n",
    "        max_len = l\n",
    "        m_idx = idx\n",
    "print(m_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "DMGWi_5oQJjr",
    "outputId": "3777b468-d41a-4b8e-d36d-67f6969a1e1a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ci z koalicji rządzącej, ci posłowie, którzy w trakcie posiedzenia sejmowej Komisji Polityki Gospodarczej, Budżetu i Finansów z uporem, myślę, godnym lepszej sprawy, bronili faktu, aby rząd łącznie z budżetem - zapowiadam, łącznie z budżetem, bo mamy świadomość, że nie było i nie ma czasu na to, żeby wcześniej rozpatrywać założenia, a potem przedkładać budżet - przedłożył założenia polityki społeczno-gospodarczej, jako dokumentu ujmującego tę politykę w dłuższym czasie, posłowie, którzy nie dopuścili do takiego rozstrzygnięcia - przypominam, tylko jednym głosem - źle służą również rządowi.\n"
     ]
    }
   ],
   "source": [
    "print(dataset[4][m_idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 102
    },
    "colab_type": "code",
    "id": "jnyxW57oQJju",
    "outputId": "431f0f19-4d1f-465d-fc23-04e572950898"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (0.0)\n",
      "Requirement already satisfied: scikit-learn in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from sklearn) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.8.2 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.15.4)\n",
      "Requirement already satisfied: scipy>=0.13.3 in /home/ec2-user/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages (from scikit-learn->sklearn) (1.1.0)\n",
      "\u001b[31mfastai 1.0.60 requires nvidia-ml-py3, which is not installed.\u001b[0m\n",
      "\u001b[33mYou are using pip version 10.0.1, however version 20.0.2 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install sklearn\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gWyQKEhGQJjx"
   },
   "source": [
    "# Polbert\n",
    "\n",
    "Here we import pretrained version of Bert for Polish language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m0MH6jDKQJjx"
   },
   "outputs": [],
   "source": [
    "model_class, tokenizer_class, pretrained_weights = (BertModel, BertTokenizer, \"dkleczek/bert-base-polish-uncased-v1\")\n",
    "\n",
    "model = model_class.from_pretrained(pretrained_weights)\n",
    "tokenizer = tokenizer_class.from_pretrained(pretrained_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FTDjTaE9QJj1"
   },
   "source": [
    "## Tokenization\n",
    "\n",
    "Tokenize every sentence from our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ynst0zmtQJj2"
   },
   "outputs": [],
   "source": [
    "tokenized = dataset[4].apply((lambda x: tokenizer.encode(x, add_special_tokens=True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "id": "mZPS_Q89QJj5",
    "outputId": "9fa515e4-d29d-47d9-d1ed-a2105a0075a0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([2, 2055, 1898, 1907, 16, 2095, 2040, 15701, 1889, 3118, 16, 2095, 32091, 1014, 12071, 1014, 51, 1893, 15887, 1012, 1906, 27508, 2165, 4785, 18, 4]),\n",
       "       list([2, 2937, 2095, 1898, 26468, 40126, 1019, 29480, 6977, 1013, 7150, 18, 4]),\n",
       "       list([2, 3006, 16, 2095, 2243, 11319, 2713, 11007, 8572, 1889, 18, 4]),\n",
       "       ...,\n",
       "       list([2, 2030, 40221, 4949, 38584, 16, 2095, 2013, 2803, 12250, 1994, 26825, 2437, 48721, 16, 2030, 14229, 2114, 2808, 21694, 40575, 4955, 52867, 9417, 16, 2030, 8822, 1948, 2243, 24391, 3117, 4955, 52867, 1014, 27972, 16, 2030, 48570, 41886, 2243, 51, 5245, 50930, 36755, 50719, 15956, 23652, 2054, 18, 4]),\n",
       "       list([2, 31040, 16, 2095, 29801, 6289, 1015, 16, 10865, 3403, 2243, 16, 2095, 2259, 16879, 1015, 1893, 40065, 1923, 2243, 68, 4109, 16, 2095, 2499, 3089, 1906, 3115, 3410, 18, 4]),\n",
       "       list([2, 31040, 16, 2095, 29801, 6289, 1015, 16, 10865, 3403, 2243, 16, 2095, 2259, 16879, 1015, 1893, 40065, 1923, 2243, 68, 4109, 16, 2095, 2499, 3089, 1906, 3115, 3410, 18, 4])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oaDi0KStQJj8"
   },
   "source": [
    "## Padding\n",
    "\n",
    "We need to have input of the same lenght in order to feed BERT once (we will get performance speed). This will be some simple python string manipulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5aSvvbmTQJj8"
   },
   "outputs": [],
   "source": [
    "max_len = 0\n",
    "for i in tokenized.values:\n",
    "    if len(i) > max_len:\n",
    "        max_len = len(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "nGx5Tv89QJj_",
    "outputId": "a4352b2e-b43a-4f56-8f00-a0fd9db4a57b"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "146"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "m6khNyYFQJkC"
   },
   "source": [
    "Maybe we can consider shortening some sentences here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yrk93wfaQJkC"
   },
   "outputs": [],
   "source": [
    "padded = np.array([i + [0]*(max_len-len(i)) for i in tokenized.values])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "kKCOSXjXQJkF",
    "outputId": "36e6de7a-e281-4a24-e2df-dc7b54e0fc27"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    2,  2055,  1898, ...,     0,     0,     0],\n",
       "       [    2,  2937,  2095, ...,     0,     0,     0],\n",
       "       [    2,  3006,    16, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [    2,  2030, 40221, ...,     0,     0,     0],\n",
       "       [    2, 31040,    16, ...,     0,     0,     0],\n",
       "       [    2, 31040,    16, ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ziFFn1CAQJkI",
    "outputId": "218dc6b4-345f-4557-9db7-38d373d34375"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2596, 146)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(padded).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iFdLTJj4SX0-"
   },
   "source": [
    "## Computing embedding using BERT\n",
    "\n",
    "Now we do create cube of 146(tokens per row) * 768 (hidden layers) * 2596"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ydNiAHljQJkK"
   },
   "outputs": [],
   "source": [
    "input_ids = torch.tensor(np.array(padded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 136
    },
    "colab_type": "code",
    "id": "8wHwKIMGQJkM",
    "outputId": "5bb767a1-87a2-4d21-d577-600d4b0a621c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    2,  2055,  1898,  ...,     0,     0,     0],\n",
       "        [    2,  2937,  2095,  ...,     0,     0,     0],\n",
       "        [    2,  3006,    16,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [    2,  2030, 40221,  ...,     0,     0,     0],\n",
       "        [    2, 31040,    16,  ...,     0,     0,     0],\n",
       "        [    2, 31040,    16,  ...,     0,     0,     0]])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2596, 146])"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RhaInBWiQJkP"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    last_hidden_states = model(input_ids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "a6yN8AJkwCTT"
   },
   "source": [
    "We will extract two sets of embeddings. One for CSL only (2D array) and one for the whole cube"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "l7J8kG1XwNyo"
   },
   "outputs": [],
   "source": [
    "features = last_hidden_states[0][:,:,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ARcBn555mnQm"
   },
   "outputs": [],
   "source": [
    "cls_features = last_hidden_states[0][:,0,:].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "UTMLzojKmuno",
    "outputId": "2581c62b-b71b-492c-9d7e-c72a4c8b3835"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2596, 146, 768)"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1sQC37m4wYK2",
    "outputId": "e44ace33-5d4b-43aa-e063-8fac02f3b4cc"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2596, 768)"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cls_features.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Onehot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xxR7-ir-wlDy"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0.],\n",
       "       [0., 0., 0., 1.],\n",
       "       [0., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., 0.],\n",
       "       [0., 0., 1., 0.],\n",
       "       [0., 0., 1., 0.]])"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.array(dataset[5], dtype=np.int64)\n",
    "y_labels = np.zeros((y.size, y.max()+1))\n",
    "y_labels[np.arange(y.size),y] = 1\n",
    "y_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jFndQqv-xLNy"
   },
   "source": [
    "## Feed Forward Neural Network\n",
    "Creating Feed Forward Neural Network which will take as an input vector of embeddings and return one of semantic classes. Firstly we will do it for 2d CLS matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "iY8WmSEkxZV2"
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as ds\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4vFWqVXTxuk2"
   },
   "source": [
    "### Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 181
    },
    "colab_type": "code",
    "id": "ITzN8xfvxihR",
    "outputId": "49d19f80-5173-4565-ed3e-648547d4b543"
   },
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(cls_features, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert data to Torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features = torch.from_numpy(train_features)\n",
    "test_features = torch.from_numpy(test_features)\n",
    "train_labels = torch.from_numpy(train_labels)\n",
    "test_labels = torch.from_numpy(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Qct6HbphyCVV"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "194"
      ]
     },
     "execution_count": 299,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_size = int(train_features.shape[0] / 10)\n",
    "epochs = 20\n",
    "batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0hGGi59u1E62"
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class FeedforwardNeuralNetModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(FeedforwardNeuralNetModel, self).__init__()\n",
    "        # Linear function 1: 784 --> 100\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim) \n",
    "        # Non-linearity 1\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        # Linear function 2: 100 --> 100\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 2\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        # Linear function 3: 100 --> 100\n",
    "        self.fc3 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        # Non-linearity 3\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        # Linear function 4 (readout): 100 --> 10\n",
    "        self.fc4 = nn.Linear(hidden_dim, output_dim)  \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "6F86gYor1z_p",
    "outputId": "f57176fb-9de1-40f3-cd78-36d6e137d3c3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "768"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_dim = 768\n",
    "hidden_dim = 256\n",
    "output_dim = len(labels)\n",
    "\n",
    "input_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EDy7hQfj2ciB"
   },
   "outputs": [],
   "source": [
    "ffnn = FeedforwardNeuralNetModel(input_dim, hidden_dim, output_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Cf5LG44b4C7T"
   },
   "outputs": [],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0220, -0.0304, -0.0040,  ..., -0.0181, -0.0017,  0.0239],\n",
      "        [-0.0040, -0.0117, -0.0244,  ...,  0.0138,  0.0004, -0.0221],\n",
      "        [-0.0149,  0.0325, -0.0181,  ...,  0.0263,  0.0030, -0.0158],\n",
      "        ...,\n",
      "        [-0.0147,  0.0221, -0.0097,  ...,  0.0206, -0.0253,  0.0132],\n",
      "        [-0.0307, -0.0319, -0.0294,  ...,  0.0269, -0.0335,  0.0347],\n",
      "        [-0.0001,  0.0040,  0.0056,  ..., -0.0106, -0.0193,  0.0158]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0339,  0.0356,  0.0059,  0.0107, -0.0315,  0.0231, -0.0001,  0.0167,\n",
      "        -0.0012,  0.0064,  0.0060,  0.0330,  0.0347, -0.0244, -0.0129, -0.0150,\n",
      "        -0.0219,  0.0115,  0.0027, -0.0151,  0.0127, -0.0195,  0.0289,  0.0104,\n",
      "         0.0243, -0.0012,  0.0039,  0.0348,  0.0129, -0.0349, -0.0204, -0.0266,\n",
      "        -0.0204,  0.0157, -0.0337, -0.0004, -0.0214, -0.0126, -0.0310,  0.0299,\n",
      "        -0.0254,  0.0044, -0.0132, -0.0006,  0.0109, -0.0230, -0.0191,  0.0314,\n",
      "         0.0227, -0.0358, -0.0014, -0.0121, -0.0302,  0.0005,  0.0074,  0.0343,\n",
      "        -0.0169, -0.0005, -0.0157, -0.0185,  0.0251,  0.0082, -0.0360,  0.0076,\n",
      "         0.0123,  0.0156, -0.0334, -0.0169, -0.0238, -0.0119,  0.0359,  0.0287,\n",
      "         0.0244, -0.0016, -0.0001,  0.0045,  0.0089,  0.0145,  0.0177, -0.0060,\n",
      "         0.0325, -0.0175,  0.0342, -0.0179,  0.0012, -0.0178,  0.0242, -0.0357,\n",
      "        -0.0330, -0.0165, -0.0170, -0.0294, -0.0330,  0.0182,  0.0329, -0.0223,\n",
      "         0.0194,  0.0175, -0.0267, -0.0180, -0.0199,  0.0330,  0.0022,  0.0229,\n",
      "        -0.0306,  0.0347,  0.0232,  0.0173,  0.0048,  0.0302,  0.0288,  0.0292,\n",
      "        -0.0289, -0.0318, -0.0199, -0.0024, -0.0257,  0.0263, -0.0049, -0.0209,\n",
      "         0.0083,  0.0183, -0.0059,  0.0033, -0.0316,  0.0001, -0.0310, -0.0018,\n",
      "        -0.0173,  0.0020,  0.0100, -0.0145,  0.0052,  0.0258,  0.0188,  0.0022,\n",
      "         0.0251, -0.0081,  0.0057,  0.0035, -0.0015, -0.0236, -0.0356, -0.0317,\n",
      "         0.0150,  0.0225, -0.0053, -0.0339, -0.0253,  0.0305, -0.0171,  0.0289,\n",
      "        -0.0149,  0.0319, -0.0014, -0.0103,  0.0017,  0.0324, -0.0208, -0.0172,\n",
      "         0.0031, -0.0290, -0.0210,  0.0254,  0.0331, -0.0146,  0.0143, -0.0116,\n",
      "        -0.0125,  0.0293, -0.0323,  0.0100,  0.0078, -0.0213,  0.0227,  0.0037,\n",
      "        -0.0106,  0.0052, -0.0291,  0.0201, -0.0213, -0.0272, -0.0052, -0.0057,\n",
      "        -0.0208, -0.0179,  0.0227,  0.0178,  0.0104, -0.0103,  0.0165, -0.0240,\n",
      "        -0.0165,  0.0032, -0.0044, -0.0050, -0.0126, -0.0126,  0.0298, -0.0154,\n",
      "        -0.0169,  0.0319,  0.0118, -0.0093,  0.0086,  0.0196, -0.0194,  0.0105,\n",
      "         0.0135,  0.0038,  0.0099,  0.0157,  0.0072, -0.0296,  0.0134,  0.0262,\n",
      "        -0.0023, -0.0197, -0.0266,  0.0179,  0.0022, -0.0044, -0.0223,  0.0014,\n",
      "         0.0174,  0.0116, -0.0017,  0.0116, -0.0185, -0.0227, -0.0310,  0.0175,\n",
      "         0.0331, -0.0140, -0.0229, -0.0229,  0.0067,  0.0321,  0.0170,  0.0068,\n",
      "        -0.0353, -0.0151,  0.0079, -0.0181, -0.0020, -0.0313,  0.0150,  0.0209,\n",
      "        -0.0157,  0.0251,  0.0053, -0.0328, -0.0149,  0.0051,  0.0132, -0.0252],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0600,  0.0476,  0.0357,  ..., -0.0158,  0.0172, -0.0039],\n",
      "        [-0.0383, -0.0398,  0.0282,  ...,  0.0112,  0.0585,  0.0034],\n",
      "        [-0.0207,  0.0387,  0.0404,  ..., -0.0214,  0.0200, -0.0561],\n",
      "        ...,\n",
      "        [-0.0467,  0.0495, -0.0349,  ..., -0.0502,  0.0472,  0.0322],\n",
      "        [ 0.0081,  0.0209,  0.0139,  ...,  0.0063, -0.0196,  0.0343],\n",
      "        [ 0.0308, -0.0310, -0.0393,  ...,  0.0097, -0.0007,  0.0349]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 1.9830e-02, -1.8145e-03, -2.6519e-02,  5.4676e-02,  4.1938e-03,\n",
      "         1.3680e-02, -3.3100e-02,  3.5232e-02,  2.6283e-02,  5.0210e-02,\n",
      "        -1.9417e-02, -2.8971e-02, -2.3853e-02,  5.3960e-02,  4.9915e-02,\n",
      "         4.6316e-02,  5.1688e-02, -2.8726e-02,  1.5991e-02, -5.6607e-02,\n",
      "         4.9563e-02, -4.5322e-02,  4.3476e-02, -4.9436e-02, -6.1497e-02,\n",
      "        -3.0631e-02,  4.0809e-02,  3.2728e-02,  2.7502e-02,  1.4515e-02,\n",
      "         1.2058e-02,  2.2593e-02,  5.3980e-02,  4.4219e-02,  3.4611e-02,\n",
      "        -4.9500e-02, -5.6841e-02,  6.2243e-02, -6.7904e-03,  4.1362e-02,\n",
      "        -5.0565e-02,  4.3908e-02, -5.6292e-02,  8.8791e-03, -2.4837e-02,\n",
      "         2.6872e-02,  4.5735e-03,  1.7822e-02,  8.9558e-03, -1.4865e-02,\n",
      "         1.0817e-02,  4.8870e-02,  4.3993e-02, -2.9990e-02, -5.9803e-02,\n",
      "         4.8746e-02,  2.5432e-02,  3.4725e-02, -7.6956e-04,  3.9783e-02,\n",
      "         2.4767e-02, -4.3371e-02, -4.1121e-03,  5.7614e-02,  4.2329e-02,\n",
      "        -1.5090e-02,  3.9474e-02, -3.8234e-02,  2.8537e-02,  5.8126e-02,\n",
      "        -2.9260e-02, -3.3070e-02,  4.1295e-02,  1.1788e-02, -4.3356e-03,\n",
      "        -4.2198e-02,  4.3243e-02, -5.1049e-02, -2.4295e-02, -1.5870e-02,\n",
      "        -3.7698e-02,  5.8576e-02,  9.7064e-03, -2.5980e-02, -2.4358e-02,\n",
      "         2.2022e-02, -4.0813e-02, -3.4680e-02, -7.2598e-03,  3.1924e-02,\n",
      "         1.3098e-02, -3.7787e-02,  2.7295e-03,  2.2866e-02,  5.2954e-02,\n",
      "         2.7096e-02, -6.2392e-02,  3.4916e-02,  4.3583e-02, -3.6180e-03,\n",
      "        -4.2726e-02,  8.9606e-03, -1.9430e-02, -2.6242e-02,  2.4912e-02,\n",
      "        -4.4938e-03, -2.0220e-02, -4.2750e-02, -1.6643e-02,  1.0997e-02,\n",
      "        -2.3134e-02, -4.2154e-02,  3.5709e-02,  4.3245e-03,  2.3150e-02,\n",
      "         2.1738e-02, -1.4670e-02,  5.4291e-03, -4.4779e-02, -1.5101e-02,\n",
      "         1.1299e-03, -5.5044e-02, -2.3284e-02,  3.1601e-02,  1.2282e-02,\n",
      "         5.3185e-02,  5.2993e-02, -4.5376e-03, -1.6603e-02, -2.4707e-02,\n",
      "         1.2417e-02, -4.5867e-02,  4.2443e-03, -2.9830e-02,  4.8278e-02,\n",
      "        -1.6115e-02, -9.8734e-03, -2.6205e-02, -1.4688e-03, -3.9138e-02,\n",
      "        -6.1120e-02,  4.9886e-02,  4.3137e-02,  6.2437e-04,  2.0179e-02,\n",
      "        -6.1253e-02, -2.4833e-02, -1.5512e-02,  3.5219e-02, -4.8780e-02,\n",
      "        -5.5461e-02, -2.1027e-02,  2.4280e-02, -5.6842e-02,  4.9586e-02,\n",
      "        -3.7483e-02,  5.3765e-02,  6.1002e-02, -3.4188e-02,  4.3772e-02,\n",
      "        -6.0934e-02,  1.0958e-02,  3.7610e-02, -3.0042e-02,  4.3618e-02,\n",
      "         1.3831e-02,  4.4776e-02,  1.3635e-02,  6.1735e-02,  3.9571e-02,\n",
      "         1.9237e-05, -3.2165e-02, -2.3241e-02, -1.7040e-03,  3.1476e-02,\n",
      "        -4.2567e-02,  1.7071e-02, -5.2403e-02, -2.1521e-02, -3.5333e-02,\n",
      "        -3.1933e-02,  1.7567e-02,  5.4282e-02, -2.9487e-02, -6.7363e-03,\n",
      "        -9.0670e-03, -1.7070e-02,  3.7678e-02,  5.7416e-02, -2.7452e-02,\n",
      "        -6.0846e-02, -3.9943e-02,  1.7411e-02, -3.3534e-03,  5.0129e-02,\n",
      "        -3.5390e-02, -1.4607e-02, -1.3254e-02, -1.1214e-02,  3.5490e-02,\n",
      "         5.8880e-02, -5.9749e-02, -8.9707e-03,  3.6153e-02, -3.6948e-02,\n",
      "        -5.8462e-02,  5.5894e-02, -1.0824e-02, -2.7961e-02, -5.5298e-02,\n",
      "        -2.9433e-03,  5.8408e-02, -4.2682e-02, -6.0038e-02,  6.0636e-02,\n",
      "         2.1286e-02, -4.6359e-02, -5.1873e-02,  5.8589e-02, -4.3891e-02,\n",
      "         8.2656e-04,  5.3466e-02,  5.1352e-02,  2.5385e-02, -5.1681e-02,\n",
      "         1.8792e-02,  5.4544e-02,  4.5788e-02,  4.6886e-02, -9.9247e-03,\n",
      "        -1.0130e-03, -1.9687e-02,  2.0436e-04,  3.7771e-02, -1.1021e-02,\n",
      "         6.1472e-02,  4.4824e-02, -5.2554e-02, -7.3728e-03, -5.0794e-02,\n",
      "         4.8719e-02,  1.5391e-02,  5.6459e-02, -4.6761e-02, -3.7485e-02,\n",
      "        -2.5783e-03, -5.8960e-02, -2.4870e-03,  2.8390e-02,  6.0297e-02,\n",
      "        -5.6156e-02,  5.1682e-02, -5.3588e-02,  5.8408e-02,  1.8322e-02,\n",
      "         2.1148e-02], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[-0.0120, -0.0516, -0.0349,  ..., -0.0484, -0.0112, -0.0027],\n",
      "        [ 0.0182,  0.0561,  0.0517,  ...,  0.0515, -0.0397, -0.0235],\n",
      "        [-0.0308,  0.0092,  0.0466,  ...,  0.0418, -0.0591, -0.0493],\n",
      "        ...,\n",
      "        [-0.0384,  0.0620,  0.0549,  ..., -0.0575, -0.0615,  0.0308],\n",
      "        [ 0.0119,  0.0498, -0.0577,  ...,  0.0548, -0.0019, -0.0442],\n",
      "        [ 0.0535, -0.0368, -0.0221,  ..., -0.0091,  0.0252,  0.0095]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0502, -0.0122, -0.0416,  0.0522, -0.0196, -0.0202,  0.0265, -0.0005,\n",
      "        -0.0045, -0.0102, -0.0168, -0.0049,  0.0312, -0.0057, -0.0029,  0.0491,\n",
      "         0.0075,  0.0072,  0.0063,  0.0103,  0.0488,  0.0465,  0.0171,  0.0381,\n",
      "         0.0612,  0.0085,  0.0338, -0.0396, -0.0205,  0.0272, -0.0361, -0.0612,\n",
      "        -0.0406,  0.0050, -0.0599, -0.0121,  0.0482,  0.0466, -0.0304, -0.0498,\n",
      "        -0.0402, -0.0527,  0.0055,  0.0172,  0.0247,  0.0041,  0.0230,  0.0523,\n",
      "        -0.0620, -0.0282, -0.0456, -0.0336, -0.0038,  0.0003, -0.0500,  0.0567,\n",
      "         0.0513, -0.0543,  0.0239,  0.0027, -0.0285,  0.0136,  0.0002,  0.0496,\n",
      "         0.0047,  0.0497,  0.0148, -0.0287, -0.0191, -0.0430, -0.0307, -0.0057,\n",
      "         0.0095, -0.0615, -0.0436, -0.0213,  0.0267, -0.0180,  0.0076,  0.0075,\n",
      "        -0.0472, -0.0391, -0.0303,  0.0141, -0.0617, -0.0008, -0.0303, -0.0359,\n",
      "        -0.0380, -0.0127, -0.0603,  0.0254,  0.0520,  0.0029,  0.0585,  0.0432,\n",
      "        -0.0412,  0.0351, -0.0602,  0.0094,  0.0459, -0.0163, -0.0309, -0.0092,\n",
      "        -0.0149,  0.0452,  0.0613,  0.0403, -0.0201, -0.0286, -0.0326,  0.0323,\n",
      "        -0.0106, -0.0232, -0.0023,  0.0049,  0.0011,  0.0146, -0.0146,  0.0442,\n",
      "        -0.0276, -0.0513,  0.0020,  0.0003,  0.0111,  0.0524,  0.0592, -0.0463,\n",
      "         0.0162, -0.0168,  0.0592,  0.0551,  0.0098,  0.0057, -0.0335,  0.0130,\n",
      "        -0.0411,  0.0568, -0.0328, -0.0561,  0.0275,  0.0199, -0.0598, -0.0513,\n",
      "        -0.0073,  0.0259,  0.0045,  0.0068, -0.0016, -0.0099, -0.0160,  0.0104,\n",
      "         0.0109,  0.0381, -0.0512,  0.0416,  0.0316, -0.0407,  0.0343, -0.0200,\n",
      "        -0.0147, -0.0330, -0.0350,  0.0143, -0.0231, -0.0595, -0.0285, -0.0185,\n",
      "        -0.0605,  0.0189,  0.0579, -0.0123, -0.0284,  0.0617, -0.0301, -0.0431,\n",
      "        -0.0414, -0.0566, -0.0099,  0.0366, -0.0480, -0.0219,  0.0582, -0.0360,\n",
      "        -0.0034,  0.0515,  0.0573,  0.0554,  0.0582,  0.0211, -0.0130, -0.0299,\n",
      "         0.0491,  0.0132, -0.0485, -0.0033, -0.0452,  0.0261,  0.0389, -0.0555,\n",
      "         0.0024, -0.0006,  0.0257, -0.0491,  0.0007,  0.0075, -0.0282, -0.0259,\n",
      "         0.0566,  0.0283,  0.0237, -0.0314, -0.0219,  0.0575,  0.0406, -0.0022,\n",
      "         0.0462, -0.0325, -0.0196,  0.0393,  0.0023,  0.0358,  0.0357,  0.0132,\n",
      "        -0.0462,  0.0369,  0.0148, -0.0421, -0.0285, -0.0387,  0.0517, -0.0043,\n",
      "        -0.0514,  0.0320, -0.0059,  0.0153,  0.0290,  0.0429,  0.0066,  0.0221,\n",
      "         0.0444, -0.0602, -0.0467, -0.0162,  0.0461,  0.0376,  0.0120,  0.0007,\n",
      "         0.0318, -0.0618,  0.0096,  0.0425,  0.0560, -0.0179, -0.0125, -0.0562],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([[ 0.0427, -0.0555, -0.0031,  ..., -0.0058,  0.0269, -0.0360],\n",
      "        [ 0.0467,  0.0128,  0.0384,  ...,  0.0239,  0.0367, -0.0560],\n",
      "        [ 0.0191, -0.0319, -0.0610,  ...,  0.0161,  0.0276, -0.0132],\n",
      "        [-0.0171, -0.0231,  0.0390,  ..., -0.0340, -0.0172, -0.0206]],\n",
      "       requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([ 0.0524, -0.0306,  0.0296, -0.0226], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "for param in ffnn.parameters():\n",
    "    print (param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "WsxNME414HUA"
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.05\n",
    "optimizer = torch.optim.SGD(ffnn.parameters(), lr=learning_rate) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zTTTazHA-HOX"
   },
   "outputs": [],
   "source": [
    "def generate_batch_data(x, y, batch_size):\n",
    "    i, batch = 0, 0\n",
    "    for batch, i in enumerate(range(0, len(x) - batch_size, batch_size), 1):\n",
    "        x_batch = x[i : i + batch_size]\n",
    "        y_batch = y[i : i + batch_size]\n",
    "        yield x_batch, y_batch, batch\n",
    "    if i + batch_size < len(x):\n",
    "        yield x[i + batch_size :], y[i + batch_size :], batch + 1\n",
    "    if batch == 0:\n",
    "        yield x, y, 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 684
    },
    "colab_type": "code",
    "id": "Tnz6d-894cqm",
    "outputId": "61b3f6b5-ebc9-4444-8272-3014150d35b0"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'FeedforwardNeuralNetModel' object has no attribute 'conv1'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-332-ac494c27f03e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mx_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgenerate_batch_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mffnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-325-50440ef271ff>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m320\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p36/lib/python3.6/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    574\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    575\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m--> 576\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m    577\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    578\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'FeedforwardNeuralNetModel' object has no attribute 'conv1'"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = [], []\n",
    "\n",
    "for epoch in range(0,epochs):\n",
    "    \n",
    "    start_time = time.time()\n",
    "    ffnn.train(True)\n",
    "    train_loss = 0 \n",
    "    \n",
    "    for x_batch, y_batch, batch in generate_batch_data(train_features, train_labels, batch_size):\n",
    "        y_pred = ffnn(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred, y_batch)\n",
    "\n",
    "        # Getting gradients w.r.t. parameters\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= batch\n",
    "    train_losses.append(train_loss)\n",
    "    elapsed = time.time() - start_time\n",
    "    \n",
    "    model.eval() # disable dropout for deterministic output\n",
    "    # deactivate autograd engine to reduce memory usage and speed up computations\n",
    "    with torch.no_grad(): \n",
    "            val_loss, batch = 0, 1\n",
    "            for x_batch, y_batch, batch in generate_batch_data(test_features, test_labels, batch_size):\n",
    "                y_pred = ffnn(x_batch)\n",
    "                loss = loss_fn(y_pred, y_batch)\n",
    "                val_loss += loss.item()\n",
    "            val_loss /= batch\n",
    "            val_losses.append(val_loss) \n",
    "            print(\"Epoch %d Train loss: %.2f. Validation loss: %.2f. Elapsed time: %.2fs.\" % (epoch + 1, train_losses[-1], val_losses[-1], elapsed))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Losses')"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(train_losses, label=\"Training loss\")\n",
    "plt.plot(val_losses, label=\"Validation loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Losses\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "bert-poc.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_pytorch_p36",
   "language": "python",
   "name": "conda_pytorch_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
